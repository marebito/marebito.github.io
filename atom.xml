<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>博伊卡の楼閣</title>
  
  <subtitle>逆水行舟，不进则退</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://zhaolilong.com/"/>
  <updated>2020-03-13T04:41:40.608Z</updated>
  <id>https://zhaolilong.com/</id>
  
  <author>
    <name>Boyka·Yuri</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>实例学习Metal-第十四章 参考书目</title>
    <link href="https://zhaolilong.com/2020/04/12/%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0Metal-%E5%8F%82%E8%80%83%E4%B9%A6%E7%9B%AE/"/>
    <id>https://zhaolilong.com/2020/04/12/实例学习Metal-参考书目/</id>
    <published>2020-04-11T16:00:00.000Z</published>
    <updated>2020-03-13T04:41:40.608Z</updated>
    
    <content type="html"><![CDATA[<p>Barrett, Sean. 2014. “stb Single-File Public Domain Libraries for C/C++.” <a href="https://github" target="_blank" rel="noopener">https://github</a>. com/nothings/stb.<br><br><br>Blinn, James F. 1977. “Models of Light Reflection for Computer Synthesized Pictures.” In Proceedings of the 4th Annual Conference on Computer Graphics and Interactive Techniques, 192–98. SIGGRAPH ’77. New York, NY, USA: ACM. doi:10.1145/563858.563893.<br><br></p><a id="more"></a><p>Barrett, Sean. 2014. “stb Single-File Public Domain Libraries for C/C++.” <a href="https://github" target="_blank" rel="noopener">https://github</a>. com/nothings/stb.<br><br><br>Blinn, James F. 1977. “Models of Light Reflection for Computer Synthesized Pictures.” In Proceedings of the 4th Annual Conference on Computer Graphics and Interactive Techniques, 192–98. SIGGRAPH ’77. New York, NY, USA: ACM. doi:10.1145/563858.563893.<br><br><br>Boxley, Paul. 2011. “Terrain Generation with the Diamond Square Algorithm.” http: //<a href="http://www.paulboxley.com/blog/2011/03/terrain-generation-mark-one" target="_blank" rel="noopener">www.paulboxley.com/blog/2011/03/terrain-generation-mark-one</a>.<br><br><br>Carpenter, Loren. 1984. “The A-Buffer, an Antialiased Hidden Surface Method.” In Pro- ceedings of the 11th Annual Conference on Computer Graphics and Interactive Techniques, 103–8. SIGGRAPH ’84. New York, NY, USA: ACM. doi:10.1145/800031.808585.<br><br><br>Esfahbod, Behdad. 2014. “GLyphy.” <a href="https://github.com/behdad/glyphy" target="_blank" rel="noopener">https://github.com/behdad/glyphy</a>.<br><br><br>Giesen, Fabien. 2011. “A Trip Through the Graphics Pipeline 2011, Part 7,” July. https:// fgiesen.wordpress.com/2011/07/08/a-trip-through-the-graphics-pipeline-2011-part-7/.<br><br><br>Glassner, Andrew. 2015. “Interpreting Alpha.” Journal of Computer Graphics Techniques (JCGT) 4 (2): 30–44. <a href="http://jcgt.org/published/0004/02/03/" target="_blank" rel="noopener">http://jcgt.org/published/0004/02/03/</a>.<br><br><br>Gortler, Steven J. 2012. Foundations of 3D Computer Graphics. The MIT Press.<br><br><br>Green, Chris. 2007. “Improved Alpha-Tested Magnification for Vector Textures and Spe- cial Effects.” In ACM SIGGRAPH 2007 Courses, 9–18. SIGGRAPH ’07. New York, NY, USA: ACM. doi:10.1145/1281500.1281665.<br><br><br>Grevera, George J. 2004. “The ‘Dead Reckoning’ Signed Distance Transform.” Com- put. Vis. Image Underst. 95 (3). New York, NY, USA: Elsevier Science Inc.: 317–33. doi:10.1016/j.cviu.2004.05.002.<br><br><br>Gustavson, Stefan. 2012. “2D Shape Rendering by Distance Fields.” In OpenGL Insights, edited by Patrick Cozzi and Christophe Riccio, 173–82. CRC Press.<br><br><br>Hughes, J.F., A. Van Dam, J.D. Foley, and S.K. Feiner. 2013. Computer Graphics: Principles<br>and Practice. 3rd ed. Addison-Wesley.<br><br><br>International Telecom Union. 2011. RECOMMENDATION ITU-R BT.601-7. https://<br><a href="http://www.itu.int/dms_pubrec/itu-r/rec/bt/R-REC-BT.601-7-201103-I!!PDF-E.pdf" target="_blank" rel="noopener">www.itu.int/dms_pubrec/itu-r/rec/bt/R-REC-BT.601-7-201103-I!!PDF-E.pdf</a>.<br><br><br>Jargstorff, Frank. 2004. “A Framework for Image Processing.” In GPU Gems, edited by Randima Fernando. Addison-Wesley Professional. <a href="http://http.developer.nvidia.com/" target="_blank" rel="noopener">http://http.developer.nvidia.com/</a> GPUGems/gpugems_ch27.html.<br><br><br>Khronos Group. 2013. “KTX File Format Specification.” Edited by Mark Callow, Georg Kolling, and Jacob Ström. <a href="https://www.khronos.org/opengles/sdk/tools/KTX/file" target="_blank" rel="noopener">https://www.khronos.org/opengles/sdk/tools/KTX/file</a>_ format_spec/.<br><br><br>Lengyel, Eric. 2011. Mathematics for 3D Game Programming and Computer Graphics. 3rd ed. Boston, MA, United States: Course Technology Press.<br><br><br>McGuire, Morgan, and Louis Bavoil. 2013. “Weighted Blended Order-Independent Transparency.” Journal of Computer Graphics Techniques (JCGT) 2 (2): 122–41. <a href="http://jcgt" target="_blank" rel="noopener">http://jcgt</a>. org/published/0002/02/09/.<br><br><br>Miller, Gavin S P. 1986. “The Definition and Rendering of Terrain Maps.” In Proceedings of the 13th Annual Conference on Computer Graphics and Interactive Techniques, 39–48. SIG- GRAPH ’86. New York, NY, USA: ACM. doi:10.1145/15922.15890.<br><br><br>Wavefront Technologies. 1991. “Appendix B1. Object Files.” In Programmer’s Reference Manual for the Advanced Visualizer. <a href="http://www.cs.utah.edu/~boulos/cs3505/obj_spec" target="_blank" rel="noopener">http://www.cs.utah.edu/~boulos/cs3505/obj_spec</a>. pdf.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Barrett, Sean. 2014. “stb Single-File Public Domain Libraries for C/C++.” &lt;a href=&quot;https://github&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github&lt;/a&gt;. com/nothings/stb.&lt;br&gt;&lt;br&gt;&lt;br&gt;Blinn, James F. 1977. “Models of Light Reflection for Computer Synthesized Pictures.” In Proceedings of the 4th Annual Conference on Computer Graphics and Interactive Techniques, 192–98. SIGGRAPH ’77. New York, NY, USA: ACM. doi:10.1145/563858.563893.&lt;br&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="iOS/Mac" scheme="https://zhaolilong.com/tags/iOS-Mac/"/>
    
      <category term="图形学" scheme="https://zhaolilong.com/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
      <category term="Metal" scheme="https://zhaolilong.com/tags/Metal/"/>
    
  </entry>
  
  <entry>
    <title>实例学习Metal-第十四章 图像处理基础</title>
    <link href="https://zhaolilong.com/2020/04/05/%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0Metal-%E7%AC%AC%E5%8D%81%E5%9B%9B%E7%AB%A0/"/>
    <id>https://zhaolilong.com/2020/04/05/实例学习Metal-第十四章/</id>
    <published>2020-04-04T16:00:00.000Z</published>
    <updated>2020-03-13T04:42:40.214Z</updated>
    
    <content type="html"><![CDATA[<p>在本章中，我们将开始使用Metal着色语言探索图像处理世界。我们将创建一个能够表示图像滤镜链的框架，然后编写一对图像滤镜，以便我们调整图像的饱和度和模糊度。最终结果将是一个交互式应用程序，允许您实时控制图像过滤器参数。</p><p>图像处理是数据并行编程的主要应用之一。在许多情况下，图像滤波器仅需要查询源图像中的一个像素或小邻域像素以计算每个输出像素的值。在这种情况下，图像滤波器的工作可以以并行方式完成。这非常适合现代GPU架构，它使用许多小内核同时处理多个数据。</p><a id="more"></a><h1 id="Chapter-14-第十四章"><a href="#Chapter-14-第十四章" class="headerlink" title="Chapter 14(第十四章)"></a>Chapter 14(第十四章)</h1><h2 id="Fundamentals-of-Image-Processing-图像处理基础"><a href="#Fundamentals-of-Image-Processing-图像处理基础" class="headerlink" title="Fundamentals of Image Processing(图像处理基础)"></a>Fundamentals of Image Processing(图像处理基础)</h2><p>在本章中，我们将开始使用Metal着色语言探索图像处理世界。我们将创建一个能够表示图像滤镜链的框架，然后编写一对图像滤镜，以便我们调整图像的饱和度和模糊度。最终结果将是一个交互式应用程序，允许您实时控制图像过滤器参数。</p><p>图像处理是数据并行编程的主要应用之一。在许多情况下，图像滤波器仅需要查询源图像中的一个像素或小邻域像素以计算每个输出像素的值。在这种情况下，图像滤波器的工作可以以并行方式完成。这非常适合现代GPU架构，它使用许多小内核同时处理多个数据。</p><h3 id="A-Look-Ahead-展望未来"><a href="#A-Look-Ahead-展望未来" class="headerlink" title="A Look Ahead(展望未来)"></a>A Look Ahead(展望未来)</h3><p>为了进一步激励本章，这里是示例项目的一个片段。它说明了如何简洁地创建并将由可动态调整的用户界面控制的去饱和度和模糊过滤器链接在一起。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">context = [MBEContext newContext]; </span><br><span class="line">imageProvider = [MBEMainBundleTextureProvider textureProviderWithImageNamed:@&quot;mandrill&quot; context:context];</span><br><span class="line">desaturateFilter = [MBESaturationAdjustmentFilter filterWithSaturationFactor:0.75</span><br><span class="line">context:context];</span><br><span class="line">desaturateFilter.provider = self.imageProvider; </span><br><span class="line">blurFilter = [MBEGaussianBlur2DFilter filterWithRadius:0.0 context:context];</span><br><span class="line">blurFilter.provider = desaturateFilter;</span><br><span class="line">imageView.image = [UIImage imageWithMTLTexture:blurFilter.texture];</span><br></pre></td></tr></table></figure><p><img src="/2020/04/05/实例学习Metal-第十四章/1584068924.png" alt=""></p><center>图14.1：示例应用程序UI，允许实时过滤器调整。</center><h3 id="A-Framework-for-Image-Processing-图像处理框架"><a href="#A-Framework-for-Image-Processing-图像处理框架" class="headerlink" title="A Framework for Image Processing(图像处理框架)"></a>A Framework for Image Processing(图像处理框架)</h3><p>现在我们已经了解了我们希望图像处理框架的界面看起来像什么，我们可以讨论构建这样一个框架的实用性。该框架的大部分架构都受到（Jargstorff 2004）的启发。</p><h4 id="Texture-Providers-and-Consumers-纹理提供者和消费者"><a href="#Texture-Providers-and-Consumers-纹理提供者和消费者" class="headerlink" title="Texture Providers and Consumers(纹理提供者和消费者)"></a>Texture Providers and Consumers(纹理提供者和消费者)</h4><p>每个过滤器都能够使用其输入和输出纹理配置其计算管道并执行其内核功能。</p><p>由于我们将以纹理的形式对图像进行操作，因此我们需要一种抽象的方式来引用生成和使用纹理的对象。例如，过滤器使用和生成纹理，我们还需要一个用于从中生成纹理的类应用程序包。</p><p>我们使用名为<code>MBETextureProvider</code>的协议来抽象纹理生成的概念：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">@protocol</span> <span class="title">MBETextureProvider</span> &lt;<span class="title">NSObject</span>&gt;</span></span><br><span class="line"><span class="keyword">@property</span> (<span class="keyword">nonatomic</span>, <span class="keyword">readonly</span>) <span class="keyword">id</span>&lt;<span class="built_in">MTLTexture</span>&gt; texture; </span><br><span class="line"><span class="keyword">@end</span></span><br></pre></td></tr></table></figure><p>这个简单的界面为我们提供了一种(同步)从纹理提供者请求纹理的方法。它可能导致图像过滤器执行其过滤过程，或从磁盘加载图像。重要的是，我们知道我们可以从任何符合<code>MBETextureProvider</code>的对象中检索纹理。</p><p>另一方面，<code>MBETextureConsumer</code>协议允许我们告诉对象它应该从哪个纹理提供者使用纹理：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">@protocol</span> <span class="title">MBETextureConsumer</span> &lt;<span class="title">NSObject</span>&gt;</span></span><br><span class="line"><span class="keyword">@property</span> (<span class="keyword">nonatomic</span>, <span class="keyword">strong</span>) <span class="keyword">id</span>&lt;MBETextureProvider&gt; provider; </span><br><span class="line"><span class="keyword">@end</span></span><br></pre></td></tr></table></figure><p>这个简单的接口为我们提供了一种（同步）从纹理提供者请求纹理的方式。它可能导致图像过滤器执行其过滤过程，或从磁盘加载图像。重要的是，我们知道我们可以从任何符合<code>MBETextureProvider</code>的对象中检索纹理。</p><p>另一方面，<code>MBETextureConsumer</code>协议允许我们告诉对象它应该从哪个纹理提供者使用纹理：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">@protocol MBETextureConsumer &lt;NSObject&gt;</span><br><span class="line">@property (nonatomic, strong) id&lt;MBETextureProvider&gt; provider; </span><br><span class="line">@end</span><br></pre></td></tr></table></figure><p>当纹理使用者想要对纹理进行操作时，它会从其提供者请求纹理并对其进行操作。</p><h4 id="An-Image-Filter-Base-Class-图像过滤器基类"><a href="#An-Image-Filter-Base-Class-图像过滤器基类" class="headerlink" title="An Image Filter Base Class(图像过滤器基类)"></a>An Image Filter Base Class(图像过滤器基类)</h4><p>抽象地，图像滤波器通过对其进行任意操作将一个纹理转换为另一个纹理。我们的MBEImageFilter类完成了调用计算着色器以从另一个生成一个纹理所需的大量工作。</p><p>图像过滤器基类符合刚才讨论的纹理提供者和纹理消费者协议。让过滤器表现为纹理提供者和纹理消费者都允许我们将过滤器链接在一起以按顺序执行多个操作。由于图像上下文管理的命令队列的串行特性，因此可以保证每个过滤器在允许其后继执行之前完成其工作。</p><p>这是MBEImageFilter类接口的相关部分：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">@interface MBEImageFilter : NSObject &lt;MBETextureProvider, MBETextureConsumer&gt; @property (nonatomic, strong) MBEContext *context;</span><br><span class="line">@property (nonatomic, strong) id&lt;MTLComputePipelineState&gt; pipeline; @property (nonatomic, strong) id&lt;MTLTexture&gt; internalTexture;</span><br><span class="line">@property (nonatomic, assign, getter=isDirty) BOOL dirty;</span><br><span class="line">- (instancetype)initWithFunctionName:(NSString *)functionName</span><br><span class="line">context:(MBEContext *)context;</span><br><span class="line">- (void)configureArgumentTableWithCommandEncoder: (id&lt;MTLComputeCommandEncoder&gt;)commandEncoder;</span><br></pre></td></tr></table></figure><p>必须使用函数名称和上下文来实例化过滤器。这些用于创建计算管道状态，然后将其存储在<code>pipeline</code>属性中。</p><p>图像过滤器保持内部纹理，用作其内核函数的输出纹理。这样它可以存储其计算结果并将其提供给其他过滤器。它也可以绘制到屏幕或转换为图像。</p><p>图像过滤器可能具有任何数量的参数，这些参数会影响它们执行计算的方式。当其中一个更改时，内部纹理无效，并且必须重新执行内核函数。脏标志允许过滤器子类指示何时需要。仅当<code>dirty</code>标识设置为YES时才会执行过滤器，这在自定义属性设置器中完成。</p><p>图像过滤器基类包含<code>-applyFilter</code>方法，该方法在被要求提供其输出纹理时被调用，并且当前是脏的。此方法创建一个命令缓冲区和命令编码器，并调度其内核函数，如前一章所述。</p><p>既然我们已经拥有了必要的机器，让我们来谈谈将要使用的几个示例过滤器。</p><h3 id="Building-a-Saturation-Adjustment-Filter-构建饱和度调整过滤器"><a href="#Building-a-Saturation-Adjustment-Filter-构建饱和度调整过滤器" class="headerlink" title="Building a Saturation Adjustment Filter(构建饱和度调整过滤器)"></a>Building a Saturation Adjustment Filter(构建饱和度调整过滤器)</h3><p>我们将构建的第一个滤镜是饱和度调整滤镜。滤波器将具有可配置的饱和因子，用于确定滤波器应对输入图像进行去饱和的程度。此因子的范围为0到1.当饱和因子为0时，输出图像将是输入的灰度版本。对于介于0和1之间的值，滤镜将通过在灰度图像和输入图像之间进行插值来生成颜色或多或少静音的图像。</p><p><img src="/2020/04/05/实例学习Metal-第十四章/1584068954.png" alt=""></p><center>图14.2：一系列图像显示了如何将滤波器的饱和因子从0增加到1会增加图像饱和度</center><h4 id="Calculating-Brightness-from-RGB-从RGB计算亮度"><a href="#Calculating-Brightness-from-RGB-从RGB计算亮度" class="headerlink" title="Calculating Brightness from RGB(从RGB计算亮度)"></a>Calculating Brightness from RGB(从RGB计算亮度)</h4><p>每个RGB颜色值都有一个相应的亮度值，我们将用符号Y’表示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Y′ = 0.299R + 0.587G + 0.114B</span><br></pre></td></tr></table></figure><p>请注意，公式中的因子总和为1.它们的值基于人类对不同原色光强度的感知：人眼对绿光最敏感，其次是红光，最后是蓝光。 （这些值作为ITU-R BT.601-7建议书（国际电信联盟2011）第2.5.1节）的一部分公布。</p><p>用相应亮度的灰色像素替换图像中的每种颜色会产生完全去饱和的图像，该图像与原始图像具有相同的感知亮度。这将是我们的去饱和核函数的任务，如下所示。</p><h4 id="The-Desaturation-Kernel-去饱和核"><a href="#The-Desaturation-Kernel-去饱和核" class="headerlink" title="The Desaturation Kernel(去饱和核)"></a>The Desaturation Kernel(去饱和核)</h4><p>为了支持将饱和因子传递给我们的内核函数，我们创建了一个名为AdjustSaturationUniforms的单元结构：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">struct AdjustSaturationUniforms </span><br><span class="line">&#123;</span><br><span class="line">    float saturationFactor; </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>内核函数本身采用输入纹理，输出纹理，对统一结构的引用，以及具有我们在前一章中没有详细描述的属性的整数的2D向量：<code>thread_position_in_grid</code>。</p><p>回想一下前一章，我们发送了一组二维线程组，其大小是根据源纹理的维度计算的。 <code>thread_position_in_grid</code>属性告诉Metal生成一个坐标向量，告诉我们我们在2D网格中的位置，该网格跨越整个调度的工作项集，即源纹理中的当前坐标。</p><p>我们为每个纹理参数指定预期的访问模式：<code>access::read</code>用于输入纹理，<code>access::write</code>用于输出纹理。这限制了我们可以调用这些参数的函数集。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">kernel void adjust_saturation(texture2d&lt;float, access::read&gt; inTexture [[texture(0)]],</span><br><span class="line">texture2d&lt;float, access::write&gt; outTexture [[texture(1)]], constant AdjustSaturationUniforms &amp;uniforms [[buffer(0)]], uint2 gid [[thread_position_in_grid]])</span><br><span class="line">&#123;</span><br><span class="line">    float4 inColor = inTexture.read(gid);</span><br><span class="line">    float value = dot(inColor.rgb, float3(0.299, 0.587, 0.114));</span><br><span class="line">    float4 grayColor(value, value, value, 1.0);</span><br><span class="line">    float4 outColor = mix(grayColor, inColor, uniforms.saturationFactor); outTexture.write(outColor, gid);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们读取源纹素的颜色，并根据前面给出的公式计算其亮度值。点函数允许我们比分别进行三次乘法和两次加法更简洁地完成此操作。然后，我们通过将亮度复制到RGB组件中来生成新颜色，这会产生灰色阴影。</p><p>要计算部分去饱和的输出颜色，我们使用Metal标准库中的函数：mix，它采用两种颜色，系数介于0和1之间。如果系数为0，则返回第一种颜色，如果为1，则返回1 ，返回第二种颜色。在它们之间，它使用线性插值将它们混合在一起。</p><p>最后，我们将得到的去饱和颜色写入输出纹理。请注意，我们之前假设输入和输出纹理具有相同的大小，并且两者的维度都是我们的线程组大小的倍数。如果不是这种情况，我们需要防止在输出纹理边界之外的输入写入范围之外进行读取。</p><h4 id="The-Saturation-Adjustment-Class-饱和度调整类"><a href="#The-Saturation-Adjustment-Class-饱和度调整类" class="headerlink" title="The Saturation Adjustment Class(饱和度调整类)"></a>The Saturation Adjustment Class(饱和度调整类)</h4><p>为了驱动饱和度调整内核，我们需要扩展图像过滤器基类。该子类名为<code>MBESaturationAdjustmentFilter</code>：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">@interface</span> <span class="title">MBESaturationAdjustmentFilter</span> : <span class="title">MBEImageFilter</span> </span></span><br><span class="line"><span class="keyword">@property</span> (<span class="keyword">nonatomic</span>, <span class="keyword">assign</span>) <span class="keyword">float</span> saturationFactor;</span><br><span class="line">+ (<span class="keyword">instancetype</span>)filterWithSaturationFactor:(<span class="keyword">float</span>)saturation</span><br><span class="line">context:(MBEContext *)context; </span><br><span class="line"><span class="keyword">@end</span></span><br></pre></td></tr></table></figure><p>该子类使用去饱和内核函数的名称调用初始化程序，并通过对它应该操作的上下文的引用。</p><p>设置<code>saturationFactor</code>属性会导致过滤器设置其<code>dirty</code>属性，这会导致在其纹理属性被请求时延迟重新计算去饱和图像。</p><p>子类的<code>-configureArgumentTableWithCommandEncoder:</code>的实现：包含样板，用于将饱和因子复制到Metal缓冲区中。这里没有显示。</p><p>我们现在有一个完整的过滤器类和内核函数来执行图像去饱和。</p><h4 id="模糊"><a href="#模糊" class="headerlink" title="模糊"></a>模糊</h4><p>我们将看到的下一类图像滤镜是模糊滤镜。</p><p>模糊图像涉及将每个纹素的颜色与相邻文本的颜色混合。在数学上，模糊滤波器是纹素的邻域的加权平均值（这种操作称为<code>卷积</code>）。邻域的大小称为过滤器的半径。小半径将平均较少的纹理像素并产生较少模糊的图像。</p><h4 id="盒子模糊"><a href="#盒子模糊" class="headerlink" title="盒子模糊"></a>盒子模糊</h4><p>最简单的模糊是盒子模糊。框模糊给予所有附近纹素的相同权重，计算它们的平均值。盒子模糊很容易计算，但会产生难看的伪影，因为它们会给噪音带来不适当的重量。</p><p>假设我们选择半径为1的盒子模糊。然后输出图像中的每个纹素将是输入纹理元素及其最近邻居的平均值。 9种颜色中的每一种都具有相同的1/9重量。</p><p><img src="/2020/04/05/实例学习Metal-第十四章/1584068998.png" alt=""></p><center>图14.3：框模糊过滤器平均每个纹素周围的邻域。</center><p>盒子模糊很容易，但它们不会产生非常令人满意的结果。相反，我们将使用更复杂的模糊滤镜，即高斯模糊。</p><h4 id="Gussian-Blur-高斯模糊"><a href="#Gussian-Blur-高斯模糊" class="headerlink" title="Gussian Blur(高斯模糊)"></a>Gussian Blur(高斯模糊)</h4><p>与盒子模糊相反，高斯模糊给相邻纹素提供了不相等的权重，为更接近的纹素赋予了更多的权重，而对于那些更远的纹理则更轻。实际上，权重是根据关于当前纹素的2D正态分布计算的：</p><p>$$<br>G_\sigma(x, y) = {1 \over \sqrt {2\pi\sigma^2}}e^{-{x^2 + y^2\over 2 \sigma^2}}<br>$$</p><p>其中x和y分别是正在处理的纹理元素与其邻居之间沿x和y轴的距离。 σ是分布的标准偏差，默认等于半径的一半。</p><p><img src="/2020/04/05/实例学习Metal-第十四章/1584069023.png" alt=""></p><center>图14.4：高斯模糊滤波器。增加滤镜半径可以创建更平滑的图像。此处显示的最大半径为7。</center><h4 id="The-Blur-Shaders-模糊着色器"><a href="#The-Blur-Shaders-模糊着色器" class="headerlink" title="The Blur Shaders(模糊着色器)"></a>The Blur Shaders(模糊着色器)</h4><p>计算高斯滤波器的模糊权重在核函数中是很昂贵的，特别是对于具有大半径的滤波器。因此，我们将预先计算表格权重并将其作为纹理提供给高斯模糊核函数。此纹理的像素格式为<code>MTLPixelFormatR32Float</code>，它是单通道32位浮点格式。每个纹素都包含0到1之间的权重，所有权重总和为1。</p><p>在内核函数内部，我们迭代当前纹理元素的邻域，从查找表中读取每个纹素及其相应的权重。然后我们将加权颜色添加到累积值。一旦我们完成了所有加权颜色值的加总，我们就会将最终颜色写入输出纹理。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">kernel void gaussian_blur_2d(texture2d&lt;float, access::read&gt; inTexture [[texture(0)]],</span><br><span class="line">texture2d&lt;float, access::write&gt; outTexture [[texture(1)]], texture2d&lt;float, access::read&gt; weights [[texture(2)]], uint2 gid [[thread_position_in_grid]])</span><br><span class="line">&#123;</span><br><span class="line">    int size = blurKernel.get_width(); int radius = size / 2;</span><br><span class="line">    float4 accumColor(0, 0, 0, 0); for(intj=0;j&lt;size;++j) </span><br><span class="line">    &#123;</span><br><span class="line">        for(inti=0;i&lt;size;++i) </span><br><span class="line">        &#123;</span><br><span class="line">            uint2 kernelIndex(i, j);</span><br><span class="line">            uint2 textureIndex(gid.x + (i - radius), gid.y + (j - radius)); float4 color = inTexture.read(textureIndex).rgba;</span><br><span class="line">            float4 weight = weights.read(kernelIndex).rrrr;</span><br><span class="line">            accumColor += weight * color;</span><br><span class="line">        &#125; </span><br><span class="line">    &#125;</span><br><span class="line">    outTexture.write(float4(accumColor.rgb, 1), gid); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="The-Filter-Class-过滤类"><a href="#The-Filter-Class-过滤类" class="headerlink" title="The Filter Class(过滤类)"></a>The Filter Class(过滤类)</h4><p>模糊过滤器类<code>MBEGaussianBlur2DFilter</code>派生自图像过滤器基类。它的<code>-configureArgumentTableWithCommandEncoder:</code>的实现：懒惰地生成模糊权重并将命令编码器上的查找表纹理设置为第三个参数（参数表索引2）。</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">- (<span class="keyword">void</span>)configureArgumentTableWithCommandEncoder: (<span class="keyword">id</span>&lt;<span class="built_in">MTLComputeCommandEncoder</span>&gt;)commandEncoder</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (!<span class="keyword">self</span>.blurWeightTexture) </span><br><span class="line">    &#123;</span><br><span class="line">        [<span class="keyword">self</span> generateBlurWeightTexture]; </span><br><span class="line">    &#125;</span><br><span class="line">    [commandEncoder setTexture:<span class="keyword">self</span>.blurWeightTexture atIndex:<span class="number">2</span>]; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>-generateBlurWeightTexture</code>方法使用上面的2D标准分布公式计算适当大小的权重矩阵，并将值复制到Metal纹理中。</p><p>这完成了我们对高斯模糊滤镜类和着色器的实现。现在我们需要讨论如何将滤镜链接在一起并将最终图像输出到屏幕上。</p><h3 id="Chaining-Image-Filters-链接图像过滤器"><a href="#Chaining-Image-Filters-链接图像过滤器" class="headerlink" title="Chaining Image Filters(链接图像过滤器)"></a>Chaining Image Filters(链接图像过滤器)</h3><p>再次考虑本章开头的代码：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">context = [MBEContext newContext]; imageProvider = [MBEMainBundleTextureProvider</span><br><span class="line">textureProviderWithImageNamed:<span class="string">@"mandrill"</span> context:context];</span><br><span class="line">desaturateFilter = [MBESaturationAdjustmentFilter filterWithSaturationFactor:<span class="number">0.75</span></span><br><span class="line">context:context];</span><br><span class="line">desaturateFilter.provider = <span class="keyword">self</span>.imageProvider; </span><br><span class="line">blurFilter = [MBEGaussianBlur2DFilter filterWithRadius:<span class="number">0.0</span> context:context];</span><br><span class="line">blurFilter.provider = desaturateFilter;</span><br><span class="line">imageView.image = [<span class="built_in">UIImage</span> imageWithMTLTexture:blurFilter.texture];</span><br></pre></td></tr></table></figure><p>主捆绑图像提供程序是一个实用程序，用于将图像加载到Metal纹理中，并充当链的开头。它被设置为去饱和度过滤器的纹理提供者，后者又被设置为模糊过滤器的纹理提供者。</p><p>请求模糊滤镜的纹理实际上是将图像滤镜处理设置为运动的原因。这会导致模糊滤镜请求去饱和过滤器的纹理，这反过来会导致去饱和内核同步调度。一旦完成，模糊滤镜将去饱和纹理作为输入并调度其自己的内核函数。</p><p>现在我们已经过滤了图像，我们可以使用它来渲染带有Metal的纹理四边形（或其他表面）。假设我们想用UIKit显示它？我们如何从UIImage创建Metal纹理，而不是从Metal纹理创建UIImage？</p><h3 id="Creating-a-UIImage-from-a-Texture-从纹理创建UIImage"><a href="#Creating-a-UIImage-from-a-Texture-从纹理创建UIImage" class="headerlink" title="Creating a UIImage from a Texture(从纹理创建UIImage)"></a>Creating a UIImage from a Texture(从纹理创建UIImage)</h3><p>最有效的方法是使用Core Graphics中的图像实用程序。首先，创建一个临时缓冲区，其中读取Metal纹理的像素数据。可以使用CGDataProviderRef包装此缓冲区，然后使用CGDataProviderRef创建CGImageRef。然后我们可以创建一个包装此CGImageRef的UIImage实例。</p><p>示例代码在UIImage上实现了一个类别，该类别在名为<code>+imageWithMTLTexture:</code>的方法中执行所有这些操作。为简洁起见，此处不包含此内容，但它有助于阅读。</p><p>值得一提的是，这不是在屏幕上获取过滤图像的最有效方法。从纹理创建图像使用额外的内存，占用CPU时间，并要求Core Animation合成器将图像数据复制回纹理以供显示。所有这些都是昂贵的，并且在许多情况下可以避免。幸运的是，在本书的整个过程中，我们已经看到很多方法可以使用不涉及UIKit的纹理。</p><h4 id="Driving-Image-Processing-Asynchronously-异步驱动图像处理"><a href="#Driving-Image-Processing-Asynchronously-异步驱动图像处理" class="headerlink" title="Driving Image Processing Asynchronously(异步驱动图像处理)"></a>Driving Image Processing Asynchronously(异步驱动图像处理)</h4><p>上面，我们提到过滤器同步调度它们的内核函数。由于图像处理是计算密集型的，我们需要一种在背景线程上进行工作的方法，以保持用户界面的响应。</p><p>将命令缓冲区提交到命令队列本质上是线程安全的，但是控制并发的其他方面是程序员的责任。</p><p>幸运的是，Grand Central Dispatch使我们的工作变得轻松。由于我们只会在主线程上响应用户操作而使用图像过滤器，因此我们可以使用一对<code>dispatch_async</code>调用将我们的图像处理工作重定位到后台线程上，异步更新主线程上的图像视图过滤器的处理完成。</p><p>我们将在视图控制器上以原子64位整数属性的形式使用粗互斥，每次请求更新时都会递增。该计数器的值由入队的块捕获。如果块在后台队列上执行时尚未发生另一个用户事件，则允许执行图像过滤器，并刷新UI。</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">- (<span class="keyword">void</span>)updateImage &#123;</span><br><span class="line">    ++<span class="keyword">self</span>.jobIndex;</span><br><span class="line">    uint64_t currentJobIndex = <span class="keyword">self</span>.jobIndex;</span><br><span class="line">    <span class="keyword">float</span> blurRadius = <span class="keyword">self</span>.blurRadiusSlider.value; </span><br><span class="line">    <span class="keyword">float</span> saturation = <span class="keyword">self</span>.saturationSlider.value;</span><br><span class="line">    <span class="built_in">dispatch_async</span>(<span class="keyword">self</span>.renderingQueue, ^&#123; </span><br><span class="line">        <span class="keyword">if</span> (currentJobIndex != <span class="keyword">self</span>.jobIndex)</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        <span class="keyword">self</span>.blurFilter.radius = blurRadius; <span class="keyword">self</span>.desaturateFilter.saturationFactor = saturation;</span><br><span class="line">        <span class="keyword">id</span>&lt;<span class="built_in">MTLTexture</span>&gt; texture = <span class="keyword">self</span>.blurFilter.texture; <span class="built_in">UIImage</span> *image = [<span class="built_in">UIImage</span> imageWithMTLTexture:texture];</span><br><span class="line">        <span class="built_in">dispatch_async</span>(dispatch_get_main_queue(), ^&#123; <span class="keyword">self</span>.imageView.image = image;</span><br><span class="line">        &#125;); </span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="The-Sample-Project-示例项目"><a href="#The-Sample-Project-示例项目" class="headerlink" title="The Sample Project(示例项目)"></a>The Sample Project(示例项目)</h3><p>本章的示例代码位于14-ImageProcessing目录中。</p><p>在本章中，我们采用了与Metal并行计算的后续步骤，并看到了几个可以在GPU上高效运行的图像过滤器示例。您现在可以使用此处提供的框架来创建自己的效果，并使用Metal的强大功能在GPU上高效运行它们。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在本章中，我们将开始使用Metal着色语言探索图像处理世界。我们将创建一个能够表示图像滤镜链的框架，然后编写一对图像滤镜，以便我们调整图像的饱和度和模糊度。最终结果将是一个交互式应用程序，允许您实时控制图像过滤器参数。&lt;/p&gt;
&lt;p&gt;图像处理是数据并行编程的主要应用之一。在许多情况下，图像滤波器仅需要查询源图像中的一个像素或小邻域像素以计算每个输出像素的值。在这种情况下，图像滤波器的工作可以以并行方式完成。这非常适合现代GPU架构，它使用许多小内核同时处理多个数据。&lt;/p&gt;
    
    </summary>
    
    
      <category term="iOS/Mac" scheme="https://zhaolilong.com/tags/iOS-Mac/"/>
    
      <category term="图形学" scheme="https://zhaolilong.com/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
      <category term="Metal" scheme="https://zhaolilong.com/tags/Metal/"/>
    
  </entry>
  
  <entry>
    <title>实例学习Metal-第十三章 介绍数据并行编程</title>
    <link href="https://zhaolilong.com/2020/03/29/%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0Metal-%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0/"/>
    <id>https://zhaolilong.com/2020/03/29/实例学习Metal-第十三章/</id>
    <published>2020-03-28T16:00:00.000Z</published>
    <updated>2020-03-13T03:06:58.793Z</updated>
    
    <content type="html"><![CDATA[<p>本章介绍了数据并行编程的主题，在GPU上完成时也称为计算编程（与图形编程相反，这是我们通常使用GPU执行的操作）。我们将介绍设置计算管道和并行处理大型数据集上的内核函数的基础知识。本章将作为下一章的设置，演示如何使用计算内核在GPU上进行图像处理。</p><a id="more"></a><h1 id="Chapter-13-第十三章"><a href="#Chapter-13-第十三章" class="headerlink" title="Chapter 13(第十三章)"></a>Chapter 13(第十三章)</h1><h2 id="Introduction-to-Data-Parallel-Programming-介绍数据并行编程"><a href="#Introduction-to-Data-Parallel-Programming-介绍数据并行编程" class="headerlink" title="Introduction to Data-Parallel Programming(介绍数据并行编程)"></a>Introduction to Data-Parallel Programming(介绍数据并行编程)</h2><p>本章介绍了数据并行编程的主题，在GPU上完成时也称为计算编程（与图形编程相反，这是我们通常使用GPU执行的操作）。我们将介绍设置计算管道和并行处理大型数据集上的内核函数的基础知识。本章将作为下一章的设置，演示如何使用计算内核在GPU上进行图像处理。</p><h3 id="Kenel-Functions-内核函数"><a href="#Kenel-Functions-内核函数" class="headerlink" title="Kenel Functions(内核函数)"></a>Kenel Functions(内核函数)</h3><p>在本书中，我们广泛使用了顶点和片段函数。在本章中，我们介绍一种新的着色器函数：内核函数。内核函数允许我们构建大规模并行程序，这些程序可以同时处理多个数据。我们将交替使用术语“内核函数”，“计算内核”和“计算着色器”。</p><p>在着色器源中通过为内核限定符添加前缀来标识内核函数，就像我们使用<code>顶点</code>或<code>片段</code>为其他类型的函数添加前缀一样。这些类型的函数之间的一个区别是内核函数<code>必须</code>返回void。这是因为内核函数对缓冲区和纹理进行操作，而不是像顶点和片段函数那样将数据提供给其他管道阶段。</p><p>以下代码段是内核函数签名的示例。稍后将详细讨论此函数签名中引入的新属性。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kernel void kernel_function(</span><br><span class="line">texture2d&lt;float, access::read&gt; inTexture [[texture(0)]], texture2d&lt;float, access::write&gt; outTexture [[texture(1)]], uint2 gid [[thread_position_in_grid]]);</span><br></pre></td></tr></table></figure><h3 id="The-Compute-Pipeline-计算管道"><a href="#The-Compute-Pipeline-计算管道" class="headerlink" title="The Compute Pipeline(计算管道)"></a>The Compute Pipeline(计算管道)</h3><p>构建计算管道类似于为我们的3D渲染工作构建渲染管道。我们创建一个上下文对象来保存各种Metal对象，而不是渲染器类。</p><h4 id="The-Context-Class-上下文类"><a href="#The-Context-Class-上下文类" class="headerlink" title="The Context Class(上下文类)"></a>The Context Class(上下文类)</h4><p>上下文包装了设备，库和命令队列，因为它们是长期存在的对象，将由我们创建的各种内核类引用。</p><p>上下文类有一个非常简单的接口。调用<code>+newContext</code>工厂方法将返回具有系统默认设备的上下文。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">@interface MBEContext : NSObject</span><br><span class="line">@property (strong) id&lt;MTLDevice&gt; device;</span><br><span class="line">@property (strong) id&lt;MTLLibrary&gt; library; @property (strong) id&lt;MTLCommandQueue&gt; commandQueue;</span><br><span class="line">+ (instancetype)newContext; @end</span><br></pre></td></tr></table></figure><p>每个上下文有一个串行命令队列。这允许我们序列化工作项，例如可能在它们之间具有数据依赖性的图像过滤器。</p><h4 id="Creating-a-Pipeline-State-创建管道状态"><a href="#Creating-a-Pipeline-State-创建管道状态" class="headerlink" title="Creating a Pipeline State(创建管道状态)"></a>Creating a Pipeline State(创建管道状态)</h4><p>构建用于执行内核函数的管道状态比创建渲染管道要简单一些。没有与计算管道的MTLRenderPipelineDescriptor等效，因为计算管道的唯一可配置部分是其关联的内核函数。</p><p>与顶点和片段函数一样，内核函数通过库中的名称检索：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[library newFunctionWithName:@&quot;kernel_function&quot;];</span><br></pre></td></tr></table></figure><p>然后通过从设备请求计算管道状态对象来创建计算管道。如果在为目标硬件编译内核函数时发生错误，则会将错误分配给error参数，并返回nil。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">id&lt;MTLComputePipelineState&gt; pipeline = [device newComputePipelineStateWithFunction:kernelFunction error:&amp;error];</span><br></pre></td></tr></table></figure><h4 id="Creating-a-Command-Buffer-and-Command-Encoder-创建命令缓冲区和命令编码器"><a href="#Creating-a-Command-Buffer-and-Command-Encoder-创建命令缓冲区和命令编码器" class="headerlink" title="Creating a Command Buffer and Command Encoder(创建命令缓冲区和命令编码器)"></a>Creating a Command Buffer and Command Encoder(创建命令缓冲区和命令编码器)</h4><p>正如我们使用渲染命令编码器将绘制调用编码到命令缓冲区中一样，我们使用新类型的命令编码器来执行内核函数：MTLComputeCommandEncoder。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">id&lt;MTLCommandBuffer&gt; commandBuffer = [context.commandQueue commandBuffer]; id&lt;MTLComputeCommandEncoder&gt; commandEncoder =</span><br><span class="line">[commandBuffer computeCommandEncoder];</span><br></pre></td></tr></table></figure><p>但是，在将工作发送到GPU之前，我们需要了解如何配置计算命令编码器的参数表以及如何描述我们希望GPU执行的工作。</p><h4 id="The-Argument-Table-参数表"><a href="#The-Argument-Table-参数表" class="headerlink" title="The Argument Table(参数表)"></a>The Argument Table(参数表)</h4><p>我们之前使用参数表来指定哪些缓冲区，纹理和采样器状态绑定到顶点和片段函数的参数。</p><p>例如，我们通过在渲染命令编码器上调用<code>-setFragmentTexture:atIndex:</code>方法来配置片段着色器的参数。回想一下，索引参数将参数表中的条目与片段函数的签名中具有相应属性（例如，<code>[[texture（0）]]</code>）的参数匹配。<br>设置计算编码器的参数表有类似的方法：<code>-setTexture:atIndex:</code>。在准备执行内核函数时，我们将使用此方法设置参数表。</p><h4 id="Threadgroups-线程组"><a href="#Threadgroups-线程组" class="headerlink" title="Threadgroups(线程组)"></a>Threadgroups(线程组)</h4><p>线程组是Metal内核函数编程的核心概念。为了并行执行，必须将每个工作负载分解为称为线程组的块，这些块可以进一步划分并分配给GPU上的线程池。</p><p>为了有效运行，GPU不会调度单个线程。相反，它们被安排成套（有时称为“warp”或“wavefronts”，尽管Metal文档不使用这些术语）。线程执行宽度表示此执行单元的大小。这是实际计划在GPU上并发运行的线程数。您可以使用其<code>threadExecutionWidth</code>属性从命令编码器查询此值。它可能是2的小功率，例如32或64。</p><p>我们还可以通过查询<code>maxTotalThreadsPerThreadgroup</code>来确定线程组大小的上限。此数字始终是线程执行宽度的倍数。例如，在iPhone 6上它是512。</p><p>为了最有效地使用GPU，线程组中的项目总数应该是线程执行宽度的倍数，并且必须低于每个线程组的最大总线程数。这通知我们如何选择细分输入数据以实现最快和最方便的执行。</p><p>线程组不必是一维的。通常，线程组的尺寸与正在操作的数据的尺寸相匹配是很方便的。例如，当在2D图像上操作时，每个块通常将是源纹理的矩形区域。下图显示了如何选择将纹理细分为线程组。</p><p><img src="/2020/03/29/实例学习Metal-第十三章/1584068791.png" alt=""></p><center>图13.1：要处理的图像被划分为多个线程组，此处用白色方块表示。</center><p>为了告诉Metal每个线程组的维度以及在给定的计算调用中应该执行多少个线程组，我们创建了一对MTLSize结构：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">MTLSize</span> threadgroupCounts = <span class="built_in">MTLSizeMake</span>(<span class="number">8</span>, <span class="number">8</span>, <span class="number">1</span>);</span><br><span class="line"><span class="built_in">MTLSize</span> threadgroups = <span class="built_in">MTLSizeMake</span>([texture width] / threadgroupCounts.width,</span><br><span class="line">[texture height] / threadgroupCounts.height, <span class="number">1</span>);</span><br></pre></td></tr></table></figure><p>在这里，我们有点随意选择8行8列的线程组大小，或者每个线程组总共64个项目。我们假设这个代码处理的纹理的维度是8的倍数，这通常是一个安全的选择。总线程组大小是目标硬件线程执行宽度的偶数倍，并且安全地低于最大总线程数。如果纹理尺寸不能被我们的线程组大小整除，我们需要在内核函数中采取措施，不要在纹理边界之外读取或写入。</p><p>既然在我们已经确定了线程组的大小以及我们需要执行多少线程组，现在我们已经准备好让GPU工作了。</p><h4 id="Dispatching-Threadgroups-for-Execution-调度线程组以执行"><a href="#Dispatching-Threadgroups-for-Execution-调度线程组以执行" class="headerlink" title="Dispatching Threadgroups for Execution(调度线程组以执行)"></a>Dispatching Threadgroups for Execution(调度线程组以执行)</h4><p>编码命令来对一组数据执行内核函数称为<code>调度</code>。一旦我们引用了一个计算命令编码器，我们就可以调用它的<code>-dispatchThreadgroups:threadsPerThreadgroup:</code>方法对执行请求进行编码，传递我们之前计算过的MTLSize结构。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[commandEncoder dispatchThreadgroups:threadgroups threadsPerThreadgroup:threadgroupCounts];</span><br></pre></td></tr></table></figure><p>一旦完成调度，我们告诉命令编码器endEncoding，然后提交相应的命令缓冲区。然后我们可以在命令缓冲区上使用<code>-waitUntilCompleted</code>方法来阻止，直到着色器在GPU上运行完毕。每个数据项将执行一次内核函数（例如，源纹理中每个纹素一次）。</p><h3 id="Conclusion-结论"><a href="#Conclusion-结论" class="headerlink" title="Conclusion(结论)"></a>Conclusion(结论)</h3><p>在这个简短的章节中，我们为讨论Metal中的高性能图像滤波以及数据并行编程的其他应用奠定了基础。在下一章中，我们将在Metal中应用数据并行编程来解决图像处理中的一些有趣问题。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本章介绍了数据并行编程的主题，在GPU上完成时也称为计算编程（与图形编程相反，这是我们通常使用GPU执行的操作）。我们将介绍设置计算管道和并行处理大型数据集上的内核函数的基础知识。本章将作为下一章的设置，演示如何使用计算内核在GPU上进行图像处理。&lt;/p&gt;
    
    </summary>
    
    
      <category term="iOS/Mac" scheme="https://zhaolilong.com/tags/iOS-Mac/"/>
    
      <category term="图形学" scheme="https://zhaolilong.com/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
      <category term="Metal" scheme="https://zhaolilong.com/tags/Metal/"/>
    
  </entry>
  
  <entry>
    <title>实例学习Metal-第十二章 渲染文本</title>
    <link href="https://zhaolilong.com/2020/03/22/%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0Metal-%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0/"/>
    <id>https://zhaolilong.com/2020/03/22/实例学习Metal-第十二章/</id>
    <published>2020-03-21T16:00:00.000Z</published>
    <updated>2020-03-13T03:02:13.506Z</updated>
    
    <content type="html"><![CDATA[<p>在本章中，我们将讨论使用Metal渲染高保真文本的方法。在考虑3D图形时，很容易忽略文本渲染。但是，很少有游戏或应用程序可以在不显示任何文本的情况下使用，因此考虑如何最好地使用GPU将文本合并到我们的Metal应用程序中非常重要。</p><a id="more"></a><h1 id="Chapter-12-第十二章"><a href="#Chapter-12-第十二章" class="headerlink" title="Chapter 12(第十二章)"></a>Chapter 12(第十二章)</h1><h2 id="Rendering-Text-渲染文本"><a href="#Rendering-Text-渲染文本" class="headerlink" title="Rendering Text(渲染文本)"></a>Rendering Text(渲染文本)</h2><p>在本章中，我们将讨论使用Metal渲染高保真文本的方法。在考虑3D图形时，很容易忽略文本渲染。但是，很少有游戏或应用程序可以在不显示任何文本的情况下使用，因此考虑如何最好地使用GPU将文本合并到我们的Metal应用程序中非常重要。</p><p><img src="/2020/03/22/实例学习Metal-第十二章/1584067620.png" alt=""></p><center>图12.1：示例应用程序使用signed-distance字段技术呈现的文本<center><h4 id="The-Structure-and-Interpretation-of-Fonts-字体的结构与解释"><a href="#The-Structure-and-Interpretation-of-Fonts-字体的结构与解释" class="headerlink" title="The Structure and Interpretation of Fonts(字体的结构与解释)"></a>The Structure and Interpretation of Fonts(字体的结构与解释)</h4><p>我们通过选择<code>字体</code>开始绘制文本的过程。字体是字形的集合，字形是字符或字符部分的图形表示。在现代字体格式中，字形表示为分段曲线，特别是线段和二次贝塞尔曲线。</p><p><img src="/2020/03/22/实例学习Metal-第十二章/1584067651.png" alt=""></p><center>图12.2：来自Verdana的'g'字形，显示了如何构造字形的二次Beziér曲线</center><p>绘制一串文本至少包含两个不同的阶段。首先，<code>文本布局引擎</code>确定将使用哪些字形来表示字符串以及它们如何相对于彼此定位。然后，渲染引擎负责将字形的抽象描述转换为屏幕上的文本。</p><h3 id="Approaches-to-Real-Time-Text-Rendering-实时文本渲染的方法"><a href="#Approaches-to-Real-Time-Text-Rendering-实时文本渲染的方法" class="headerlink" title="Approaches to Real-Time Text Rendering(实时文本渲染的方法)"></a>Approaches to Real-Time Text Rendering(实时文本渲染的方法)</h3><p>您可以通过多种方式在iOS上呈现文本。您可能熟悉UIKit控件，如UILabel和UITextField。这些UI元素由叫作Core Text的强大框架支持。 Core Text是一种Unicode文本布局引擎，它与Quartz 2D（Core Graphics）紧密集成，可以布局和渲染文本。</p><p>文本布局是一个非常复杂的主题，必须考虑到不同的脚本，书写方向和印刷约定。我们永远不会想要自己重新发明这个功能，因此我们会让Core Text在我们的实时文本渲染解决方案中付出沉重的代价。</p><p>让我们简要介绍一下在实时3D图形环境中绘制文本的常用方法。</p><h4 id="Dynamic-Rasterization-动态光栅化"><a href="#Dynamic-Rasterization-动态光栅化" class="headerlink" title="Dynamic Rasterization(动态光栅化)"></a>Dynamic Rasterization(动态光栅化)</h4><p>文本渲染最灵活的方法之一是动态光栅化，其中字符串在CPU上进行光栅化，并将生成的位图作为纹理上载到GPU进行绘制。这是<code>stb_truetype</code>等库采用的方法(Bar-rett 2014)。</p><p>动态光栅化的缺点是每当文本字符串改变时重新绘制字形的计算成本。即使文本渲染的大部分成本发生在布局阶段，光栅化字形对CPU的需求也是非常重要的，并且iOS上没有现有的字体光栅化GPU实现。此技术还需要一定量的纹理内存，与字体大小和正在呈现的字符串的长度成比例。最后，放大时，光栅化文本会变得模糊或模糊，具体取决于放大滤镜。</p><h4 id="Font-Atlases-字体地图集"><a href="#Font-Atlases-字体地图集" class="headerlink" title="Font Atlases(字体地图集)"></a>Font Atlases(字体地图集)</h4><p>许多使用GPU绘制文本的应用程序更喜欢预先渲染所有可能的字形而不是动态绘制它们。这种方法根据纹理内存进行折衷，以获得按需栅格化字形的计算成本。为了最小化字体所需的纹理内存量，字形被打包成单个矩形纹理，称为图集。下图说明了这种纹理。</p><p><img src="/2020/03/22/实例学习Metal-第十二章/1584067674.png" alt=""></p><center> 图 12.3：一个字体地图集</center><p>辅助数据结构存储描述每个字形的边界矩形的纹理坐标。绘制字符串时，应用程序会生成一个网格，其中包含字符串构成字形的适当位置和纹理坐标。</p><p><img src="/2020/03/22/实例学习Metal-第十二章/1584067697.png" alt=""></p><center>图12.4：为文本字符串中的每个字形生成一对三角形</center><p>字体图集的一个缺点是，即使它们包含的许多字形在运行时都没有使用，它们也会占用大量的内存。</p><p>与动态光栅化一样，使用图集纹理渲染的文本在放大时会受到失去的影响。这里，问题可能更糟，因为字形通常被绘制得更小以便将整个字体打包成一个纹理。</p><p>在下一节中，我们将寻求纠正一些基于天真地图集的文本渲染问题。</p><h4 id="Signed-Distance-Fields-签名距离字段"><a href="#Signed-Distance-Fields-签名距离字段" class="headerlink" title="Signed-Distance Fields(签名距离字段)"></a>Signed-Distance Fields(签名距离字段)</h4><p>我们将深入探索的方法使用有符号距离字段，该字段是字体图集的预先表示，其隐式存储字形轮廓。具体地，有符号距离场纹理的纹理元素值对应于纹素与最近的字形边缘的距离，其中字形外的纹素采用负值。</p><p><img src="/2020/03/22/实例学习Metal-第十二章/1584067721.png" alt=""></p><center>图12.5：从字体图集生成的带符号距离字段。最亮的像素是最里面的。</center><p>为了在纹理中存储有符号距离字段，必须对其进行缩放和量化以匹配像素格式。我们的示例项目使用单通道8位纹理，每像素占一个字节。通过这种结构，恰好落在字形边缘的纹素的值为127或50％。</p><p>在其最简单的化身中，可以使用固定功能alpha测试来完成符号距离场渲染。通过丢弃其值小于50％的所有片段，将仅渲染字形内的那些像素。不幸的是，这会产生沿着字形边缘产生“摆动”的效果，因为下采样和量化的距离纹理不能捕获足够的细节来完美地重建理想的轮廓。</p><p>对alpha测试技术的改进是使用像素着色器在字形的内部和外部之间进行插值，从而平滑摆动的不连续性。这将在下面详细描述。</p><p>签名距离场渲染由Valve的Green Green（Green 2007）引入主流，描述了该技术在热门游戏Team Fortress 2中的使用。我们的实施将严格遵循Green的论文中提出的方案。</p><h4 id="Signed-Distance-Field-Rendering-in-Metal-Metal中的符号距离场渲染"><a href="#Signed-Distance-Field-Rendering-in-Metal-Metal中的符号距离场渲染" class="headerlink" title="Signed-Distance Field Rendering in Metal(Metal中的符号距离场渲染)"></a>Signed-Distance Field Rendering in Metal(Metal中的符号距离场渲染)</h4><p>在本节中，我们将详细描述使用Metal在GPU上实现平滑文本渲染的方法。</p><h4 id="Generating-a-Font-Atlas-Texture-生成字体图集纹理）"><a href="#Generating-a-Font-Atlas-Texture-生成字体图集纹理）" class="headerlink" title="Generating a Font Atlas Texture(生成字体图集纹理）"></a>Generating a Font Atlas Texture(生成字体图集纹理）</h4><p>第一步是将我们选择的字体中的所有可用字形呈现为图集。在示例代码中，不使用最佳打包;相反，字形只是从左到右排列，以贪婪的方式从上到下包裹线条。这大大简化了实施，代价是浪费了一些空间。</p><p>示例代码通过确定所选字体的最大大小来构建来自UIFont的字体图集，其字形将完全适合用于构建图集（4096×4096像素）的位图。然后，它使用Core Text从字体中检索字形轮廓，并在没有抗锯齿的情况下将它们渲染到地图集图像中。</p><p>在绘制字体图集时，实现还将每个字形的原点和范围（即纹理坐标）存储在单独的数组中。在渲染期间使用此数组从布局的字形映射到atlas纹理上的相应区域。</p><h4 id="Generating-a-Signed-Distance-Field-生成有符号距离场"><a href="#Generating-a-Signed-Distance-Field-生成有符号距离场" class="headerlink" title="Generating a Signed-Distance Field(生成有符号距离场)"></a>Generating a Signed-Distance Field(生成有符号距离场)</h4><p>上述过程以相当高的分辨率生成字体的二进制图像。也就是说，落入字形内部的像素一直是“开启”（255），而字形外部的像素一直都是“关闭”（0）。我们现在需要对此位图执行带符号距离变换，以生成字体图集的带符号距离字段表示，我们将使用它来进行渲染。</p><h4 id="A-Brute-Force-Approach-蛮力方法"><a href="#A-Brute-Force-Approach-蛮力方法" class="headerlink" title="A Brute Force Approach(蛮力方法)"></a>A Brute Force Approach(蛮力方法)</h4><p>生成有符号距离字段需要找到从每个纹素到最近的字形边缘的距离。某些实现（例如GLyphy（Esfahbod 2014））直接针对字形的分段曲线表示执行此计算。这种方法可以具有惊人的保真度，但实施起来很复杂，充满了边缘情况。</p><p>由于我们已选择生成字体的位图表示，因此我们可以简单地在每个纹素的邻域上进行操作，在我们处理边缘另一侧的纹素时执行最小化搜索。为了达到易处理性，这要求我们选择一个合理大小的区域来进行搜索。</p><p>合理的启发式是字体平均笔划宽度的一半。例如，在典型笔画为20像素宽的字体中，在字形内到目前为止它们具有大于10的距离的纹素已经将在渲染期间被钳位到“内部”的最大值。类似地，在字形外部距离大于10的纹素不太可能影响字形的呈现方式。因此，我们将对每个纹素周围的10 x 10邻域进行搜索。</p><p>根据Green的说法，蛮力方法适用于在生产中使用的工作站类别上为文本和矢量图形创建距离场。<br>TF2。然而，由于对签名距离场生成进行了大量研究，让我们看一下稍微好一点的方法，即使在移动硬件上也能让我们快速生成它们。</p><h4 id="A-Better-Approach-Dead-Reckoning-更好的方法：航位推算法"><a href="#A-Better-Approach-Dead-Reckoning-更好的方法：航位推算法" class="headerlink" title="A Better Approach: Dead Reckoning(更好的方法：航位推算法)"></a>A Better Approach: Dead Reckoning(更好的方法：航位推算法)</h4><p>有符号距离场具有广泛的适用性，因此成为许多研究的主题。 G. J. Grevera，建立在一个名为cham-的古老的算法倒角距离算法的基础之上，构造了一种更精确的启发式方法，称为“航位推算”（Grevera 2004）。实质上，该算法在源图像上执行两次传递，首先向下和向右传播最小距离，然后将第一次传递中发现的最小距离传播回到左侧。在每个步骤中，距离值被确定为围绕中心纹理元素的一些掩模上的最小距离值加上沿着矢量到最近的先前发现边缘的距离。</p><p>在不深入研究该算法的所有细节的情况下，值得注意的是它比蛮力方法快得多。在两次传球中，航位推算都只能得到3x3纹素的邻域，远远低于类似精度的蛮力算法。虽然我们还没有使用计算着色器实现它，但我们强烈怀疑它可以通过基于GPU的实现更快地制作。</p><h4 id="使用核心文本进行布局"><a href="#使用核心文本进行布局" class="headerlink" title="使用核心文本进行布局"></a>使用核心文本进行布局</h4><p>一旦我们有了字体的有符号距离字段表示，我们需要一种在屏幕上呈现其字形的方法。此过程的第一部分再次使用Core Text布局引擎告诉我们应该呈现哪些字形以及它们应该如何定位。我们使用CTFramesetter对象在所选矩形中布局文本。框架设置过程生成一个CTLine对象数组，每个对象包含一系列字形。有关这些类的其他详细信息，请参阅Core Text参考。</p><p>为了构造用于使用Metal渲染的文本网格，我们枚举了Core Text框架设置提供的字形，它为我们提供了屏幕空间坐标和我们在构建字体图集纹理时先前构建的纹理坐标表的索引。这两个数据允许我们创建一个表示文本字符串的索引三角形网格。然后可以以通常的方式渲染该网格，片段着色器对从每个像素的有符号距离场纹理转换为适当的颜色进行繁重的提升。</p><h4 id="The-Orthographic-Projection-正投影"><a href="#The-Orthographic-Projection-正投影" class="headerlink" title="The Orthographic Projection(正投影)"></a>The Orthographic Projection(正投影)</h4><p>在屏幕上绘制文本时，我们使用<code>正交投影</code>或<code>平行投影</code>。这种投影使网格平行于屏幕平面，而不会引入透视投影中固有的缩短。</p><p>渲染UI元素时，可以方便地选择其范围与视图尺寸匹配的正交投影。因此，示例应用程序使用的正交投影使用（0,0）作为屏幕的左上角和屏幕的可绘制宽度和高度（以像素为单位）作为右下角，与UIKit的约定相匹配。</p><p>在数学上，这种转换由以下矩阵表示：</p><p>$$<br> \left[<br> \begin{matrix}<br>   2\over r-l &amp; 0 &amp; 0 &amp; r+l \over l-r \<br>   0 &amp; 2\over t-b &amp; 0 &amp; t+b \over b-t \<br>   0 &amp; 0 &amp; 1\over f-n &amp; n \over f-n \<br>   0 &amp; 0 &amp; 0 &amp; 1<br>  \end{matrix}<br>  \right]<br>$$</p><p>这里l，r，t，b，n和f是左，右，上，下，近和远剪裁平面值。在我们的实现中，假设近平面和远平面分别位于z = 0和z = 1。</p><h4 id="The-Vertex-and-Fragment-Functions-顶点和片段函数"><a href="#The-Vertex-and-Fragment-Functions-顶点和片段函数" class="headerlink" title="The Vertex and Fragment Functions(顶点和片段函数)"></a>The Vertex and Fragment Functions(顶点和片段函数)</h4><p>绘制文本的顶点函数非常简单;它看起来与我们过去使用的顶点函数完全一样。文本网格的每个顶点由模型矩阵（可用于定位和缩放文本）和组合的视图 - 投影矩阵变换，该矩阵简单地是上面讨论的正交投影矩阵。</p><p>另一方面，片段函数涉及更多。由于我们正在使用带符号距离字段作为查找表而不是纹理，我们需要将场中的采样纹理像素转换为颜色值，该颜色值根据像素与相应字形边缘的接近度而变化。</p><p>我们在字形的边缘应用抗锯齿，通过在边缘周围的窄带中从不透明到半透明插值。通过使用内置的<code>dfdx</code>和<code>dfdy</code>函数找到距离场的梯度的长度，每个像素计算该带的宽度。然后我们使用smoothstep函数，它从0过渡到1这个平滑边缘的宽度，使用采样距离值本身作为最终参数。无论文本放大或缩小多少，这都会产生大约一个像素宽的边带。 Green对原始方法的改进归功于Gustavson（Gustavson 2012）。</p><p>以下是用于从有符号距离字段表示中呈现字形的完整片段函数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">float edgeDistance = 0.5;</span><br><span class="line">float dist = texture.sample(samp, vert.texCoords).r;</span><br><span class="line">float edgeWidth = 0.7 * length(float2(dfdx(dist), dfdy(dist))); </span><br><span class="line">float opacity = smoothstep(edgeDistance - edgeWidth, edgeDistance + edgeWidth, dist);</span><br><span class="line">return half4(textColor.r, textColor.g, textColor.b, opacity);</span><br></pre></td></tr></table></figure><p>请注意，我们返回一个具有alpha分量的颜色，因此我们使用的管道状态应启用Alpha混合，以便文本与其后面的几何图形正确混合。这也意味着应该在场景几何的其余部分之后绘制文本。</p><h3 id="The-Sample-App-示例应用"><a href="#The-Sample-App-示例应用" class="headerlink" title="The Sample App(示例应用)"></a>The Sample App(示例应用)</h3><p>本章的示例代码位于12-TextRendering目录中。</p><p>本章的示例应用程序呈现了一段可以实时缩放和平移的文本。使用一对UIGestureRecognizers实现交互。更确切地说，即使在极端放大率下，字形的边缘仍然保持非常清晰，这与预光栅化的位图纹理在放大下会变得锯齿状或模糊的方式形成对比。</p></center></center>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在本章中，我们将讨论使用Metal渲染高保真文本的方法。在考虑3D图形时，很容易忽略文本渲染。但是，很少有游戏或应用程序可以在不显示任何文本的情况下使用，因此考虑如何最好地使用GPU将文本合并到我们的Metal应用程序中非常重要。&lt;/p&gt;
    
    </summary>
    
    
      <category term="iOS/Mac" scheme="https://zhaolilong.com/tags/iOS-Mac/"/>
    
      <category term="图形学" scheme="https://zhaolilong.com/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
      <category term="Metal" scheme="https://zhaolilong.com/tags/Metal/"/>
    
  </entry>
  
  <entry>
    <title>实例学习Metal-第十一章 实例渲染</title>
    <link href="https://zhaolilong.com/2020/03/15/%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0Metal-%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0/"/>
    <id>https://zhaolilong.com/2020/03/15/实例学习Metal-第十一章/</id>
    <published>2020-03-14T16:00:00.000Z</published>
    <updated>2020-03-13T02:43:22.103Z</updated>
    
    <content type="html"><![CDATA[<p>在本章中，我们将讨论一种通过单个绘制调用有效绘制许多对象的重要技术：实例渲染。此技术可帮助您充分利用GPU，同时将内存和CPU使用率降至最低。</p><p>本章的示例应用程序呈现了数十个动画奶牛在顶部移动随机生成的地形补丁。每头奶牛都有自己的位置，方向和运动方向，所有这些都在每一帧都更新。我们只用两次绘制调用来完成所有这些绘图。该应用程序仅消耗A8处理器上CPU的百分之几，但最大化GPU，每帧绘制超过240,000个三角形。即使有这么大的负载，这样的设备也能够以理想的每秒60帧的速度渲染。</p><a id="more"></a><h1 id="Chapter11-第11章"><a href="#Chapter11-第11章" class="headerlink" title="Chapter11(第11章)"></a>Chapter11(第11章)</h1><h2 id="Instanced-Rendering-实例渲染"><a href="#Instanced-Rendering-实例渲染" class="headerlink" title="Instanced Rendering(实例渲染)"></a>Instanced Rendering(实例渲染)</h2><p>在本章中，我们将讨论一种通过单个绘制调用有效绘制许多对象的重要技术：实例渲染。此技术可帮助您充分利用GPU，同时将内存和CPU使用率降至最低。</p><p>本章的示例应用程序呈现了数十个动画奶牛在顶部移动随机生成的地形补丁。每头奶牛都有自己的位置，方向和运动方向，所有这些都在每一帧都更新。我们只用两次绘制调用来完成所有这些绘图。该应用程序仅消耗A8处理器上CPU的百分之几，但最大化GPU，每帧绘制超过240,000个三角形。即使有这么大的负载，这样的设备也能够以理想的每秒60帧的速度渲染。</p><h3 id="What-is-Instanced-Rendering-什么是实例渲染？"><a href="#What-is-Instanced-Rendering-什么是实例渲染？" class="headerlink" title="What is Instanced Rendering?(什么是实例渲染？)"></a>What is Instanced Rendering?(什么是实例渲染？)</h3><p>虚拟世界经常在场景中拥有许多某些元素的副本：粒子，树叶，敌人等等。这些元素在内存中由单个几何体（网格）和一组特定于应用程序的属性表示。实例化渲染多次绘制相同的几何体，每个实例的属性用于控制它出现的位置和方式。</p><p>实例化渲染也称为“几何实例化”，“实例绘制”，或者有时只是“实例化”。</p><h4 id="Setting-the-Scene-设置场景"><a href="#Setting-the-Scene-设置场景" class="headerlink" title="Setting the Scene(设置场景)"></a>Setting the Scene(设置场景)</h4><p>这一章的虚拟场景是一个田园山坡，有许多流浪的牛。每次应用程序运行时，地形都是唯一生成的，每头牛都有自己的随机运动路径。</p><p><img src="/2020/03/15/实例学习Metal-第十一章/1584067202.png" alt=""></p><center>图11.1：使用实例化渲染可以有效地绘制数十个动画角色。 （草纹理由Simon Murray提供的goodtextures.com）</center><h4 id="Generating-the-Terrain-生成地形"><a href="#Generating-the-Terrain-生成地形" class="headerlink" title="Generating the Terrain(生成地形)"></a>Generating the Terrain(生成地形)</h4><p>地形的特征由称为中点位移的算法创建，也称为“菱形方形”算法。这是一种递归细分地形边缘的技术，并随机向上或向下轻推它们以产生看起来自然的山丘。由于本章的重点是实例绘图而非地形生成，如果您对此技术感到好奇，请参阅示例源代码（请参阅MBETerrainMesh类）。可以在线找到该技术的交互式演示（Boxley 2011）。</p><h4 id="Loading-the-Model-加载模型"><a href="#Loading-the-Model-加载模型" class="headerlink" title="Loading the Model(加载模型)"></a>Loading the Model(加载模型)</h4><p>我们使用前面章节中的OBJ模型加载器来加载牛模型。一旦我们在内存中有一个OBJ模型，我们就会从OBJ文件中的相应组创建一个MBEOBJMesh实例。</p><h4 id="Instanced-Rendering-实例渲染-1"><a href="#Instanced-Rendering-实例渲染-1" class="headerlink" title="Instanced Rendering(实例渲染)"></a>Instanced Rendering(实例渲染)</h4><p>通过发出绘制调用来执行实例渲染，该调用指定应该渲染几何的次数。为了使每个实例都有自己的属性，我们将包含每个实例数据的缓冲区设置为顶点着色器参数表中的缓冲区参数之一。我们还需要传入一个共享的统一缓冲区，它存储所有实例共享的制服。以下是配置用于渲染牛网格的完整参数表：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[commandEncoder setVertexBuffer:cowMesh.vertexBuffer offset:<span class="number">0</span> atIndex:<span class="number">0</span>]; </span><br><span class="line">[commandEncoder setVertexBuffer:sharedUniformBuffer offset:<span class="number">0</span> atIndex:<span class="number">1</span>]; </span><br><span class="line">[commandEncoder setVertexBuffer:cowUniformBuffer offset:<span class="number">0</span> atIndex:<span class="number">2</span>];</span><br></pre></td></tr></table></figure><p>现在让我们来看看我们如何在校园里布置制服。</p><h4 id="Storing-Per-Instance-Uniforms-存储每个实例统一量"><a href="#Storing-Per-Instance-Uniforms-存储每个实例统一量" class="headerlink" title="Storing Per-Instance Uniforms(存储每个实例统一量)"></a>Storing Per-Instance Uniforms(存储每个实例统一量)</h4><p>对于每个实例，我们需要一个唯一的模型矩阵和一个相应的正常矩阵。回想一下，常规矩阵用于将网格的法线转换为世界空间。我们还希望将投影矩阵本身存储在共享的统一缓冲区中。我们将Uniforms结构拆分为两个结构：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> </span><br><span class="line">&#123;</span><br><span class="line">    matrix_float4x4 viewProjectionMatrix; </span><br><span class="line">&#125; Uniforms;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> </span><br><span class="line">&#123;</span><br><span class="line">    matrix_float4x4 modelMatrix;</span><br><span class="line">    matrix_float3x3 normalMatrix; </span><br><span class="line">&#125; PerInstanceUniforms;</span><br></pre></td></tr></table></figure><p>共享统一量存储在Metal缓冲区中，该缓冲区可容纳Uniforms类型的单个实例。每个实例的制服缓冲区可以为我们想要呈现的每头牛的一个PerInstanceUniforms实例提供空间：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cowUniformBuffer = [device newBufferWithLength:<span class="keyword">sizeof</span>(PerInstanceUniforms) * MBECowCount</span><br><span class="line">options:<span class="built_in">MTLResourceOptionCPUCacheModeDefault</span>];</span><br></pre></td></tr></table></figure><h4 id="Updating-Per-Instance-Uniforms-更新每个实例统一量"><a href="#Updating-Per-Instance-Uniforms-更新每个实例统一量" class="headerlink" title="Updating Per-Instance Uniforms(更新每个实例统一量)"></a>Updating Per-Instance Uniforms(更新每个实例统一量)</h4><p>因为我们希望奶牛移动，所以我们在名为MBECow的数据模型中存储了一些简单的属性。每一帧，我们更新这些值以将奶牛移动到新位置并旋转它以使其与其行进方向对齐。</p><p>一旦奶牛对象是最新的，我们可以为每头奶牛生成适当的矩阵并将它们写入每个实例缓冲区，以便与下一个绘图调用一起使用：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">PerInstanceUniforms uniforms;</span><br><span class="line">uniforms.modelMatrix = matrix_multiply(translation, rotation); </span><br><span class="line">uniforms.normalMatrix = matrix_upper_left3x3(uniforms.modelMatrix);</span><br><span class="line"><span class="built_in">NSInteger</span> instanceUniformOffset = <span class="keyword">sizeof</span>(PerInstanceUniforms) * instanceIndex; </span><br><span class="line">memcpy([<span class="keyword">self</span>.cowUniformBuffer contents] + instanceUniformOffset, &amp;uniforms, <span class="keyword">sizeof</span>(PerInstanceUniforms));</span><br></pre></td></tr></table></figure><h4 id="Issuing-the-Draw-Call-发给绘制调用"><a href="#Issuing-the-Draw-Call-发给绘制调用" class="headerlink" title="Issuing the Draw Call(发给绘制调用)"></a>Issuing the Draw Call(发给绘制调用)</h4><p>要发给实例化绘图调用，我们在具有<code>instanceCount:</code>参数的渲染命令编码器上使用<code>-drawIndexedPrimitive:</code>方法。在这里，我们传递实例总数：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[commandEncoder drawIndexedPrimitives:<span class="built_in">MTLPrimitiveTypeTriangle</span>                                    indexCount:indexCount</span><br><span class="line">                            indexType:<span class="built_in">MTLIndexTypeUInt16</span></span><br><span class="line">                          indexBuffer:cowMesh.indexBuffer</span><br><span class="line">                    indexBufferOffset:<span class="number">0</span> </span><br><span class="line">                        instanceCount:MBECowCount];</span><br></pre></td></tr></table></figure><p>要执行此绘制调用，GPU将多次绘制网格，每次重复使用几何体。但是，我们需要一种在顶点着色器中获取适当矩阵集的方法，这样我们就可以将每头牛转换到它在世界中的位置。为此，我们来看看如何从顶点着色器中获取实例ID。</p><h4 id="Accessing-Per-Instance-Data-in-Shaders-访问着色器中的每实例数据"><a href="#Accessing-Per-Instance-Data-in-Shaders-访问着色器中的每实例数据" class="headerlink" title="Accessing Per-Instance Data in Shaders(访问着色器中的每实例数据)"></a>Accessing Per-Instance Data in Shaders(访问着色器中的每实例数据)</h4><p>要索引每个实例的统一缓冲区，我们使用instance_id属性添加顶点着色器参数。这告诉Metal我们希望它向我们传递一个参数，该参数表示当前正在绘制的实例的索引。然后我们可以在正确的偏移处访问每个实例的uniforms数组并提取适当的矩阵：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vertex ProjectedVertex vertex_project(device InVertex *vertices [[buffer(0)]], constant Uniforms &amp;uniforms [[buffer(1)]], constant PerInstanceUniforms *perInstanceUniforms [[buffer(2)]], ushort vid [[vertex_id]], ushort iid [[instance_id]]) </span><br><span class="line">&#123;</span><br><span class="line">    float4x4 instanceModelMatrix = perInstanceUniforms[iid].modelMatrix; </span><br><span class="line">    float3x3 instanceNormalMatrix = perInstanceUniforms[iid].normalMatrix;</span><br></pre></td></tr></table></figure><p>顶点着色器的其余部分很简单。它投影顶点，变换法线，并穿过纹理坐标。</p><h4 id="Going-Further-走得更远"><a href="#Going-Further-走得更远" class="headerlink" title="Going Further(走得更远)"></a>Going Further(走得更远)</h4><p>您可以在每个实例的统一结构中存储所需的任何类型的数据。例如，您可以为每个实例传递颜色，并使用它来唯一地着色每个对象。您可以包含纹理索引，并将索引编入纹理数组，以便为​​某些实例提供完全不同的视觉外观。您还可以将缩放矩阵乘以模型转换，以便为每个实例提供不同的物理大小。基本上任何特征（网格拓扑本身除外）都可以改变，以便为每个实例创建一个独特的外观。</p><h3 id="The-Sample-App-示例应用"><a href="#The-Sample-App-示例应用" class="headerlink" title="The Sample App(示例应用)"></a>The Sample App(示例应用)</h3><p>本章的示例代码位于11-InstancedDrawing目录中。</p><p>您可以通过将手指放在屏幕上向前移动来移动示例应用程序。通过向左或向右平移来转动相机。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在本章中，我们将讨论一种通过单个绘制调用有效绘制许多对象的重要技术：实例渲染。此技术可帮助您充分利用GPU，同时将内存和CPU使用率降至最低。&lt;/p&gt;
&lt;p&gt;本章的示例应用程序呈现了数十个动画奶牛在顶部移动随机生成的地形补丁。每头奶牛都有自己的位置，方向和运动方向，所有这些都在每一帧都更新。我们只用两次绘制调用来完成所有这些绘图。该应用程序仅消耗A8处理器上CPU的百分之几，但最大化GPU，每帧绘制超过240,000个三角形。即使有这么大的负载，这样的设备也能够以理想的每秒60帧的速度渲染。&lt;/p&gt;
    
    </summary>
    
    
      <category term="iOS/Mac" scheme="https://zhaolilong.com/tags/iOS-Mac/"/>
    
      <category term="图形学" scheme="https://zhaolilong.com/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
      <category term="Metal" scheme="https://zhaolilong.com/tags/Metal/"/>
    
  </entry>
  
  <entry>
    <title>Modbus</title>
    <link href="https://zhaolilong.com/2020/03/12/Modbus/"/>
    <id>https://zhaolilong.com/2020/03/12/Modbus/</id>
    <published>2020-03-12T07:07:32.000Z</published>
    <updated>2020-03-13T00:56:09.642Z</updated>
    
    <content type="html"><![CDATA[<p>Modbus是一个通信协议，它可以用来发送和接收数据通过一条串行总线，像RS232和RS485总线。在本章中，你将学习到如何使用Modbus通讯协议通过RS485总线来连接工业设备到您的基于Arduino的PLC（可编程序逻辑控制器）。Modbus使用master-slave（主-从）架构，配置一个节点作为master（例如，Arduino PLC）并配置其他设备作为slaves（温度传感器，湿度传感器，光传感器等等）。使用RS485的好处是它仅仅使用两条共享线来连接所有设备（slaves）到主节点上。它也支持远距离以及电噪声环境中设备的使用。</p><a id="more"></a><p>Modbus</p><p>  Modbus是一个通信协议，它可以用来发送和接收数据通过一条串行总线，像RS232和RS485总线。在本章中，你将学习到如何使用Modbus通讯协议通过RS485总线来连接工业设备到您的基于Arduino的PLC（可编程序逻辑控制器）。Modbus使用master-slave（主-从）架构，配置一个节点作为master（例如，Arduino PLC）并配置其他设备作为slaves（温度传感器，湿度传感器，光传感器等等）。使用RS485的好处是它仅仅使用两条共享线来连接所有设备（slaves）到主节点上。它也支持远距离以及电噪声环境中设备的使用。</p><p>  为了连接您的Arduino PLC到Modbus通信协议开启设备，首先你应当添加一些硬件模块到Arduino中为了开启它作为一个Modbus主节点。</p><p>  <strong>RS485/Modbus模块</strong>是一个理想组件，它可以用来在您的Arduino主板上开启Modbus通信协议。另外，你需要一个板子来与您的Arduino连接和交互。市场上有很多Arduino的RS485/Modbus模块。</p><p>  为了搭建开启RS485和Modbus的Arduino PLC，需要下列操作：<br>    * Multiprotocol Radio Shield（多协议无线电板)<br>    * RS485/Modbus模块</p><h3 id="多协议无线电板"><a href="#多协议无线电板" class="headerlink" title="多协议无线电板"></a>多协议无线电板</h3><p>来自Cooking Hacks的多协议无线电板是Arduino UNO搭建开启Modbus PLCs的理想兼容板。该板被设计为同时连接两个通信模块。<br><img src="/2020/03/12/Modbus/1583998593.png" alt=""></p><p><strong>图 7-1.</strong> 来自Cooking Hacks的多协议无线电板。图片由Libelium提供（<a href="http://www.cooking-hacks.com" target="_blank" rel="noopener">http://www.cooking-hacks.com</a>)</p><blockquote><p><strong>注意</strong>    多协议板有两个插口（Figure 7-2)，你可以用来连接任何开启UART（通用异步收发传输器）的硬件模块。两个插口被命名为SOCKET0和SOCKET1。插口是由2mm母排针组成的，它一共有20个连接。（UART代表通用一步收发传输器并且它是最流行的串行协议。）</p></blockquote><p><img src="/2020/03/12/Modbus/1583999579.png" alt=""></p><p><strong>图 7-2.</strong> 多协议无线电板的顶视图。图片由Libelium提供（<a href="http://www.cooking-hacks.com" target="_blank" rel="noopener">http://www.cooking-hacks.com</a>)</p><p>  所有插口开启SPI（串行外设接口），所以你可以连接<strong>RS485，RS232，</strong>CAN(Controller Area Network控制局域网路) 总线<strong>模块</strong>到它们上面。对于<strong>SOCKET0，</strong>SPI使用<strong>3.3V</strong>电平，SOCKET1，SPI使用<strong>5V</strong>电平。</p><p>  有<strong>两个</strong>绕线式接头被焊接到板子上，所以您可以连接它们到任何Arduino UNO或者兼容的板子上。板子物理连接到Arduino像下面这样。</p><ul><li><p><strong>Header 1</strong>：Arduino数字引脚，0到7有八个连接。</p></li><li><p><strong>Header 2</strong>：Arduino模拟引脚，A0到A5有六个连接。</p><p>板子也包含<strong>数字开关</strong>来开启和禁用两个插口。您可以使用Arduino IDE中软件定义的库函数控制它们。</p></li></ul><h3 id="Arduino和树莓派的RS485-Modbusm模块"><a href="#Arduino和树莓派的RS485-Modbusm模块" class="headerlink" title="Arduino和树莓派的RS485/Modbusm模块"></a>Arduino和树莓派的RS485/Modbusm模块</h3><p>  <strong>对于Arduino和树莓派的RS485/Modbus模块</strong>允许你仅仅用两根线就可以连接多于一个的工业设备到Arduino上。你可以通过带有唯一标识的设备使用两根共享线最多连接<strong>32个设备</strong>到Arduino。</p><p><img src="/2020/03/12/Modbus/1584000687.png" alt=""></p><p><strong>图 7-3.</strong> Arduino和树莓派的RS485/Modbus模块。图片由Libelium提供（<a href="http://www.cooking-hacks.com" target="_blank" rel="noopener">http://www.cooking-hacks.com</a>)</p><p>  表7-1展示了一些Arduino和树莓派的RS485/Modbus模块的技术说明，由Cooking Hacks发布。</p><table><thead><tr><th>Standard</th><th>EIA RS485</th></tr></thead><tbody><tr><td><strong>Physical Media</strong></td><td>Twisted Pair</td></tr><tr><td><strong>Network Topology</strong></td><td>Point-to-point, multi-dropped, multi-point</td></tr><tr><td><strong>Maximum Devices</strong></td><td>Maximum Devices</td></tr><tr><td><strong>Voltage Levels</strong></td><td>-7V to +12V</td></tr><tr><td><strong>Mark(1)</strong></td><td>Positive voltages (B-A &gt; +200mV)</td></tr><tr><td><strong>Space(0)</strong></td><td>Negative voltages (B-A &lt; -200mV)</td></tr><tr><td><strong>Available Signals</strong></td><td>Tx+/Rx+, Tx-/Rx-(Half Duplex)Tx+,Tx-,Rx+,Rx-(Full Duplex)</td></tr></tbody></table><p><strong>表 7-1.</strong> Arduino和树莓派的RS485/Modbus模块技术说明</p><h3 id="为Arduino安装RS485库"><a href="#为Arduino安装RS485库" class="headerlink" title="为Arduino安装RS485库"></a>为Arduino安装RS485库</h3><p>为了与<strong>RS485</strong>一起工作，首先你应该安装<strong>Arduino的RS485库</strong>。使用以下步骤来安装它到Arduino IDE。</p><pre><code>1. 接下下载的zip文件，RS485_for_Arduino(参见第一章的“Modbus RS485库”部分获得更多关于下载链接的信息）。使用任何压缩软件。你将得到一个名为RS485_for_Arduino的文件夹。2. 文件夹结构和下面的层级非常相似：RS485_for_Arduino                    -&gt; RS485                                -&gt; ModBusMaster485                                -&gt; ModbusSlave485                                -&gt; RS485拷贝ModBusMaster485，ModbusSlave485和RS485文件夹到你的Arduino安装的*libraries*文件夹。3. 最终，重启Arduino IDE并确认是否你可以看见样例sketches通过选择File ➤ Examples ➤ RS485</code></pre><p>如果你可以看见它们，你已经为Arduino成功安装了RS485库。</p><h3 id="用Modbus搭建PLC"><a href="#用Modbus搭建PLC" class="headerlink" title="用Modbus搭建PLC"></a>用Modbus搭建PLC</h3><p>  现在，您将学习如何将温度传感器与Arduino接口，以通过RS485总线使用Modbus通信协议。然后你将学习如何读取传感器值从温度传感器并再Arduino串行显示器上显示它们。</p><h4 id="搭建硬件设置"><a href="#搭建硬件设置" class="headerlink" title="搭建硬件设置"></a>搭建硬件设置</h4><p>搭建硬件设置，需要做下面的事情。</p><ul><li>Arduino UNO</li><li>多协议无线电板</li><li>Arduino的RS485/Modbus模块</li><li>TQS3-I MODBUS RS485 室内温度计</li></ul><p>以下步骤将贯穿整个构建过程。</p><pre><code>1. 使用绕线式接头连接**多协议无线电板**到Arduino UNO上（图 7-4）。2. 连接Arduino的RS485/Modbus模块，树莓派连接到**SOCKET1**（图 7-4）。![](1584002689.png)**图 7-4.** Arduino设置RS485和Modbus。图片由Libelium提供（[http://www.cooking-hacks.com](http://www.cooking-hacks.com)3. **温度传感器**我们将使用来自**PAPOUCH**([www.papouch.com](www.papouch.com))**TQS3-I Modbus RS485室内温度计（图 7-5）。**它支持**Modbus**和**Spinel**通信协议通过**RS485总线**。你可以从[http://www.papouch.com/en/shop/product/tqs3-i-rs485interior-thermometer/tqs3.pdf/_downloadFile.php](http://www.papouch.com/en/shop/product/tqs3-i-rs485interior-thermometer/tqs3.pdf/_downloadFile.php)下载这个产品的文档。</code></pre><p> <img src="/2020/03/12/Modbus/1584003116.png" alt=""></p><p> <strong>图 7-5.</strong> TQS3-I Modbus RS485室内温度计。图片由Papouch提供（<a href="http://www.papouch.com" target="_blank" rel="noopener">http://www.papouch.com</a></p><p>   <strong>Wago接线端</strong>位于装置内部，用于连接电源和RS485。图7-6显示了标有电源的接线端和RS485连接。</p><ul><li><p>连接7-20V的直流供电，使用+极和-极。</p></li><li><p>连接RS485总线，使用TX+和TX-端。</p><p><img src="/2020/03/12/Modbus/1584004096.png" alt=""></p></li></ul><p><strong>图 7-6.</strong> Wago接线端。图片由Papouch提供（<a href="http://www.papouch.com" target="_blank" rel="noopener">http://www.papouch.com</a></p><p>   默认的情况下，这个温度传感器配置使用<strong>Spinel</strong>协议（<a href="http://www.papouch.com/en/website/mainmenu/spinel/" target="_blank" rel="noopener">http://www.papouch.com/en/website/mainmenu/spinel/</a>）来通信。对于<strong>Modbus RTU协议</strong>简单的跳线设置可以用来配置它，如图7-7所示，通过缩短安装跳线。</p><p>   <img src="/2020/03/12/Modbus/1584004381.png" alt=""></p><p><strong>图 7-7.</strong> 缩短跳线的设置来启用Modbus RTU。图片由Papouch提供（<a href="http://www.papouch.com" target="_blank" rel="noopener">http://www.papouch.com</a></p><p>  现在用两条线连接<strong>温度传感器</strong>到<strong>Arduino和树莓派</strong>的RS485/Modbus模块，如图7-8所示。</p><pre><code>  1. 连接温度传感器的TX+端到RS485模块标有**A**的一端（同相信号）。  2. 连接温度传感器的TX-端到RS485模块标有**B**的一端（反相信号）。  ![](1584004721.png)**图 7-7.** 信号线端。Image courtesy of Libelium ([https://www.cooking-hacks.com](https://www.cooking-hacks.com)) 3. 使用壁式电源适配器将7-20V之间的DC电源连接到标有+和-的端。</code></pre><h4 id="Arduino-Sketch"><a href="#Arduino-Sketch" class="headerlink" title="Arduino Sketch"></a>Arduino Sketch</h4><p>RS485库中提供了现成的Arduino草图。使用以下步骤来修改草图按照你的Modbus设备。</p><pre><code>1. 开启你的Arduino IDE并选择File ➤ Examples ➤ RS485 ➤ _RS485_04_modbus_read_input_registers，打开名为_RS485_04_modbus_read_input_registers.ino，如清单7-1所示。文件将打开一个新的窗口。</code></pre><p><strong>清单 7-1</strong> 使用Modbus读取温度传感器示例（_RS485_04_modbus_read_input_register.ino）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;RS485.h&gt; </span><br><span class="line">#include &lt;ModbusMaster485.h&gt; </span><br><span class="line">#include &lt;SPI.h&gt;</span><br><span class="line"></span><br><span class="line">// Instantiate ModbusMaster object as slave ID 1 ModbusMaster485 node(254);</span><br><span class="line"></span><br><span class="line">// Define one address for reading </span><br><span class="line">#define address 101</span><br><span class="line">// Define the number of bytes to read </span><br><span class="line">#define bytesQty 2</span><br><span class="line"></span><br><span class="line">void setup() &#123;</span><br><span class="line">    // Power on the USB for viewing data in the serial monitor </span><br><span class="line">    Serial.begin(115200); </span><br><span class="line">    delay(100); </span><br><span class="line">    // Initialize Modbus communication baud rate </span><br><span class="line">    node.begin(19200);</span><br><span class="line"></span><br><span class="line">    // Print hello message </span><br><span class="line">    Serial.println(&quot;Modbus communication over RS-485&quot;);</span><br><span class="line">    delay(100);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void loop() &#123;</span><br><span class="line">    // This variable will store the result of the communication </span><br><span class="line">    // result = 0 : no errors </span><br><span class="line">    // result = 1 : error occurred</span><br><span class="line">    int result = node.readHoldingRegisters(address, bytesQty);</span><br><span class="line">    if (result != 0) &#123; </span><br><span class="line">        // If no response from the slave, print an error message </span><br><span class="line">        Serial.println(&quot;Communication error&quot;); </span><br><span class="line">        delay(1000); </span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        // If all OK </span><br><span class="line">        Serial.print(&quot;Read value : &quot;);</span><br><span class="line"></span><br><span class="line">        // Print the read data from the slave </span><br><span class="line">        Serial.print(node.getResponseBuffer(0)); </span><br><span class="line">        delay(1000);</span><br><span class="line">    &#125;</span><br><span class="line">    Serial.print(&quot;\n&quot;); </span><br><span class="line">    delay(2000);</span><br><span class="line">    // Clear the response buffer </span><br><span class="line">    node.clearResponseBuffer();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><pre><code>2. 现在按照你的温度传感器的存储寄存器地址修改Arduino草图中address变量的值。看到产品数据清单来找到存储寄存器的正确地址，如表7-2。**表 7-2. 存储寄存器的说明</code></pre><table><thead><tr><th>Address</th><th>Acess</th><th>Function</th><th>Description</th></tr></thead><tbody><tr><td>102</td><td>Read</td><td>0x03</td><td>RAW value, which is the value as it was received from the sensors</td></tr></tbody></table><p>  在该示例中，温度值被存储在地址102并且可以被函数readHoldingRegisters()读取。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// Define one address for reading </span><br><span class="line">#define address 102</span><br></pre></td></tr></table></figure><pre><code>3. 修改寄存器的大小（以字节为单位）。在该示例中，存储寄存器在地址102可以存储四个字节的数据。</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// Define the number of bytes to read </span><br><span class="line">#define bytesQty 4</span><br></pre></td></tr></table></figure><pre><code>4. 以下语句将存储ngreadHoldingRegisters()返回的结果。结果为0表示无错误，结果为1表示已发生错误。</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">int result = node.readHoldingRegisters(address, bytesQty);</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">    5. 要从响应缓冲区中检索数据，请在loop（）函数内使用以下语句。</span><br></pre></td></tr></table></figure><p>getResponseBuffer(0)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">    6. 您可以使用以下语句在Arduino串行监视器上打印来自温度传感器的数据：</span><br><span class="line"></span><br><span class="line">```   </span><br><span class="line">Serial.print(node.getResponseBuffer(0));</span><br></pre></td></tr></table></figure><pre><code>7. 读取数据后，不要忘记清除响应缓冲区。您可以使用clearResponseBuffer（）;功能清除响应缓冲区。8. 现在，验证并将Arduino草图上传到Arduino开发板。成功上传草图后，通过选择工具➤串行监视器打开Arduino串行监视器。串行监视器将打印存储在响应缓冲区中的值，如图7-9所示。</code></pre><p><img src="/2020/03/12/Modbus/1584006631.png" alt=""></p><p><strong>图 7-9.</strong> Arduino串行显示器输出（读取响应缓冲）</p><p>通过使用温度传感器数据表中提到的conversion公式，可以将输出值进一步转换为摄氏或华氏温度。但是某些启用了Modbus的设备可以直接以摄氏度或华氏度输出所需的值，而无需进行任何进一步的转换。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在本章中，您学习了如何通过RS485总线使用Modbus通信协议将工业设备连接到基于Arduino的PLC并编写基于RS485库的Arduino草图。您还学习了如何从启用了Modbus通信协议的设备中读取值。在下一章中，您将学习如何使用NearBus Cloud Connector将基于Arduino的PLC映射到云中。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Modbus是一个通信协议，它可以用来发送和接收数据通过一条串行总线，像RS232和RS485总线。在本章中，你将学习到如何使用Modbus通讯协议通过RS485总线来连接工业设备到您的基于Arduino的PLC（可编程序逻辑控制器）。Modbus使用master-slave（主-从）架构，配置一个节点作为master（例如，Arduino PLC）并配置其他设备作为slaves（温度传感器，湿度传感器，光传感器等等）。使用RS485的好处是它仅仅使用两条共享线来连接所有设备（slaves）到主节点上。它也支持远距离以及电噪声环境中设备的使用。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Ardunio" scheme="https://zhaolilong.com/tags/Ardunio/"/>
    
      <category term="Modbus" scheme="https://zhaolilong.com/tags/Modbus/"/>
    
  </entry>
  
  <entry>
    <title>实例学习Metal-第十章 半透明和透明</title>
    <link href="https://zhaolilong.com/2020/03/08/%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0Metal-%E7%AC%AC%E5%8D%81%E7%AB%A0/"/>
    <id>https://zhaolilong.com/2020/03/08/实例学习Metal-第十章/</id>
    <published>2020-03-07T16:00:00.000Z</published>
    <updated>2020-03-13T02:39:31.983Z</updated>
    
    <content type="html"><![CDATA[<p>到目前为止，我们在探索金属时已经轻易避免的一个主题是渲染不透明的材料。在本章中，我们将探讨一些实现透明度和半透明度的相关技术：alpha测试和alpha混合。</p><p>本章的示例场景是一片沙漠，里面有许多棕榈树和几个水池。棕榈树的叶子由几个多边形组成，纹理部分透明纹理，水通过alpha混合呈现为半透明表面，我们将在下面详细讨论。</p><a id="more"></a><h1 id="Chapter-10-第十章"><a href="#Chapter-10-第十章" class="headerlink" title="Chapter 10(第十章)"></a>Chapter 10(第十章)</h1><h2 id="Translucency-and-Transparency-半透明和透明"><a href="#Translucency-and-Transparency-半透明和透明" class="headerlink" title="Translucency and Transparency(半透明和透明)"></a>Translucency and Transparency(半透明和透明)</h2><p>到目前为止，我们在探索金属时已经轻易避免的一个主题是渲染不透明的材料。在本章中，我们将探讨一些实现透明度和半透明度的相关技术：alpha测试和alpha混合。</p><p>本章的示例场景是一片沙漠，里面有许多棕榈树和几个水池。棕榈树的叶子由几个多边形组成，纹理部分透明纹理，水通过alpha混合呈现为半透明表面，我们将在下面详细讨论。</p><h3 id="What-is-Alpha-Anyway-无论如何，Alpha是什么？"><a href="#What-is-Alpha-Anyway-无论如何，Alpha是什么？" class="headerlink" title="What is Alpha, Anyway?(无论如何，Alpha是什么？)"></a>What is Alpha, Anyway?(无论如何，Alpha是什么？)</h3><p>Alpha是颜色值的不透明度(或覆盖率)。 alpha值越高，颜色越不透明。 alpha值为0表示总透明度，而值为1(或100％)表示总不透明度。当根据片段颜色说话时，数据组件指示片段后面的场景显示的程度。请参阅(Glassner 2015)对基础知识的严格讨论。</p><p><img src="/2020/03/08/实例学习Metal-第十章/1584066843.png" alt=""></p><center>图10.1：示例应用程序演示了alpha测试和alpha混合</center><h3 id="Alpha-Testing-透明度测试"><a href="#Alpha-Testing-透明度测试" class="headerlink" title="Alpha Testing(透明度测试)"></a>Alpha Testing(透明度测试)</h3><p>我们将用于渲染部分透明表面的第一种技术是<code>alpha testing</code>。</p><p>透明度测试允许我们通过比较其不透明度与阈值(称为<code>参考值</code>)来确定片段是否应该对存储在渲染缓冲区中的颜色做出贡献。 透明度测试用于使表面<code>选择性</code>透明。</p><p>透明度测试的一个常见应用是渲染树叶，其中相对较少的多边形可用于描述树叶的形状，并且叶子纹理的alpha通道可用于确定绘制哪些像素和不绘制哪些像素。</p><p><img src="/2020/03/08/实例学习Metal-第十章/1584066892.png" alt=""></p><center>图10.2：透明度测试允许我们绘制部分透明的棕榈叶</center><h3 id="Alpha-Testing-in-Metal-Metal中的透明度测试"><a href="#Alpha-Testing-in-Metal-Metal中的透明度测试" class="headerlink" title="Alpha Testing in Metal(Metal中的透明度测试)"></a>Alpha Testing in Metal(Metal中的透明度测试)</h3><p>Metal中的透明度测试是在片段函数中实现的。着色器文件包含全局参考值（示例应用程序中为0.5），我们的alpha值将与之进行比较。片段函数对棕榈树的漫反射纹理进行采样，对于应该是透明的纹素，其alpha值为0。然后使用采样的颜色来确定片段是否应该是可见的。</p><h4 id="The-‘discard-fragment’-function-discard-fragment函数"><a href="#The-‘discard-fragment’-function-discard-fragment函数" class="headerlink" title="The ‘discard_fragment’ function(discard_fragment函数)"></a>The ‘discard_fragment’ function(discard_fragment函数)</h4><p>为了向Metal指示我们不想为片段提供颜色，我们不能简单地将返回的alpha值设置为0.如果我们这样做，片段深度仍会被写入深度缓冲区，从而导致任何几何隐藏在“透明”点之后。</p><p>相反，我们需要调用一个特殊的函数来避免完全为片段指定颜色值：<code>discard_fragment</code>。调用此函数可防止Metal将片段的计算深度和颜色值写入帧缓冲区，从而允许片段后面的场景显示。</p><h5 id="The-Texture-Alpha-Channel-纹理Alpha通道"><a href="#The-Texture-Alpha-Channel-纹理Alpha通道" class="headerlink" title="The Texture Alpha Channel(纹理Alpha通道)"></a>The Texture Alpha Channel(纹理Alpha通道)</h5><p>要执行每片段alpha测试，我们需要一个特殊构造的纹理，其alpha通道中包含合适的覆盖信息。下图显示了示例应用程序中使用的棕榈叶纹理。</p><p><img src="/2020/03/08/实例学习Metal-第十章/1584066914.png" alt=""></p><center>图10.3：用于在示例应用程序中绘制棕榈叶的纹理。不绘制图像的透明部分。</center><h5 id="Performing-the-Alpha-Test-执行Alpha测试"><a href="#Performing-the-Alpha-Test-执行Alpha测试" class="headerlink" title="Performing the Alpha Test(执行Alpha测试)"></a>Performing the Alpha Test(执行Alpha测试)</h5><p>片段着色器中alpha测试的实现非常简单。将我们刚刚讨论的技术集合在一起，我们根据阈值测试采样的alpha值，并丢弃未通过alpha测试的任何片段：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">float4 textureColor = texture.sample(texSampler, vert.texCoords);</span><br><span class="line">if (textureColor.a &lt; kAlphaTestReferenceValue) </span><br><span class="line">    discard_fragment();</span><br></pre></td></tr></table></figure><h4 id="A-Note-on-Performance-关于绩效的说明"><a href="#A-Note-on-Performance-关于绩效的说明" class="headerlink" title="A Note on Performance(关于绩效的说明)"></a>A Note on Performance(关于绩效的说明)</h4><p>使用<code>discard_fragment</code>会影响性能。特别是，它可以防止硬件执行称为<code>早期深度测试</code>（有时称为<code>早期z</code>）的优化。</p><p>通常，硬件可以在调用片段函数之前确定片段是否有助于渲染缓冲区，因为片段深度是在光栅化器中计算的。这意味着它可以避免着色已知被其他几何体遮挡的碎片块。</p><p>另一方面，如果要使用包含条件<code>discard_fragment</code>调用的函数对片段进行着色，则无法应用此优化，并且硬件必须为每个可能可见的片段调用着色器。</p><p>在本章的示例代码中，我们为几何体提供了单独的片段函数，这些函数使用alpha测试而不是。 alpha测试函数应仅用于实际需要它的几何体，因为过度使用<code>discard_fragment</code>会对性能产生很大的负面影响。</p><p>早期深度测试的完整解释超出了本书的范围，但Fabien Giesen的博客系列(Giesen 2011)提供了有关深度测试和与现代3D渲染管道相关的许多其他主题的更多详细信息。</p><h4 id="Alpha-Blending-透明度混合"><a href="#Alpha-Blending-透明度混合" class="headerlink" title="Alpha Blending(透明度混合)"></a>Alpha Blending(透明度混合)</h4><p>另一种实现透明度的有用技术是<code>透明度混合</code>。</p><p>通过在渲染缓冲区（目标）中已有的颜色和当前被遮蔽的片段（源）之间进行插值来实现透明度混合。使用的确切公式取决于所需的效果，但对于我们当前的目的，我们将使用以下等式：</p><p>c<sub>f</sub> =α<sub>s</sub> ×c<sub>s</sub> +(1−α<sub>s</sub>)×c<sub>d</sub></p><p>其中c<sub>s</sub>和c<sub>d</sub>分别是源和目标颜色的RGB分量; α<sub>s</sub>是源颜色的不透明度;和c<sub>f</sub>是碎片的最终混合颜色值。</p><p>用文字表示，这个公式说：我们将源颜色的不透明度乘以源颜色的RGB分量，产生片段对最终颜色的贡献。这将添加到不透明度的加法倒数乘以渲染缓冲区中已有的颜色。这将“混合”两种颜色以创建写入渲染缓冲区的新颜色。</p><h3 id="Alpha-Blending-in-Metal-Metal中的透明度混合"><a href="#Alpha-Blending-in-Metal-Metal中的透明度混合" class="headerlink" title="Alpha Blending in Metal(Metal中的透明度混合)"></a>Alpha Blending in Metal(Metal中的透明度混合)</h3><p>在本章的示例项目中，我们使用alpha混合来使水面半透明。这种效果在计算上是便宜的并且不是特别令人信服，但它可以补充立方体图反射或在水面上滑动纹理或物理地移动它的动画。</p><h3 id="Enabling-Blending-in-the-Pipeline-State-在管道状态中启用混合"><a href="#Enabling-Blending-in-the-Pipeline-State-在管道状态中启用混合" class="headerlink" title="Enabling Blending in the Pipeline State(在管道状态中启用混合)"></a>Enabling Blending in the Pipeline State(在管道状态中启用混合)</h3><p>在Metal中混合有两种基本方法：固定功能和可编程。我们将在本节讨论固定功能混合。固定功能混合包括在渲染管道描述符的颜色附件描述符上设置属性。这些属性确定片段函数返回的颜色如何与像素的现有颜色组合以生成最终颜色。</p><p>为了使接下来的几个步骤更简洁，我们保存了对颜色附件的引用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MTLRenderPipelineColorAttachmentDescriptor *renderbufferAttachment = pipelineDescriptor.colorAttachments[0];</span><br></pre></td></tr></table></figure><p>要启用混合，请将blendingEnabled设置为YES：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">renderbufferAttachment.blendingEnabled = <span class="literal">YES</span>;</span><br></pre></td></tr></table></figure><p>接下来，我们选择用于组合加权颜色和透明度分量的操作。在这里，我们选择<code>Add</code>：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">renderbufferAttachment.rgbBlendOperation = <span class="built_in">MTLBlendOperationAdd</span>; renderbufferAttachment.alphaBlendOperation = <span class="built_in">MTLBlendOperationAdd</span>;</span><br></pre></td></tr></table></figure><p>现在我们需要指定源颜色和透明度的加权因子。我们选择SourceAlpha因子，以匹配上面给出的公式。</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">renderbufferAttachment.sourceRGBBlendFactor = <span class="built_in">MTLBlendFactorSourceAlpha</span>; renderbufferAttachment.sourceAlphaBlendFactor = <span class="built_in">MTLBlendFactorSourceAlpha</span>;</span><br></pre></td></tr></table></figure><p>最后，我们选择目标颜色和透明度的加权因子。这些是源颜色因子的加法逆运算，OneMinusSourceAlpha：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">renderbufferAttachment.destinationRGBBlendFactor = MTLBlendFactorOneMinusSourceAlpha;</span><br><span class="line">renderbufferAttachment.destinationAlphaBlendFactor = MTLBlendFactorOneMinusSourceAlpha;</span><br></pre></td></tr></table></figure><h4 id="The-Alpha-Blending-Fragment-Shader-透明度混合碎片着色器"><a href="#The-Alpha-Blending-Fragment-Shader-透明度混合碎片着色器" class="headerlink" title="The Alpha Blending Fragment Shader(透明度混合碎片着色器)"></a>The Alpha Blending Fragment Shader(透明度混合碎片着色器)</h4><p>片段着色器返回它为其片段计算的颜色。在前面的章节中，此颜色的alpha分量无关紧要，因为未启用混合。现在，我们需要确保着色器返回的alpha分量表示片段所需的不透明度。此值将用作在渲染管道状态上配置的混合方程中的“源”alpha值。</p><p>在示例代码中，我们将采样的漫反射纹理颜色与当前顶点颜色相乘，以获得片段的源颜色。由于纹理是不透明的，因此顶点颜色的alpha分量变为水的不透明度。将此值作为alpha的alpha传递片段颜色的返回值根据先前配置颜色附件的方式生成alpha混合。</p><p><img src="/2020/03/08/实例学习Metal-第十章/1584067144.png" alt=""></p><center>图10.4：Alpha混合允许沙漠沙漠通过清澈的水面</center><h4 id="Order-Dependent-Blending-versus-Order-Independent-Blending-依赖于顺序的混合与顺序无关的混合"><a href="#Order-Dependent-Blending-versus-Order-Independent-Blending-依赖于顺序的混合与顺序无关的混合" class="headerlink" title="Order-Dependent Blending versus Order-Independent Blending(依赖于顺序的混合与顺序无关的混合)"></a>Order-Dependent Blending versus Order-Independent Blending(依赖于顺序的混合与顺序无关的混合)</h4><p>在渲染半透明表面时，顺序很重要。为了使透明度混合生成正确的图像，应在所有不透明对象之后渲染半透明对象。另外，相对于相机，它们应该从后端到前端。由于顺序取决于视图位置和方向，因此每当相对顺序发生变化时，通常每当相机移动时，都需要对对象进行重新排序。</p><p>我们在示例应用程序中完全避免了这个问题，因为在场景中只有一个凸出的半透明表面：水。其他应用程序不会那么容易。</p><p>在过去几年中，已经有很多关于避免这种昂贵的分选步骤的方法的研究。一种技术使用所谓的A缓冲（由Carpenter于1984年引入（Carpenter 1984））来维持对每个像素贡献的片段的一对颜色和深度值。然后将这些片段分类并在第二轮中混合。<br>最近，研究强调了alpha复合本身的数学，试图推导出一种与订单无关的透明度解决方案。有关此技术的进展，请参阅McGuire和Bavoil的论文(McGuire和Bavoil 2013)。</p><h3 id="示例应用"><a href="#示例应用" class="headerlink" title="示例应用"></a>示例应用</h3><p>本章的示例代码位于10-AlphaBlending目录中。按屏幕可使摄像机沿其当前航向前进，同时向左或向右平移会改变摄像机前进的方向。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;到目前为止，我们在探索金属时已经轻易避免的一个主题是渲染不透明的材料。在本章中，我们将探讨一些实现透明度和半透明度的相关技术：alpha测试和alpha混合。&lt;/p&gt;
&lt;p&gt;本章的示例场景是一片沙漠，里面有许多棕榈树和几个水池。棕榈树的叶子由几个多边形组成，纹理部分透明纹理，水通过alpha混合呈现为半透明表面，我们将在下面详细讨论。&lt;/p&gt;
    
    </summary>
    
    
      <category term="iOS/Mac" scheme="https://zhaolilong.com/tags/iOS-Mac/"/>
    
      <category term="图形学" scheme="https://zhaolilong.com/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
      <category term="Metal" scheme="https://zhaolilong.com/tags/Metal/"/>
    
  </entry>
  
  <entry>
    <title>实例学习Metal-第九章 压缩纹理</title>
    <link href="https://zhaolilong.com/2020/03/01/%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0Metal-%E7%AC%AC%E4%B9%9D%E7%AB%A0/"/>
    <id>https://zhaolilong.com/2020/03/01/实例学习Metal-第九章/</id>
    <published>2020-02-29T16:00:00.000Z</published>
    <updated>2020-03-13T02:33:25.652Z</updated>
    
    <content type="html"><![CDATA[<p>在本章中，我们将考虑几种GPU友好的压缩纹理格式。这些格式允许我们交换一些图像质量，以显着改进磁盘使用和性能。特别是，我们将研究ETC2，PVRTC和ASTC格式。</p><a id="more"></a><h1 id="Chapter9-第九章"><a href="#Chapter9-第九章" class="headerlink" title="Chapter9(第九章)"></a>Chapter9(第九章)</h1><h2 id="Compressed-Textures-压缩纹理"><a href="#Compressed-Textures-压缩纹理" class="headerlink" title="Compressed Textures(压缩纹理)"></a>Compressed Textures(压缩纹理)</h2><p>在本章中，我们将考虑几种GPU友好的压缩纹理格式。这些格式允许我们交换一些图像质量，以显着改进磁盘使用和性能。特别是，我们将研究ETC2，PVRTC和ASTC格式。</p><h3 id="Why-Use-Compressed-Textures-为什么使用压缩纹理？"><a href="#Why-Use-Compressed-Textures-为什么使用压缩纹理？" class="headerlink" title="Why Use Compressed Textures?(为什么使用压缩纹理？)"></a>Why Use Compressed Textures?(为什么使用压缩纹理？)</h3><p>在前面的章节中，我们通过将图像加载到内存中，将其绘制到位图上下文中，并将这些位复制到Metal纹理中来创建纹理。这些纹理使用未压缩的像素格式，MTLPixelFormatRGBA8Unorm。</p><p>Metal还支持多种压缩格式。这些格式允许我们将图像数据直接复制到纹理中而不对其进行解压缩。这些格式设计为在采样纹理时而不是在加载纹理时由GPU按需解压缩。</p><p>我们将在下面考虑的格式是有损的，这意味着它们不能完全保留图像内容，像PNG一样的无损格式。相反，他们通过降低图像质量来减少内存使用量。因此，使用压缩纹理数据可以大大减少采样纹理时消耗的内存带宽，并且对缓存更友好。</p><p><img src="/2020/03/01/实例学习Metal-第九章/1584066690.png" alt=""></p><center>图9.1：示例应用程序展示了各种压缩纹理格式</center><h3 id="A-Brief-Overview-of-Compressed-Texture-Formats-压缩纹理格式简介"><a href="#A-Brief-Overview-of-Compressed-Texture-Formats-压缩纹理格式简介" class="headerlink" title="A Brief Overview of Compressed Texture Formats(压缩纹理格式简介)"></a>A Brief Overview of Compressed Texture Formats(压缩纹理格式简介)</h3><h4 id="S3TC"><a href="#S3TC" class="headerlink" title="S3TC"></a>S3TC</h4><p>S3TC，也称为DXT，是第一个获得广泛采用的压缩格式，因为它分别在1998年和2001年被包含在DirectX 6.0和OpenGL 1.3中。虽然S3TC在桌面GPU上得到广泛支持，但它在iOS设备上不可用。</p><h4 id="PVRTC"><a href="#PVRTC" class="headerlink" title="PVRTC"></a>PVRTC</h4><p>PVRTC图像格式由Imagination Technologies引入，Imagination Technologies是PowerVR系列GPU的创建者，是每个iOS设备的核心。这是Simon Fenney在2003年的一篇论文中首次描述的。</p><p>PVRTC通过将源图像下采样为两个较小的图像来进行操作，这两个较小的图像被放大并混合以重建原始的近似值。它一次考虑4×4或4×8像素的块，它们被打包成一个64位数量。从而，<br>每个像素分别占据4位或2位。</p><p>在iOS上使用PVRTC格式的一个重要限制是纹理必须是方形的，每个维度必须是2的幂。幸运的是，游戏纹理最常以与此限制兼容的尺寸生成。</p><h4 id="ETC"><a href="#ETC" class="headerlink" title="ETC"></a>ETC</h4><p>爱立信纹理压缩（ETC）于2005年首次亮相。与PVRTC的每像素4位模式类似，它将每个4×4像素块压缩为单个64位数量，但缺乏对alpha通道的支持。后续版本ETC2增加了对1位和8位alpha通道的支持。所有与Metal兼容的硬件都支持ETC2，但PVRTC通常在可比较的文件大小下提供更好的质量。</p><h4 id="ASTC"><a href="#ASTC" class="headerlink" title="ASTC"></a>ASTC</h4><p>高级可扩展纹理压缩（ASTC）是Metal支持的最新压缩纹理格式。由AMD开发并在OpenGL ES 3.0级硬件上得到广泛支持，这种格式包含一个可选的块大小(从4×4到12×12)决定图像的压缩比。这种前所未有的灵活性使得ASTC成为一个非常有吸引力的选择，但它最低需要A8处理器，使其无法在iPhone 5s等设备上使用。</p><h3 id="Container-Formats-容器格式"><a href="#Container-Formats-容器格式" class="headerlink" title="Container Formats(容器格式)"></a>Container Formats(容器格式)</h3><p>纹理使用的压缩格式只是图片的一半。为了加载来自磁盘的纹理，我们需要知道它的尺寸（宽度和高度）及其像素格式。此元数据通常以头信息形式写入文件本身，该头信息位于图像数据之前。标题的布局由图像的容器格式描述。在本章中，我们将使用两种容器格式：PVR和ASTC。</p><h4 id="The-PVR-Container-Format-PVR容器格式"><a href="#The-PVR-Container-Format-PVR容器格式" class="headerlink" title="The PVR Container Format(PVR容器格式)"></a>The PVR Container Format(PVR容器格式)</h4><p>不要与PVRTC压缩格式相混淆，PVR容器格式描述了如何解释纹理文件中的数据。 PVR文件可以包含多种格式的未压缩数据或压缩数据(包括S3TC，ETC和PVRTC)。</p><p>PVR格式有一些不同的，互不兼容的版本。这意味着每个版本的PVR都需要不同的代码才能正确解析。例如，“遗留”格式(PVRv2)的头信息结构如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">struct PVRv2Header &#123;</span><br><span class="line">    uint32_t headerLength; </span><br><span class="line">    uint32_t height; </span><br><span class="line">    uint32_t width; </span><br><span class="line">    uint32_t mipmapCount; </span><br><span class="line">    uint32_t flags; </span><br><span class="line">    uint32_t dataLength; </span><br><span class="line">    uint32_t bitsPerPixel; </span><br><span class="line">    uint32_t redBitmask; </span><br><span class="line">    uint32_t greenBitmask;</span><br><span class="line">    uint32_t blueBitmask; </span><br><span class="line">    uint32_t alphaBitmask; </span><br><span class="line">    uint32_t pvrTag; </span><br><span class="line">    uint32_t surfaceCount;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>最新版本(PVRv3)的头信息结构如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">struct PVRv3Header &#123; </span><br><span class="line">    uint32_t version; </span><br><span class="line">    uint32_t flags; </span><br><span class="line">    uint64_t pixelFormat; </span><br><span class="line">    uint32_t colorSpace; </span><br><span class="line">    uint32_t channelType; </span><br><span class="line">    uint32_t height; </span><br><span class="line">    uint32_t width; </span><br><span class="line">    uint32_t depth; </span><br><span class="line">    uint32_t surfaceCount; </span><br><span class="line">    uint32_t faceCount; </span><br><span class="line">    uint32_t mipmapCount; </span><br><span class="line">    uint32_t metadataLength;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>头信息之间存在更多相似之处。各个字段描述了包含的数据，包括纹理的尺寸以及文件是否包含一组mipmap或单个图像。如果文件包含mipmap，则它们只是连接在一起而没有填充。读取文件的程序负责计算每个图像的预期长度。本章的示例代码包括解析旧版和PVRv3容器的代码。</p><p>请注意，标题还包含surfaceCount和（在PVRv3的情况下）faceCount字段，可以在将纹理数组或立方体贴图写入单个文件时使用。我们不会在本章中使用这些字段。</p><h4 id="The-KTX-Container-Format-KTX容器格式"><a href="#The-KTX-Container-Format-KTX容器格式" class="headerlink" title="The KTX Container Format(KTX容器格式)"></a>The KTX Container Format(KTX容器格式)</h4><p>KTX文件格式是由Khronos Group设计的容器，它负责许多开放标准，包括OpenGL。 KTX旨在尽可能无缝地将纹理数据加载到OpenGL中，但我们可以使用它将纹理数据轻松加载到Metal中。</p><p>KTX文件头看起来像这样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">struct KTXHeader </span><br><span class="line">&#123;</span><br><span class="line">    uint8_t identifier[12]; </span><br><span class="line">    uint32_t endianness;</span><br><span class="line">    uint32_t glType;</span><br><span class="line">    uint32_t glTypeSize;</span><br><span class="line">    uint32_t glFormat;</span><br><span class="line">    uint32_t glInternalFormat; </span><br><span class="line">    uint32_t glBaseInternalFormat; </span><br><span class="line">    uint32_t width;</span><br><span class="line">    uint32_t height;</span><br><span class="line">    uint32_t depth;</span><br><span class="line">    uint32_t arrayElementCount; </span><br><span class="line">    uint32_t faceCount; </span><br><span class="line">    uint32_t mipmapCount; </span><br><span class="line">    uint32_t keyValueDataLength;</span><br><span class="line">&#125; MBEKTXHeader;</span><br></pre></td></tr></table></figure><p><code>identifier</code>字段是一个字节序列，用于将文件标识为KTX容器，并帮助检测编码错误。以gl开头的字段对应于OpenGL语言。我们关心的是<code>glInternalFormat</code>字段，它告诉我们使用哪个编码器（PVRTC，ASTC等）来压缩纹理数据。一旦我们知道了这一点，我们就可以将GL内部格式映射为Metal像素格式，并从文件的其余部分中提取数据。</p><p>有关此格式的所有详细信息，请参阅KTX规范（Khronos Group 2013）。</p><h3 id="Creating-Compressed-Textures-创建压缩纹理"><a href="#Creating-Compressed-Textures-创建压缩纹理" class="headerlink" title="Creating Compressed Textures(创建压缩纹理)"></a>Creating Compressed Textures(创建压缩纹理)</h3><p>在命令行和GUI上都有各种用于创建压缩纹理的工具。下面，我们将介绍两种工具，它们允许我们在上面讨论的格式中创建纹理。</p><h4 id="Creating-Textures-with-texturetool-使用texturetool创建纹理"><a href="#Creating-Textures-with-texturetool-使用texturetool创建纹理" class="headerlink" title="Creating Textures with texturetool(使用texturetool创建纹理)"></a>Creating Textures with texturetool(使用texturetool创建纹理)</h4><p>Apple包含一个名为texturetool的Xcode命令行实用程序，可以将图像转换为压缩纹理格式，如PVRTC和ASTC。在撰写本文时，它不支持PVRv3容器格式。相反，它使用传统（PVRv2）格式写入PVR文件，如上所述。使用<code>-e</code>标识，指定所需的容器格式：PVR，KTX或RAW（无标题）。使用-f格式指定压缩类型：PVRTC或ASTC。 <code>-m</code>标识表示应生成所有mipmap并将其顺序写入文件。</p><p>每种压缩格式都有自己的标志，用于选择压缩程度。例如，要创建带有PVR遗留头的4位/像素PVRTC纹理（包括所有mipmap级别），请使用以下的texturetool调用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">texturetool -m -e PVRTC -f PVR --bits-per-pixel-4 -o output.pvr input.png</span><br></pre></td></tr></table></figure><p>使用“thorough”压缩模式在具有8×8块大小的KTX容器中创建ASTC压缩纹理：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">texturetool -m -e ASTC -f KTX --block-width-8 --block-height-8 \</span><br><span class="line">--compression-mode-thorough -o output.astc input.png</span><br></pre></td></tr></table></figure><h4 id="Creating-Textures-with-PVRTexToolGUI-使用PVRTexToolGUI创建纹理"><a href="#Creating-Textures-with-PVRTexToolGUI-使用PVRTexToolGUI创建纹理" class="headerlink" title="Creating Textures with PVRTexToolGUI(使用PVRTexToolGUI创建纹理)"></a>Creating Textures with PVRTexToolGUI(使用PVRTexToolGUI创建纹理)</h4><p>Imagination Technologies在其PowerVR SDK中包含一个工具，允许使用GUI创建压缩纹理。 PVRTexToolGUI允许您导入图像并选择各种压缩格式，包括ASTC，PVRTC和ETC2。与<code>texturetool</code>不同，此应用程序默认使用PVRv3容器格式，因此如果使用此工具压缩纹理，则应使用需要适当头信息格式的代码。</p><p>PVRTexToolGUI有一个命令行对应物<code>PVRTexToolCLI</code>，它在GUI中公开可用的所有参数，并允许您编写脚本以快速批量转换纹理。</p><p><img src="/2020/03/01/实例学习Metal-第九章/1584066736.png" alt=""></p><center>图9.2：Imagination Technologies的PVRTexToolGUI允许用户以各种格式压缩图像</center><h3 id="Loading-Compressed-Texture-Data-into-Metal-加载压缩纹理数据到Metal中"><a href="#Loading-Compressed-Texture-Data-into-Metal-加载压缩纹理数据到Metal中" class="headerlink" title="Loading Compressed Texture Data into Metal(加载压缩纹理数据到Metal中)"></a>Loading Compressed Texture Data into Metal(加载压缩纹理数据到Metal中)</h3><p>加载压缩纹理是一个双重过程。首先，我们读取容器格式的头信息。然后，我们读取头信息描述的图像数据并将其交给Metal。无论使用何种压缩算法，我们都不需要自己解析图像数据，因为Metal能够在硬件中理解和解码压缩纹理。</p><p>使用压缩数据创建纹理与使用未压缩数据完全相同。首先，我们使用适当的像素格式和尺寸创建纹理描述符。如果纹理具有mipmap，我们使用mipmapped参数指示。例如，以下是我们如何为每个像素为4位的PVRTC纹理创建纹理描述符，我们有mipmaps：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="built_in">MTLTextureDescriptor</span> texture2DDescriptorWithPixelFormat:<span class="built_in">MTLPixelFormatPVRTC_RGBA_4BPP</span> width:width height:height mipmapped:<span class="literal">YES</span>];</span><br></pre></td></tr></table></figure><p>然后我们可以要求设备生成与此描述符匹配的纹理：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">id</span> texture = [device newTextureWithDescriptor：descriptor];</span><br></pre></td></tr></table></figure><p>对于图像中的每个mipmap级别，我们需要单独调用MTLTexture方法-replaceRegion：mipmapLevel：withBytes：bytesPerRow :,如下所示：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">MTLRegion</span> region = <span class="built_in">MTLRegionMake2D</span>(<span class="number">0</span>, <span class="number">0</span>, levelWidth, levelHeight); [texture replaceRegion:region mipmapLevel:level withBytes:levelData</span><br><span class="line">bytesPerRow:levelBytesPerRow];</span><br></pre></td></tr></table></figure><p>其中levelWidth和levelHeight是当前mip级别的维度，level是当前mip级别的索引（基本级别是索引0），而levelData是指向mip级别的图像数据的指针。 levelBytesPerRow可以计算为图像数据的长度除以级别的高度。加载PVRTC数据时，bytesPerRow可以设置为0。</p><h3 id="The-Sample-App-示例应用"><a href="#The-Sample-App-示例应用" class="headerlink" title="The Sample App(示例应用)"></a>The Sample App(示例应用)</h3><p>本章的示例代码位于09-CompressedTextures目录中。</p><p>示例应用程序包括本章中提到的所有纹理格式的演示。点击“切换纹理”按钮会弹出一个菜单，允许用户在各种纹理中进行选择。如果运行应用程序的设备不支持ASTC压缩，则ASTC选项的菜单选项将不可用。</p><p>一般来说，ASTC在可用的硬件上提供最佳的质量/尺寸比。在使用A7处理器定位设备时，通常应首选PVRTC格式。</p><p><img src="/2020/03/01/实例学习Metal-第九章/1584066772.png" alt=""></p><center>图9.3：示例应用程序允许您从Metal支持的几种压缩格式中进行选择。</center>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在本章中，我们将考虑几种GPU友好的压缩纹理格式。这些格式允许我们交换一些图像质量，以显着改进磁盘使用和性能。特别是，我们将研究ETC2，PVRTC和ASTC格式。&lt;/p&gt;
    
    </summary>
    
    
      <category term="iOS/Mac" scheme="https://zhaolilong.com/tags/iOS-Mac/"/>
    
      <category term="图形学" scheme="https://zhaolilong.com/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
      <category term="Metal" scheme="https://zhaolilong.com/tags/Metal/"/>
    
  </entry>
  
  <entry>
    <title>实例学习Metal-第八章 多维数据集地图的反射和折射</title>
    <link href="https://zhaolilong.com/2020/02/23/%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0Metal-%E7%AC%AC%E5%85%AB%E7%AB%A0/"/>
    <id>https://zhaolilong.com/2020/02/23/实例学习Metal-第八章/</id>
    <published>2020-02-22T16:00:00.000Z</published>
    <updated>2020-03-13T02:30:57.938Z</updated>
    
    <content type="html"><![CDATA[<p>在本章中，我们将讨论Metal中一些更高级的纹理功能。我们将立方体贴图应用于天空盒以模拟周围的详细环境现场。我们还将介绍一种称为立方体环境映射的技术来模拟反射和折射，以进一步增强我们虚拟世界的真实感。</p><a id="more"></a><h1 id="Chapter8-第八章"><a href="#Chapter8-第八章" class="headerlink" title="Chapter8(第八章)"></a>Chapter8(第八章)</h1><h2 id="Reflection-and-Refraction-with-Cube-Maps-多维数据集地图的反射和折射"><a href="#Reflection-and-Refraction-with-Cube-Maps-多维数据集地图的反射和折射" class="headerlink" title="Reflection and Refraction with Cube Maps(多维数据集地图的反射和折射)"></a>Reflection and Refraction with Cube Maps(多维数据集地图的反射和折射)</h2><p>在本章中，我们将讨论Metal中一些更高级的纹理功能。我们将立方体贴图应用于天空盒以模拟周围的详细环境现场。我们还将介绍一种称为立方体环境映射的技术来模拟反射和折射，以进一步增强我们虚拟世界的真实感。</p><p>首先，我们来谈谈示例场景。</p><h3 id="Setting-the-Scene-设置场景"><a href="#Setting-the-Scene-设置场景" class="headerlink" title="Setting the Scene(设置场景)"></a>Setting the Scene(设置场景)</h3><p>示例应用程序的场景包含围绕圆环结的天空盒。天空盒是一个立方体，其内部具有纹理，以创建围绕相机的大型户外环境的错觉。你可能熟悉圆环，这是一个几何形状，由一个围绕另一个圆圈垂直扫过的圆圈组成。圆环结通过扭转轨道圆圈所采用的路径引入了额外的复杂性，创造出更具视觉趣味的图形。</p><p>我们将在程序上生成必要的几何，而不是从磁盘加载模型来构建示例场景。</p><p><img src="/2020/02/23/实例学习Metal-第八章/1584066152.png" alt=""></p><center>图8.1：环形图反映了圆环结。纹理由Emil Persson提供（http://humus.name）</center><h4 id="The-Vertex-Format-顶点格式"><a href="#The-Vertex-Format-顶点格式" class="headerlink" title="The Vertex Format(顶点格式)"></a>The Vertex Format(顶点格式)</h4><p>虽然我们场景中的对象将被纹理化，但我们不需要在顶点中显式存储纹理坐标。相反，我们将在特制的顶点着色器中生成天空盒和圆环结的纹理坐标。因此，每个顶点只有两个属性：position和normal：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">typedef struct &#123;</span><br><span class="line">vector_float4 position;</span><br><span class="line">vector_float4 normal; &#125; MBEVertex;</span><br></pre></td></tr></table></figure><h4 id="The-Mesh-Class-网格类"><a href="#The-Mesh-Class-网格类" class="headerlink" title="The Mesh Class(网格类)"></a>The Mesh Class(网格类)</h4><p>正如我们之前所做的那样，我们使用网格对象来包装顶点缓冲区和索引缓冲区，以便我们可以方便地发出索引绘制调用。基类MBEMesh为这两个缓冲区提供了一个抽象接口。</p><h4 id="The-Skybox-Mesh-天空盒网格"><a href="#The-Skybox-Mesh-天空盒网格" class="headerlink" title="The Skybox Mesh(天空盒网格)"></a>The Skybox Mesh(天空盒网格)</h4><p>生成天空盒网格很简单。天空盒是关于原点的单位立方体，因此天空盒类使用静态的位置，法线和索引列表来构建其缓冲区。请注意，索引按顺序排列以生成指向内部的立方体面，因为虚拟摄像机始终位于天空盒内。</p><p><img src="/2020/02/23/实例学习Metal-第八章/1584066187.png" alt=""></p><center>图8.2：应用于天空盒的立方体环境贴图可以产生详细背景的错觉。</center><h4 id="The-Torus-Knot-Mesh-圆环结网"><a href="#The-Torus-Knot-Mesh-圆环结网" class="headerlink" title="The Torus Knot Mesh(圆环结网)"></a>The Torus Knot Mesh(圆环结网)</h4><p>MBETorusKnotMesh类在沿着圆环结的路径扫描时生成顶点，然后生成将顶点编织成实体网格的索引。您可以通过改变传递给网格初始化方法的参数来生成各种有趣的结。</p><p><img src="/2020/02/23/实例学习Metal-第八章/1584066211.png" alt=""></p><center>图8.3：这种三叶形结是一种可以由圆环结网格类产生的结。</center><p>现在我们要渲染一些几何体，让我们来谈谈Metal中的一种新纹理。</p><h3 id="Cube-Textures-立方体纹理"><a href="#Cube-Textures-立方体纹理" class="headerlink" title="Cube Textures(立方体纹理)"></a>Cube Textures(立方体纹理)</h3><p>立方体纹理（也称为“立方体贴图”）是一种特殊类型的纹理。与常规2D纹理相比，立方体纹理是六个图像的集合，这些图像彼此具有空间关系。特别地，每个图像对应于沿着3D坐标系的一个轴的方向。</p><p>在下图中，包含立方体贴图的六个纹理被布置为从内部显示立方体。 -Y脸在十字架的中间。</p><h4 id="The-Cube-Map-Coordinate-Space-立方体地图坐标空间"><a href="#The-Cube-Map-Coordinate-Space-立方体地图坐标空间" class="headerlink" title="The Cube Map Coordinate Space(立方体地图坐标空间)"></a>The Cube Map Coordinate Space(立方体地图坐标空间)</h4><p>Metal中的立方体贴图是左撇子，这意味着如果您想象自己位于立方体内部，右侧是+X面，而上面是+Y面，则+Z轴将是直接前面的那个。相反，如果您位于立方体之外，则坐标系似乎是右手的，并且所有图像都是镜像的。</p><p><img src="/2020/02/23/实例学习Metal-第八章/1584066232.png" alt=""></p><center>图8.4：未包装的立方体贴图。</center><h4 id="Creating-and-Loading-a-Cube-Map-Texture-创建和加载多维数据集地图纹理"><a href="#Creating-and-Loading-a-Cube-Map-Texture-创建和加载多维数据集地图纹理" class="headerlink" title="Creating and Loading a Cube Map Texture(创建和加载多维数据集地图纹理)"></a>Creating and Loading a Cube Map Texture(创建和加载多维数据集地图纹理)</h4><p>创建立方体纹理并使用图像数据加载它与创建和加载2D纹理类似，但有一些例外。</p><p>第一个区别是纹理类型。 MTLTextureDescriptor有一个方便的方法来创建描述立方体纹理的纹理描述符。描述符的textureType属性设置为MTLTextureTypeCube，高度和宽度属性设置为size参数。立方体纹理的所有组成纹理的宽度和高度必须相等。</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="built_in">MTLTextureDescriptor</span> textureCubeDescriptorWithPixelFormat:<span class="built_in">MTLPixelFormatRGBA8Unorm</span></span><br><span class="line">size:cubeSize mipmapped:<span class="literal">NO</span>];</span><br></pre></td></tr></table></figure><p>从描述符创建纹理对象的方式与创建2D纹理时的方式相同：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">id</span>&lt;<span class="built_in">MTLTexture</span>&gt; texture = [device newTextureWithDescriptor:textureDescriptor];</span><br></pre></td></tr></table></figure><p>2D纹理和立方体纹理之间的另一个区别是图像数据的加载方式。因为立方体纹理实际上包含六个不同的图像，所以我们必须在为每个面设置像素数据时指定切片参数。每个切片对应一个立方体面，具有以下映射：</p><table><thead><tr><th>Face number</th><th>Cube texture face</th></tr></thead><tbody><tr><td>0</td><td>Positive X</td></tr><tr><td>1</td><td>Negative X</td></tr><tr><td>2</td><td>Positive Y</td></tr><tr><td>3</td><td>Negative Y</td></tr><tr><td>4</td><td>Positive Z</td></tr><tr><td>5</td><td>Negative X</td></tr></tbody></table><p>要将数据加载到每个立方体面，我们迭代切片，用适当的图像数据替换切片的整个区域：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> slice = <span class="number">0</span>; slice &lt; <span class="number">6</span>; ++slice&gt;)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="comment">// fetch image data for current cube face</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    [texture replaceREgion:region</span><br><span class="line">               mipmapLevel:<span class="number">0</span></span><br><span class="line">                     slice:slice</span><br><span class="line">                 withBytes:imageData</span><br><span class="line">               bytesPerRow:bytesPerRow</span><br><span class="line">             bytesPerImage:bytesPerImage];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">`imageData`必须采用纹理描述符中指定的任何像素格式。 `bytesPerRow`是多维数据集的宽度乘以每个像素的字节数。反过来，`bytesPerImage`是每行的字节数乘以多维数据集的高度。由于宽度和高度相等，您可以在这些计算中替换立方体边长。</span><br><span class="line"></span><br><span class="line"><span class="meta">#### Sampling a Cube Map(采样立方体贴图)</span></span><br><span class="line"></span><br><span class="line">立方体贴图纹理坐标的工作方式与<span class="number">2</span>D纹理坐标略有不同。第一个区别是需要三个坐标来采样立方体贴图，而不是两个。三个坐标被视为起源于立方体中心的射线，与立方体上特定点处的面相交。通过这种方式，立方体纹理坐标表示方向而不是特定点。</span><br><span class="line"></span><br><span class="line">以这种方式采样时会出现一些有趣的边缘情况。例如，三角形的三个顶点可能会跨越立方体贴图的角，对三个不同的面进行采样。金属通过沿立方体的边缘和角落正确插入样本来自动处理此类情况。</span><br><span class="line"></span><br><span class="line"><span class="meta">### Applications of Cube Maps(立方体贴图的应用)</span></span><br><span class="line"></span><br><span class="line">现在我们知道如何创建，加载和采样立方体贴图，让我们来谈谈我们可以使用立方体贴图实现的一些有趣效果。首先，我们需要纹理我们的天空盒。</span><br><span class="line"></span><br><span class="line"><span class="meta">#### Texturing the Skybox(纹理天空盒)</span></span><br><span class="line"></span><br><span class="line">回想一下，我们从一组静态数据创建了我们的天空盒网格，这些静态数据表示关于原点的单位立方体。单位立方体的角的位置精确映射到立方体贴图的角落纹理坐标，因此可以将立方体的顶点位置重复为其纹理坐标，忽略面法线。</span><br><span class="line"></span><br><span class="line"><span class="meta">#### Drawing the Skybox(回执天空盒)</span></span><br><span class="line"></span><br><span class="line">渲染天空盒时，一个非常重要的考虑因素是它对深度缓冲区的影响。由于天空盒旨在成为场景的背景，场景中的所有其他对象必须出现在其前面，以免打破幻觉。因此，始终在任何其他对象之前绘制天空框，并禁用写入深度缓冲区。这意味着在天空盒之后绘制的任何对象都用它们自己的像素替换它的像素。</span><br><span class="line">首先绘制天空盒还会引入一个小优化：因为天空盒覆盖了屏幕上的每个像素，所以在绘制场景之前不必清除渲染缓冲区的颜色纹理。</span><br><span class="line"></span><br><span class="line"><span class="meta">#### The Skybox Vertex Shader(天空盒顶点着色器)</span></span><br><span class="line"></span><br><span class="line">天空盒的顶点着色器非常简单。根据组合模型 - 视图 - 投影矩阵投影位置，并将纹理坐标设置为立方角的模型空间位置。</span><br></pre></td></tr></table></figure><p>vertex ProjectedVertex vertex_skybox(device Vertex *vertices [[buffer(0)]], constant Uniforms &amp;uniforms [[buffer(1)]], uint vid [[vertex_id]])<br>{<br>float4 position = vertices[vid].position;<br>ProjectedVertex outVert;<br>outVert.position = uniforms.modelViewProjectionMatrix * position; outVert.texCoords = position;<br>return outVert;<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#### The Fragment Shader(片段着色器)</span><br><span class="line"></span><br><span class="line">我们将对天空盒和圆环结图使用相同的片段着色器。片段着色器只是反转纹理坐标的z坐标，然后在适当的方向上对纹理立方体进行采样：</span><br></pre></td></tr></table></figure><p>fragment half4 fragment_cube_lookup(ProjectedVertex vert [[stage_in]], constant Uniforms &amp;uniforms [[buffer(0)]],<br>texturecube<half> cubeTexture [[texture(0)]],<br>sampler cubeSampler [[sampler(0)]])<br>{<br>float3 texCoords = float3(vert.texCoords.x, vert.texCoords.y,<br>-vert.texCoords.z);<br>return cubeTexture.sample(cubeSampler, texCoords);<br>}</half></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">在这种情况下我们反转z坐标，因为立方体贴图的坐标系是从内部看的左手（借用OpenGL的惯例），但我们更喜欢右手坐标系。这只是示例应用程序采用的惯例;您可能更喜欢使用左手坐标。一致性和正确性比常规更重要。</span><br><span class="line"></span><br><span class="line">### The Physics of Reflection(反射物理)</span><br><span class="line"></span><br><span class="line">当光从反射表面反弹时发生反射。在这里，我们只考虑完美的镜面反射，即所有光线以与入射角度相等的角度反弹的情况。为了模拟虚拟场景中的反射，我们向后运行此过程，跟踪来自虚拟相机的光线穿过场景，将其从表面反射，并确定它与我们的立方体贴图相交的位置。</span><br><span class="line"></span><br><span class="line">![](1584066435.png)</span><br><span class="line">&lt;center&gt;图8.5：光线以等于其入射角的角度反射&lt;/center&gt;</span><br><span class="line"></span><br><span class="line">#### The Reflection Vertex Shader(反射顶点着色器)</span><br><span class="line"></span><br><span class="line">要计算给定矢量的立方体贴图纹理坐标，我们需要找到从虚拟摄像机指向当前顶点的矢量及其法线。这些向量必须都相对于世界坐标系。我们传递到顶点着色器的制服包括模型矩阵以及法线矩阵（它是模型矩阵的逆转置）。这允许我们根据上面给出的公式计算用于找到反射矢量的必要矢量。</span><br><span class="line"></span><br><span class="line">幸运的是，Metal包含一个内置函数，可以为我们进行矢量数学运算。 reflect有两个参数：输入向量和表面法向量。它返回反射向量。为了使数学运算正确，两个输入向量都应该提前标准化。</span><br><span class="line"></span><br><span class="line">```C++</span><br><span class="line">vertex ProjectedVertex vertex_reflect(device Vertex *vertices [[buffer(0)]], constant Uniforms &amp;uniforms [[buffer(1)]], uint vid [[vertex_id]])</span><br><span class="line">&#123;</span><br><span class="line">    float4 modelPosition = vertices[vid].position; </span><br><span class="line">    float4 modelNormal = vertices[vid].normal;</span><br><span class="line">    float4 worldCameraPosition = uniforms.worldCameraPosition;</span><br><span class="line">    float4 worldPosition = uniforms.modelMatrix * modelPosition;</span><br><span class="line">    float4 worldNormal = normalize(uniforms.normalMatrix * modelNormal); </span><br><span class="line">    float4 worldEyeDirection = normalize(worldPosition - worldCameraPosition);</span><br><span class="line">    ProjectedVertex outVert;</span><br><span class="line">    outVert.position = uniforms.modelViewProjectionMatrix * modelPosition; </span><br><span class="line">    outVert.texCoords = reflect(worldEyeDirection, worldNormal);</span><br><span class="line">    return outVert; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出顶点纹理坐标由硬件插值并传递给我们已经看到的片段着色器。这会产生每像素反射的效果，因为片段着色器的每次执行都使用一组不同的纹理坐标来绘制立方体贴图。</p><h4 id="The-Physics-of-Refraction-折射物理学"><a href="#The-Physics-of-Refraction-折射物理学" class="headerlink" title="The Physics of Refraction(折射物理学)"></a>The Physics of Refraction(折射物理学)</h4><p>我们将建模的第二个现象是折射。当光从一种介质传递到另一种介质时发生折射。一个日常的例子是稻草如何在一杯水中弯曲。</p><p><img src="/2020/02/23/实例学习Metal-第八章/1584066459.png" alt=""></p><center>图8.6：通过圆环结折射的环境贴图</center><p>我们不会在这里详细讨论折射的数学，但是折射的基本特征是光的弯曲量与它所经过的两种介质的折射率之间的比率成比例。物质的折射率是无单位量，表征相对于真空，它减慢了光的传播速度。空气指数接近1，而水指数约为1.333，玻璃指数约为1.5。</p><p>折射遵循一项称为Snell定律的定律，该定律指出入射角和透射角的正弦比等于介质折射率的反比：<br>sin(θI)/sin(θT) = η<sub>1</sub>/η<sub>0</sub></p><p><img src="/2020/02/23/实例学习Metal-第八章/1584066538.png" alt=""></p><center>图8.7：当光线在具有不同折射率的物质之间通过时，光线会弯曲</center><h4 id="The-Refraction-Vertex-Shader-折射顶点着色器"><a href="#The-Refraction-Vertex-Shader-折射顶点着色器" class="headerlink" title="The Refraction Vertex Shader(折射顶点着色器)"></a>The Refraction Vertex Shader(折射顶点着色器)</h4><p>用于折射的顶点着色器与用于反射的顶点着色器相同，不同之处在于我们使用不同的内置函数refract。我们提供了入射矢量，表面法线和两种物质之间的比例（空气和玻璃，在样本代码的情况下）。返回折射矢量并将其用作立方体贴图纹理，如前所述。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">vertex ProjectedVertex vertex_refract(device Vertex *vertices [[buffer(0)]], constant Uniforms &amp;uniforms [[buffer(1)]], uint vid  [[vertex_id]])</span><br><span class="line">&#123;</span><br><span class="line">    float4 modelPosition = vertices[vid].position; </span><br><span class="line">    float4 modelNormal = vertices[vid].normal;</span><br><span class="line"></span><br><span class="line">    float4 worldCameraPosition = uniforms.worldCameraPosition;</span><br><span class="line">    float4 worldPosition = uniforms.modelMatrix * modelPosition;</span><br><span class="line">    float4 worldNormal = normalize(uniforms.normalMatrix * modelNormal); </span><br><span class="line">    float4 worldEyeDirection = normalize(worldPosition - worldCameraPosition);</span><br><span class="line"></span><br><span class="line">    ProjectedVertex outVert;</span><br><span class="line">    outVert.position = uniforms.modelViewProjectionMatrix * modelPosition; </span><br><span class="line">    outVert.texCoords = refract(worldEyeDirection, worldNormal, kEtaRatio);</span><br><span class="line">   </span><br><span class="line">    return outVert; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Using-Core-Motion-to-Orient-the-Scene-使用Core-Motion定位场景"><a href="#Using-Core-Motion-to-Orient-the-Scene-使用Core-Motion定位场景" class="headerlink" title="Using Core Motion to Orient the Scene(使用Core Motion定位场景)"></a>Using Core Motion to Orient the Scene(使用Core Motion定位场景)</h3><p>本章的示例代码位于09-CubeMapping目录中。</p><p>示例应用程序中的场景包含一个被天空盒包围的圆环结。圆环结反射或折射周围的场景;你可以点击两者之间交替。</p><h4 id="The-Motion-Manager-运动管理器"><a href="#The-Motion-Manager-运动管理器" class="headerlink" title="The Motion Manager(运动管理器)"></a>The Motion Manager(运动管理器)</h4><p>应用程序使用设备的方向旋转场景，以便环面始终显示在中心，环境围绕它旋转。这是通过Core Motion框架中的<code>CMMotionManager</code>类实现的。<br>要使用运动管理器跟踪设备的运动，首先应检查设备是否可用。如果是，您可以继续设置更新间隔并请求运动管理器开始跟踪运动。以下代码执行这些步骤，每秒请求更新60次。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CMMotionManager *motionManager = [[CMMotionManager alloc] init]; </span><br><span class="line">if (motionManager.deviceMotionAvailable)</span><br><span class="line">&#123;</span><br><span class="line">    motionManager.deviceMotionUpdateInterval = 1 / 60.0; </span><br><span class="line">    CMAttitudeReferenceFrame frame = CMAttitudeReferenceFrameXTrueNorthZVertical;</span><br><span class="line">    [motionManager startDeviceMotionUpdatesUsingReferenceFrame:frame]; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Reference-Frames-and-Device-Orientation-参考框架和设备方向"><a href="#Reference-Frames-and-Device-Orientation-参考框架和设备方向" class="headerlink" title="Reference Frames and Device Orientation(参考框架和设备方向)"></a>Reference Frames and Device Orientation(参考框架和设备方向)</h4><p>参考系是指定设备方向的一组轴。有几种不同的参考框架可供选择。它们中的每一个都将Z标识为垂直轴，而X轴的对齐可以根据应用的需要进行选择。我们选择将X轴与磁北对齐，以便虚拟场景的方向与外界直观对齐，并在应用程序运行之间保持一致。</p><p>设备方向可以被认为是相对于参考系的旋转。旋转的基础使其轴与设备的轴对齐，+X指向设备的右侧，+Y指向设备的顶部，+Z指向前方的屏幕。</p><h4 id="Reading-the-Current-Orientation-读取当前的方向"><a href="#Reading-the-Current-Orientation-读取当前的方向" class="headerlink" title="Reading the Current Orientation(读取当前的方向)"></a>Reading the Current Orientation(读取当前的方向)</h4><p>每一帧，我们都想获得更新的设备方向，因此我们可以将虚拟场景与现实世界对齐。我们通过从动画管理器中请求CMDeviceMotion的实例来完成此操作。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CMDeviceMotion *motion = motionManager.deviceMotion;</span><br></pre></td></tr></table></figure><p>设备运动对象以几种等效形式提供设备方向：欧拉角，旋转矩阵和四元数。由于我们已经使用矩阵来代表我们的Metal代码中的旋转，因此它们最适合将Core Motion的数据合并到我们的应用程序中。</p><p>每个人都有自己对于哪个视图坐标空间最直观的看法，但我们总是选择右手系统，+ Y朝上，+ X朝右，+ Z指向观察者。这与Core Motion的惯例不同，因此为了使用设备方向数据，我们按照以下方式解释Core Motion的轴：Core Motion的X轴成为我们世界的Z轴，Z变为Y，Y变为X.我们不必镜像任何轴，因为Core Motion的参考框架都是右手的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CMRotationMatrix m = motion.attitude.rotationMatrix;</span><br><span class="line"></span><br><span class="line">vector_float4 X = &#123; m.m12, m.m22, m.m32, 0 &#125;; </span><br><span class="line">vector_float4 Y = &#123; m.m13, m.m23, m.m33, 0 &#125;; </span><br><span class="line">vector_float4 Z = &#123; m.m11, m.m21, m.m31, 0 &#125;;</span><br><span class="line">vector_float4 W = &#123; 0, 0, 0, 1 &#125;;</span><br><span class="line"></span><br><span class="line">matrix_float4x4 orientation = &#123; X, Y, Z, W &#125;; renderer.sceneOrientation = orientation;</span><br></pre></td></tr></table></figure><p>渲染器将​​场景方向矩阵合并到它为场景构造的视图矩阵中，从而使场景与物理世界保持一致。</p><h3 id="The-Sample-App-示例应用"><a href="#The-Sample-App-示例应用" class="headerlink" title="The Sample App(示例应用)"></a>The Sample App(示例应用)</h3><p>本章的示例代码位于08-CubeMapping目录中。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在本章中，我们将讨论Metal中一些更高级的纹理功能。我们将立方体贴图应用于天空盒以模拟周围的详细环境现场。我们还将介绍一种称为立方体环境映射的技术来模拟反射和折射，以进一步增强我们虚拟世界的真实感。&lt;/p&gt;
    
    </summary>
    
    
      <category term="iOS/Mac" scheme="https://zhaolilong.com/tags/iOS-Mac/"/>
    
      <category term="图形学" scheme="https://zhaolilong.com/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
      <category term="Metal" scheme="https://zhaolilong.com/tags/Metal/"/>
    
  </entry>
  
  <entry>
    <title>实例学习Metal-第七章 纹理贴图</title>
    <link href="https://zhaolilong.com/2020/02/16/%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0Metal-%E7%AC%AC%E4%B8%83%E7%AB%A0/"/>
    <id>https://zhaolilong.com/2020/02/16/实例学习Metal-第七章/</id>
    <published>2020-02-15T16:00:00.000Z</published>
    <updated>2020-03-13T02:13:14.256Z</updated>
    
    <content type="html"><![CDATA[<p>在本章中，我们将学习mipmapping，这是一种在远处渲染纹理对象的重要技术。我们将找出为什么mipmapping很重要，它如何补充常规纹理过滤，以及如何使用blit命令编码器在GPU上有效地生成mipmap。</p><a id="more"></a><h1 id="Chapter7-第七章"><a href="#Chapter7-第七章" class="headerlink" title="Chapter7(第七章)"></a>Chapter7(第七章)</h1><h2 id="Mipmapping-纹理贴图"><a href="#Mipmapping-纹理贴图" class="headerlink" title="Mipmapping(纹理贴图)"></a>Mipmapping(纹理贴图)</h2><p>在本章中，我们将学习mipmapping，这是一种在远处渲染纹理对象的重要技术。我们将找出为什么mipmapping很重要，它如何补充常规纹理过滤，以及如何使用blit命令编码器在GPU上有效地生成mipmap。</p><h3 id="A-Review-of-Texture-Filtering-纹理过滤研究综述"><a href="#A-Review-of-Texture-Filtering-纹理过滤研究综述" class="headerlink" title="A Review of Texture Filtering(纹理过滤研究综述)"></a>A Review of Texture Filtering(纹理过滤研究综述)</h3><p>在上一章中，我们使用纹理过滤来描述当像素的屏幕空间大小与纹素的大小不同时，纹素应如何映射到像素。当每个纹素映射到多个像素时，这称为<code>放大率</code>，当每个像素映射到多个纹素时，这称为<code>缩小</code>。在Metal中，我们可以选择在这两种方案中应用哪种类型的过滤。</p><p>最近的过滤只选择最接近的纹理像素来表示采样点。这导致块状输出图像，但计算上便宜。线性滤波选择四个相邻纹素并生成它们的加权平均值。</p><p>在Metal中，我们指定过滤类型使用MTLSamplerDescriptor的minFilter和magFilter属性。</p><p><img src="/2020/02/16/实例学习Metal-第七章/1584065223.png" alt=""></p><center>图7.1：示例应用程序说明了各种mipmapping过滤器的效果。这里使用的mipmap是人工着色的，用于演示目的。</center><h3 id="Mipmap-Theory-纹理贴图原理"><a href="#Mipmap-Theory-纹理贴图原理" class="headerlink" title="Mipmap Theory(纹理贴图原理)"></a>Mipmap Theory(纹理贴图原理)</h3><p>名称“mipmap”来自拉丁语短语“multum in parvo”，大致意思是“很少”。这暗示了mipmap中的每个纹素都结合了几个在它上面的水平的纹素。在我们讨论如何构建纹理贴图之前，让我们花一些时间来讨论为什么我们首先需要它们。</p><h4 id="The-Aliasing-Problem-锯齿问题"><a href="#The-Aliasing-Problem-锯齿问题" class="headerlink" title="The Aliasing Problem(锯齿问题)"></a>The Aliasing Problem(锯齿问题)</h4><p>你可能会认为，因为我们处理了纹理缩小和放大的情况，我们的纹理贴图应该是完美的，没有视觉伪像。不幸的是，当纹理缩小超过某个因素时，会产生一种邪恶的效果。</p><p>当虚拟相机跨越场景时，每帧使用不同的纹理像素集来确定包括远处对象的像素的颜色。无论选择何种缩小滤镜，都会发生这种情况。在视觉上，这会产生难看的闪光。问题基本上是对高频信号进行欠采样（在这种情况下信号是纹理）。如果有一种方法可以在采样过程中平滑纹理，我们可以换取少量的模糊度，以显着减少运动过程中的分解闪烁效应。</p><p>使用线性缩小滤波器和线性缩小滤波器结合mipmap之间的区别如下所示，以激发进一步的讨论。</p><p><img src="/2020/02/16/实例学习Metal-第七章/1584065357.png" alt=""></p><center>图7.2：基本线性滤波和mipmapped线性滤波的并排比较</center><h4 id="The-Mipmap-Solution-Mipmap解决方案"><a href="#The-Mipmap-Solution-Mipmap解决方案" class="headerlink" title="The Mipmap Solution(Mipmap解决方案)"></a>The Mipmap Solution(Mipmap解决方案)</h4><p>Mipmapping是一种设计用于解决此混叠问题的技术。不是在运行中对图像进行下采样，而是在离线或加载时生成一系列预滤波图像（级别）。每个级别比其前身小两倍（沿每个维度）。这导致每个纹理的内存使用量增加33％，但可以极大地增强运动中场景的保真度。</p><p>在下图中，显示了为棋盘纹理生成的级别。</p><p><img src="/2020/02/16/实例学习Metal-第七章/1584065467.png" alt=""></p><center>图7.3：构成mipmap的各个级别。每个图像的大小是其前一个图像的一半，面积的1/4，低至1个像素。</center><h4 id="Mipmap-Sampling-Mipmap采样"><a href="#Mipmap-Sampling-Mipmap采样" class="headerlink" title="Mipmap Sampling(Mipmap采样)"></a>Mipmap Sampling(Mipmap采样)</h4><p>当对mipmapped纹理进行采样时，片段的投影区域用于确定哪个mipmap级别最接近纹理的纹素大小。相对于纹素大小较小的片段使用已经减少到更大程度的mipmap级别。</p><p>在Metal中，mipmap过滤器与缩小过滤器分开指定，在描述符的mipFilter属性中，但min和mip过滤器交互以创建四种可能的场景。下面按照增加计算成本的顺序描述它们。</p><p>当minFilter设置为MTLSamplerMinMagFilterNearest并且mipFilter设置为MTLSamplerMipFilterNearest时，将选择最接近匹配的mipmap级别，并使用其中的单个纹素作为样本。</p><p>当minFilter设置为MTLSamplerMinMagFilterNearest且mipFilter设置为MTLSamplerMipFilterLinear时，将选择两个最接近匹配的mipmap级别，并从中获取一个样本。然后将这两个样品平均以产生最终样本。</p><p>当minFilter设置为MTLSamplerMinMagFilterLinear并且mipFilter设置为MTLSamplerMipFilterNearest时，将选择最接近匹配的mipmap级别，并平均四个纹素以生成样本。</p><p>当minFilter设置为MTLSamplerMinMagFilterLinear并且mipFilter设置为MTLSamplerMipFilterLinear时，将选择两个最接近匹配的mipmap级别，并对每个级别的四个样本进行平均以创建该级别的样本。然后将这两个平均样本再次平均以产生最终样本。</p><p>下图显示了使用线性最小值滤波器时使用最近和线性mip滤波器之间的差异：</p><p><img src="/2020/02/16/实例学习Metal-第七章/1584065494.png" alt=""></p><center>图7.4：使用线性最小值滤波器和最近的mip滤波器的效果。 Mip水平已经人工着色，以更清楚地显示不同的水平。</center><p><img src="/2020/02/16/实例学习Metal-第七章/1584065514.png" alt=""></p><center>图7.5：使用线性最小值滤波器和线性mip滤波器的效果。 Mip水平已经人工着色，以更清楚地显示不同的水平。</center><h3 id="Mipmapped-Textures-in-Metal-Metal中的Mipmapped纹理"><a href="#Mipmapped-Textures-in-Metal-Metal中的Mipmapped纹理" class="headerlink" title="Mipmapped Textures in Metal(Metal中的Mipmapped纹理)"></a>Mipmapped Textures in Metal(Metal中的Mipmapped纹理)</h3><p>在Metal中构建一个mipmap纹理是一个由两部分组成的过程：创建纹理对象并将图像数据复制到mipmap级别。 Metal不会自动为我们生成mipmap级别，因此我们将在下面介绍两种自行生成方式。</p><h4 id="Creating-the-Texture-创建纹理"><a href="#Creating-the-Texture-创建纹理" class="headerlink" title="Creating the Texture(创建纹理)"></a>Creating the Texture(创建纹理)</h4><p>我们可以使用相同的便捷方法来创建2D mipmapped纹理描述符，就像非mipmapped纹理一样，传递YES作为最终参数。</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="built_in">MTLTextureDescriptor</span> texture2DDescriptorWithPixelFormat:<span class="built_in">MTLPixelFormatRGBA8Unorm</span></span><br><span class="line">width:width height:height mipmapped:<span class="literal">YES</span>];</span><br></pre></td></tr></table></figure><p>当mipmapped参数等于YES时，Metal会计算描述符<code>mipmapLevelCount</code>属性。用于查找级别数的公式是floor（log2（max（width，height）））+ 1.例如，512×256纹理有10个级别。</p><p>一旦我们有了描述符，我们就从Metal设备请求一个纹理对象：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">id</span>&lt;<span class="built_in">MTLTexture</span>&gt; texture = [device newTextureWithDescriptor:descriptor];</span><br></pre></td></tr></table></figure><h4 id="Generating-Mipmap-Levels-Manually-手动生成Mipmap级别"><a href="#Generating-Mipmap-Levels-Manually-手动生成Mipmap级别" class="headerlink" title="Generating Mipmap Levels Manually(手动生成Mipmap级别)"></a>Generating Mipmap Levels Manually(手动生成Mipmap级别)</h4><p>创建mipmap级别涉及创建基本图像的越来越小的版本，直到级别的维度仅为一个像素大小。<br>iOS和OS X共享一个名为Core Graphics的框架，该框架具有用于绘制形状，文本和图像的低级实用程序。生成mipmap级别包括使用CGBitmapContextCreate创建位图上下文，使用CGContextDrawImage将基本图像绘制到其中，然后将基础数据复制到Metal纹理的相应级别，如下所示：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">MTLRegion</span> region = <span class="built_in">MTLRegionMake2D</span>(<span class="number">0</span>, <span class="number">0</span>, mipWidth, mipWidth); [texture replaceRegion:region</span><br><span class="line">mipmapLevel:level withBytes:mipImageData bytesPerRow:mipWidth * bytesPerPixel]</span><br></pre></td></tr></table></figure><p>对于级别1，mipWidth和mipHeight等于原始图像大小的一半。每次围绕mipmap生成循环，宽度和高度减半，级别被添加，并且过程重复直到生成所有级别。<br>在示例应用程序中，色调颜色应用于使用Core Graphics生成的每个mipmap级别，以便可以轻松区分它们。下图显示了由Core Graphics生成的包含棋盘纹理的图像。</p><p><img src="/2020/02/16/实例学习Metal-第七章/1584065574.png" alt=""></p><center>图7.6：CPU生成的mipmap级别;在每个级别应用了一种色调颜色，以便在渲染时将其区分开来</center><h3 id="The-Blit-Command-Encoder-Blit命令编码器"><a href="#The-Blit-Command-Encoder-Blit命令编码器" class="headerlink" title="The Blit Command Encoder(Blit命令编码器)"></a>The Blit Command Encoder(Blit命令编码器)</h3><p>在CPU上生成mipmap的主要缺点是速度。使用Core Graphics缩小图像比使用GPU要<strong>容易十倍</strong>。但是我们如何将工作卸载到GPU？令人高兴的是，Metal包含一种特殊类型的命令编码器，其作用是利用GPU进行图像复制和调整操作大小：blit命令编码器。术语“blit”是短语“block transfer”的衍生词。</p><h4 id="Capabilities-of-the-Blit-Command-Encoder-Blit命令编码器的功能"><a href="#Capabilities-of-the-Blit-Command-Encoder-Blit命令编码器的功能" class="headerlink" title="Capabilities of the Blit Command Encoder(Blit命令编码器的功能)"></a>Capabilities of the Blit Command Encoder(Blit命令编码器的功能)</h4><p>Blit命令编码器支持GPU资源（缓冲区和纹理）之间的硬件加速传输。 blit命令编码器可用于填充具有特定值的缓冲区，将一个纹理的一部分复制到另一个纹理中，并在缓冲区和纹理之间进行复制。</p><p>我们不会在本章中探讨blit命令编码器的所有功能。我们将使用它来生成mipmap的所有级别。</p><h4 id="Capabilities-of-the-Blit-Command-Encoder-使用Blit命令编码器生成Mipmap"><a href="#Capabilities-of-the-Blit-Command-Encoder-使用Blit命令编码器生成Mipmap" class="headerlink" title="Capabilities of the Blit Command Encoder(使用Blit命令编码器生成Mipmap)"></a>Capabilities of the Blit Command Encoder(使用Blit命令编码器生成Mipmap)</h4><p>使用blit命令编码器生成mipmap是非常简单的，因为有一个名为generateMipmapsForTexture的MTLBlitCommandEncoder协议上的方法：调用此方法后，我们添加一个完成处理程序，以便我们知道何时<br>命令完成。这个过程非常快，在A8处理器上的1024×1024纹理大约需要1毫秒。</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">id</span>&lt;<span class="built_in">MTLBlitCommandEncoder</span>&gt; commandEncoder = [commandBuffer blitCommandEncoder]; </span><br><span class="line">[commandEncoder generateMipmapsForTexture:texture];</span><br><span class="line">[commandEncoder endEncoding];</span><br><span class="line">[commandBuffer addCompletedHandler:^(<span class="keyword">id</span>&lt;<span class="built_in">MTLCommandBuffer</span>&gt; buffer) &#123;</span><br><span class="line"><span class="comment">// texture is now ready for use &#125;];</span></span><br><span class="line">[commandBuffer commit];</span><br></pre></td></tr></table></figure><p>调用完成块时，纹理已准备好用于渲染。</p><h3 id="The-Sample-App-示例应用"><a href="#The-Sample-App-示例应用" class="headerlink" title="The Sample App(示例应用)"></a>The Sample App(示例应用)</h3><p>本章的示例代码位于07-Mipmapping目录中。</p><p>示例应用程序显示旋转的纹理立方体。您可以使用轻击手势在多种不同模式之间切换：无mipmapping，使用GPU生成的纹理进行mipmapping，使用CPU生成的纹理进行mipmapping和线性mip过滤，以及使用CPU生成的纹理和最近的mip过滤进行mipmapping。 CPU生成的纹理具有应用于每个级别的不同颜色的色调，以明确对哪些级别进行采样。</p><p>如果启用了mipmapping，则可以使用捏合手势将立方体缩放得更近和更远，这将导致对不同的mipmap级别进行采样。您还可以观察到当立方体接近边缘时，或者当它离开相机时不使用mipmap导致的降级。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在本章中，我们将学习mipmapping，这是一种在远处渲染纹理对象的重要技术。我们将找出为什么mipmapping很重要，它如何补充常规纹理过滤，以及如何使用blit命令编码器在GPU上有效地生成mipmap。&lt;/p&gt;
    
    </summary>
    
    
      <category term="iOS/Mac" scheme="https://zhaolilong.com/tags/iOS-Mac/"/>
    
      <category term="图形学" scheme="https://zhaolilong.com/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
      <category term="Metal" scheme="https://zhaolilong.com/tags/Metal/"/>
    
  </entry>
  
  <entry>
    <title>实例学习Metal-第六章 纹理</title>
    <link href="https://zhaolilong.com/2020/02/09/%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0Metal-%E7%AC%AC%E5%85%AD%E7%AB%A0/"/>
    <id>https://zhaolilong.com/2020/02/09/实例学习Metal-第六章/</id>
    <published>2020-02-08T16:00:00.000Z</published>
    <updated>2020-03-13T02:05:29.922Z</updated>
    
    <content type="html"><![CDATA[<p>纹理是渲染的核心主题。虽然它们有许多用途，但它们的主要目的之一是为表面提供比单独使用顶点颜色更高的细节水平。使用纹理贴图允许我们基本上按像素指定颜色，大大提高了渲染图像的视觉保真度。</p><a id="more"></a><p>Chapter 6(第六章)</p><h2 id="Textures-纹理"><a href="#Textures-纹理" class="headerlink" title="Textures(纹理)"></a>Textures(纹理)</h2><p>纹理是渲染的核心主题。虽然它们有许多用途，但它们的主要目的之一是为表面提供比单独使用顶点颜色更高的细节水平。使用纹理贴图允许我们基本上按像素指定颜色，大大提高了渲染图像的视觉保真度。</p><p>在接下来的几章中，我们将讨论与Metal中纹理的使用相关的几个主题。</p><p>在本章中，我们将讨论纹理映射，它可以帮助我们将虚拟角色带入生活。我们还将介绍采样器，它们可以强大地控制在绘制时如何解释纹理数据。一路上，我们将得到名为Spot的卡通牛的协助。</p><p><img src="/2020/02/09/实例学习Metal-第六章/1584064666.png" alt=""></p><center>图6.1：Meet Spot。 （型号由Keenan Crane提供）</center><h3 id="Textures-纹理-1"><a href="#Textures-纹理-1" class="headerlink" title="Textures(纹理)"></a>Textures(纹理)</h3><p>纹理是格式化的图像数据。这使它们与缓冲区不同，缓冲区是非结构化的内存块。我们将在本章中使用的纹理类型是2D图像。尽管Metal支持其他几种纹理，但我们可以通过遍历纹理映射的示例来介绍几乎所有重要的概念。</p><h3 id="Texture-Mapping-纹理映射"><a href="#Texture-Mapping-纹理映射" class="headerlink" title="Texture Mapping(纹理映射)"></a>Texture Mapping(纹理映射)</h3><p>纹理映射是将网格中的每个顶点与纹理中的点相关联的过程。这与包装礼物类似，因为2D纸张包装纸（纹理）符合3D存在（网格）。</p><p>纹理映射通常使用专门的编辑工具完成。将网格展开为平面图形（2D图形，其尽可能多地保持3D模型的连通性），然后将其覆盖在纹理图像上。<br>下图显示了奶牛的三维模型（其组成面的边缘突出显示）及其对应的纹理贴图。注意到的各个部分<br>牛（头部，躯干，腿部，角部）已经在地图上分离，即使它们连接在3D模型上。</p><p><img src="/2020/02/09/实例学习Metal-第六章/1584064893.png" alt=""></p><center>图6.2：如何打开一头牛。网格被展平为2D表面，以便更容易将纹理坐标指定给顶点</center><h3 id="Coordinate-Systems-坐标系统"><a href="#Coordinate-Systems-坐标系统" class="headerlink" title="Coordinate Systems(坐标系统)"></a>Coordinate Systems(坐标系统)</h3><p>在Metal中，纹理的像素坐标系的原点与其左上角重合。这与UIKit中的坐标系相同。但是，它与OpenGL中的默认纹理坐标系不同，其中原点是左下角。<br>纹理坐标系的轴通常标记为s和t（或u和v），以区别于世界坐标系的x和y轴。</p><p><img src="/2020/02/09/实例学习Metal-第六章/1584064942.png" alt=""></p><center>图6.3：Metal的纹理坐标系的原点位于左上角。</center><h4 id="Pixel-Coordinates-Versus-Normalized-Coordinates-像素坐标与标准化坐标"><a href="#Pixel-Coordinates-Versus-Normalized-Coordinates-像素坐标与标准化坐标" class="headerlink" title="Pixel Coordinates Versus Normalized Coordinates(像素坐标与标准化坐标)"></a>Pixel Coordinates Versus Normalized Coordinates(像素坐标与标准化坐标)</h4><p>Metal足够灵活，允许我们指定像素坐标或标准化坐标中的纹理坐标。像素坐标范围从（0,0）到（width-1，height-1）。因此，它们取决于纹理图像的尺寸。归一化坐标范围从（0,0）到（1,1），这使得它们与图像大小无关。</p><p>我们选择在本章和本书的其余部分使用标准化坐标。</p><h3 id="Filtering-过滤"><a href="#Filtering-过滤" class="headerlink" title="Filtering(过滤)"></a>Filtering(过滤)</h3><p>纹理是由有限数量的像素（称为<code>纹素</code>）组成的离散图像。但是，在绘制时，可以以高于或低于其原始大小的分辨率绘制纹理。因此，重要的是能够确定纹理在其纹理像素之间应该是什么颜色，或者当许多纹理像素被碾压到相同的空间中时。当以大于其原始大小的大小绘制纹理时，这称为<code>放大</code>。在其原始分辨率下绘制纹理的逆过程称为<code>缩小</code>。</p><p>从纹理重建图像数据的过程称为过滤。Metal提供了两种不同的过滤模式：最近和线性。</p><p>最近（也称为“最近邻居”）过滤只是选择与请求的纹理坐标最接近的纹素。这具有非常快的优点，但是当纹理被放大时（即，当每个纹理像素覆盖多个像素时），它可能导致渲染图像看起来是块状的。</p><p>线性滤波选择四个最接近的纹素，并根据从采样坐标到纹素的距离产生加权平均值。线性滤波比最近邻滤波产生更加视觉上令人愉悦的结果，并且足够快速地实时执行。</p><h3 id="Mipmaps-纹理贴图"><a href="#Mipmaps-纹理贴图" class="headerlink" title="Mipmaps(纹理贴图)"></a>Mipmaps(纹理贴图)</h3><p>当纹理缩小时，多个纹素可以与单个像素重合。即使是场景中的轻微运动也会出现闪烁现象。线性过滤对情况没有帮助，因为覆盖每个像素的纹理像素集在帧与帧之间变化。</p><p>减轻此问题的一种方法是将纹理图像预滤波为一系列图像，称为mipmap。序列中的每个mipmap都是前一个图像的一半，大小为1×1。当缩小纹理时，最接近分辨率的mipmap将替换原始纹理图像。</p><p>下一章将深入介绍Mipmapping。</p><h3 id="Addressing-寻址"><a href="#Addressing-寻址" class="headerlink" title="Addressing(寻址)"></a>Addressing(寻址)</h3><p>通常，当将纹理坐标与网格的顶点相关联时，这些值沿两个轴被约束为[0,1]。然而，这并非总是如此。也可以使用负纹理坐标或大于1的坐标。当使用[0,1]范围之外的坐标时，采样器的寻址模式生效。可以选择各种不同的行为。</p><h4 id="Clamp-to-Edge-Addressing-钳位到边缘寻址"><a href="#Clamp-to-Edge-Addressing-钳位到边缘寻址" class="headerlink" title="Clamp-to-Edge Addressing(钳位到边缘寻址)"></a>Clamp-to-Edge Addressing(钳位到边缘寻址)</h4><p>在Clamp-to-Edge寻址中，对于越界值重复沿着纹理边缘的值。</p><p><img src="/2020/02/09/实例学习Metal-第六章/1584064983.png" alt=""></p><center>图6.4：Clamp-to-edge过滤重复纹理图像的外边缘以获得越界坐标</center><h4 id="Clamp-to-Zero-Addressing-钳位到零寻址"><a href="#Clamp-to-Zero-Addressing-钳位到零寻址" class="headerlink" title="Clamp-to-Zero Addressing(钳位到零寻址)"></a>Clamp-to-Zero Addressing(钳位到零寻址)</h4><p>在Clamp-to-Zero寻址中，越界坐标的采样值是黑色或清晰的，具体取决于纹理是否具有alpha颜色分量。</p><p><img src="/2020/02/09/实例学习Metal-第六章/1584065000.png" alt=""></p><center>Figure 6.5: Clamp-to-Zero过滤在纹理图像的边界之外产生黑色</center><h4 id="Repeat-Addressing-重复寻址"><a href="#Repeat-Addressing-重复寻址" class="headerlink" title="Repeat Addressing(重复寻址)"></a>Repeat Addressing(重复寻址)</h4><p>在重复寻址中，越界坐标围绕纹理的相应边缘并从零开始重复。换句话说，采样坐标是输入坐标的分数部分，忽略整数部分。</p><p><img src="/2020/02/09/实例学习Metal-第六章/1584065021.png" alt=""></p><center>图6.6：重复寻址通过重复对纹理进行平铺</center><h4 id="Mirrored-Repeat-Addressing-镜像重复寻址"><a href="#Mirrored-Repeat-Addressing-镜像重复寻址" class="headerlink" title="Mirrored Repeat Addressing(镜像重复寻址)"></a>Mirrored Repeat Addressing(镜像重复寻址)</h4><p>在镜像重复寻址中，采样坐标首先从0增加到1，然后减少回0，依此类推。这会导致纹理被翻转并在每个其他整数边界上重复。</p><p><img src="/2020/02/09/实例学习Metal-第六章/1584065040.png" alt=""></p><center>图6.7：镜像重复寻址首先重复围绕轴镜像的纹理，然后正常重复，依此类推</center><h3 id="Creating-Textures-in-Metal-在Metal中创建纹理"><a href="#Creating-Textures-in-Metal-在Metal中创建纹理" class="headerlink" title="Creating Textures in Metal(在Metal中创建纹理)"></a>Creating Textures in Metal(在Metal中创建纹理)</h3><p>在我们实际要求Metal创建纹理对象之前，我们需要更多地了解像素格式，以及如何将纹理数据添加到内存中。</p><h4 id="Pixel-Formats-像素格式"><a href="#Pixel-Formats-像素格式" class="headerlink" title="Pixel Formats(像素格式)"></a>Pixel Formats(像素格式)</h4><p><code>像素</code>格式描述了颜色信息在存储器中的布局方式。此信息有几个不同的方面：颜色<code>组件</code>，颜色组件<code>排序</code>，颜色组件<code>大小</code>以及是否存在<code>压缩</code>。<br>常见的颜色成分是红色，绿色，蓝色和alpha（透明度）。这些都可以存在（如RGBA格式），或者可以不存在一个或多个。在完全不透明的图像的情况下，省略了alpha信息。<br>颜色分量排序是指哪些颜色分量出现在存储器中：BGRA或RGBA。<br>颜色可以用任何精度表示，但是两个流行的选择是每个组件8位和每个组件32位。最常见的是，当使用8位时，每个组件都是无符号的8位整数，介于0和255之间。当使用32位时，每个组件通常是一个32位浮点，范围从0.0到1.0。显然，32位比8位提供更高的精度，但8位通常足以捕获颜色之间可感知的差异，并且从存储器的角度来看要好得多。<br>Metal支持的像素格式列在MTLPixelFormat枚举中。支持的格式因操作系统版本和硬件而异，请参阅“金属编程指南”以获取更多详细信息。</p><h4 id="Loading-Image-Data-加载图像数据"><a href="#Loading-Image-Data-加载图像数据" class="headerlink" title="Loading Image Data(加载图像数据)"></a>Loading Image Data(加载图像数据)</h4><p>我们将使用UIKit提供的强大实用程序从应用程序包中加载图像。要从包中的图像创建UIImage实例，我们只需要一行代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UIImage *image = [UIImage imageNamed:@&quot;my-texture-name&quot;];</span><br></pre></td></tr></table></figure><p>不幸的是，UIKit没有提供访问UIImage底层位的方法。相反，我们必须将图像绘制到Core Graphics位图上下文中，该上下文具有与所需纹理相同的格式。作为此过程的一部分，我们转换上下文（使用平移后跟刻度），以便生成的图像位垂直翻转。这会使我们图像的坐标空间与Metal的纹理坐标空间一致。</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">CGImageRef</span> imageRef = [image <span class="built_in">CGImage</span>];</span><br><span class="line"><span class="comment">// Create a suitable bitmap context for extracting the bits of the image NSUInteger width = CGImageGetWidth(imageRef);</span></span><br><span class="line"><span class="built_in">NSUInteger</span> height = <span class="built_in">CGImageGetHeight</span>(imageRef);</span><br><span class="line"><span class="built_in">CGColorSpaceRef</span> colorSpace = <span class="built_in">CGColorSpaceCreateDeviceRGB</span>();</span><br><span class="line">uint8_t *rawData = (uint8_t *)calloc(height * width * <span class="number">4</span>, <span class="keyword">sizeof</span>(uint8_t)); <span class="built_in">NSUInteger</span> bytesPerPixel = <span class="number">4</span>;</span><br><span class="line"><span class="built_in">NSUInteger</span> bytesPerRow = bytesPerPixel * width;</span><br><span class="line"><span class="built_in">NSUInteger</span> bitsPerComponent = <span class="number">8</span>;</span><br><span class="line"><span class="built_in">CGContextRef</span> context = <span class="built_in">CGBitmapContextCreate</span>(rawData, width, height,</span><br><span class="line">bitsPerComponent, bytesPerRow, colorSpace,</span><br><span class="line">kCGImageAlphaPremultipliedLast | kCGBitmapByteOrder32Big); <span class="built_in">CGColorSpaceRelease</span>(colorSpace);</span><br><span class="line"><span class="comment">// Flip the context so the positive Y axis points down CGContextTranslateCTM(context, 0, height); CGContextScaleCTM(context, 1, -1);</span></span><br><span class="line"><span class="built_in">CGContextDrawImage</span>(context, <span class="built_in">CGRectMake</span>(<span class="number">0</span>, <span class="number">0</span>, width, height), imageRef); <span class="built_in">CGContextRelease</span>(context);</span><br></pre></td></tr></table></figure><p>此代码包含在MTKTextureLoader实用程序类中。</p><h4 id="Texture-Descriptors-纹理描述符"><a href="#Texture-Descriptors-纹理描述符" class="headerlink" title="Texture Descriptors(纹理描述符)"></a>Texture Descriptors(纹理描述符)</h4><p>纹理描述符是一个轻量级对象，它指定纹理的尺寸和格式。在创建纹理时，您需要提供纹理描述符并接收符合MTLTexture协议的对象，该协议是MTLResource的子协议。纹理描述符（纹理类型，尺寸和格式）上指定的属性在创建纹理后是不可变的，但只要新数据的像素格式与像素格式匹配，您仍然可以更新纹理的内容。接收纹理。<br>MTLTextureDescriptor类提供了几种用于构建常见纹理类型的工厂方法。要描述2D纹理，您必须指定像素格式，纹理尺寸（以像素为单位），以及Metal是否应分配空间来存储纹理的相应mipmap级别。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[MTLTextureDescriptor texture2DDescriptorWithPixelFormat:MTLPixelFormatRGBA8Unorm</span><br><span class="line">width:width height:height mipmapped:YES];</span><br></pre></td></tr></table></figure><h4 id="Creating-a-Texture-Object-创建一个纹理对象"><a href="#Creating-a-Texture-Object-创建一个纹理对象" class="headerlink" title="Creating a Texture Object(创建一个纹理对象)"></a>Creating a Texture Object(创建一个纹理对象)</h4><p>现在创建纹理对象非常简单。我们只需通过提供有效的纹理描述符来从设备请求纹理：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">id</span>&lt;<span class="built_in">MTLTexture</span>&gt; texture = [<span class="keyword">self</span>.device newTextureWithDescriptor:textureDescriptor];</span><br></pre></td></tr></table></figure><h4 id="Updating-Texture-Contents-更新纹理内容"><a href="#Updating-Texture-Contents-更新纹理内容" class="headerlink" title="Updating Texture Contents(更新纹理内容)"></a>Updating Texture Contents(更新纹理内容)</h4><p>现在创建纹理对象非常简单。我们只需通过提供有效的纹理描述符来从设备请求纹理：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> <span class="built_in">MTLRegion</span> region = <span class="built_in">MTLRegionMake2D</span>(<span class="number">0</span>, <span class="number">0</span>, width, height); [texture replaceRegion:region mipmapLevel:<span class="number">0</span> withBytes:rawData</span><br><span class="line">bytesPerRow:bytesPerRow];</span><br></pre></td></tr></table></figure><h4 id="Passing-Textures-to-Shader-Functions-传递纹理到着色器函数"><a href="#Passing-Textures-to-Shader-Functions-传递纹理到着色器函数" class="headerlink" title="Passing Textures to Shader Functions(传递纹理到着色器函数)"></a>Passing Textures to Shader Functions(传递纹理到着色器函数)</h4><p>现在可以在着色器中使用此纹理。要将纹理传递给着色器函数，我们在发出绘制调用之前将它设置在命令编码器上。纹理在参数表中有自己的插槽与缓冲区分开，因此我们使用的索引从0开始。</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[commandEncoder setFragmentTexture:texture atIndex:<span class="number">0</span>];</span><br></pre></td></tr></table></figure><p>现在，此纹理可以绑定到着色器函数的参数列表中具有[[texture（0）]]属性的参数。</p><h3 id="Samplers-采样器"><a href="#Samplers-采样器" class="headerlink" title="Samplers(采样器)"></a>Samplers(采样器)</h3><p>在Metal中，采样器是一个对象，它封装了与读取纹理相关的各种渲染状态：坐标系，寻址模式和过滤。可以在着色器功能或应用程序代码中创建采样器。我们将在以下部分中依次讨论每个问题。</p><h4 id="Creating-Samplers-in-Shaders-在Shader中创建采样器"><a href="#Creating-Samplers-in-Shaders-在Shader中创建采样器" class="headerlink" title="Creating Samplers in Shaders(在Shader中创建采样器)"></a>Creating Samplers in Shaders(在Shader中创建采样器)</h4><p>我们将在片段函数中使用采样器，因为我们希望为渲染图像中的每个像素生成不同的颜色。因此，有时在片段函数中直接创建采样器是有意义的。<br>以下代码创建了一个采样器，它将使用重复寻址模式在标准化坐标空间中进行采样，并使用线性过滤：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">constexpr sampler s(coord::normalized, address::repeat, filter::linear);</span><br></pre></td></tr></table></figure><p>着色函数本地的采样器必须使用<code>constexpr</code>进行限定。这个关键字是C++ 11中的新关键字，表示可以在编译时而不是运行时计算表达式。这意味着将只创建一个采样器结构，以便在函数的所有调用中使用。</p><p>坐标值可以是<code>normalized</code>或<code>pixel</code>。</p><p>地址的可能值是<code>clamp_to_zero</code>，<code>clamp_to_edge</code>，<code>repeat</code>，<br><code>mirrored_repeat</code>。</p><p>过滤器的可能值最接近和线性’，以便在最近的位置之间进行选择邻居和线性过滤。</p><p>所有这些值都属于强类型枚举。强类型枚举是C ++ 11中的一项新功能，它允许对枚举值进行更严格的类型检查。省略值的类型名称是一个错误（即，你必须说<code>filter::linear</code>而不是简单的<code>linear</code>）。</p><p>可以按任何顺序指定参数，因为采样器的构造函数实现为可变参数模板函数（C++ 11的另一个新特性）。</p><h4 id="Using-a-Sampler-使用一个采样器"><a href="#Using-a-Sampler-使用一个采样器" class="headerlink" title="Using a Sampler(使用一个采样器)"></a>Using a Sampler(使用一个采样器)</h4><p>从采样器获取颜色很简单。纹理有一个示例函数，它采用一个采样器和一组纹理坐标，返回一种颜色。在着色器函数中，我们调用此函数，传入一个采样器和当前顶点的（插值）纹理坐标。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">float4 sampledColor = texture.sample(sampler, vertex.textureCoords);</span><br></pre></td></tr></table></figure><p>然后，采样的颜色可以用于您想要的任何进一步计算，例如照明。</p><h4 id="Creating-Samplers-in-Application-Code-在应用程序代码中创建采样器"><a href="#Creating-Samplers-in-Application-Code-在应用程序代码中创建采样器" class="headerlink" title="Creating Samplers in Application Code(在应用程序代码中创建采样器)"></a>Creating Samplers in Application Code(在应用程序代码中创建采样器)</h4><p>要在应用程序代码中创建一个采样器，我们填写MTLSamplerDescriptor对象并要求设备为我们提供一个采样器（符合MTLSamplerState的对象）。</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">MTLSamplerDescriptor</span> *samplerDescriptor = [<span class="built_in">MTLSamplerDescriptor</span> new]; </span><br><span class="line">samplerDescriptor.minFilter = <span class="built_in">MTLSamplerMinMagFilterNearest</span>; </span><br><span class="line">samplerDescriptor.magFilter = <span class="built_in">MTLSamplerMinMagFilterLinear</span>; </span><br><span class="line">samplerDescriptor.sAddressMode = <span class="built_in">MTLSamplerAddressModeClampToEdge</span>; </span><br><span class="line">samplerDescriptor.tAddressMode = <span class="built_in">MTLSamplerAddressModeClampToEdge</span>;</span><br><span class="line"></span><br><span class="line">samplerState = [device newSamplerStateWithDescriptor:samplerDescriptor];</span><br></pre></td></tr></table></figure><p>请注意，我们必须单独指定放大和缩小过滤器。在着色器代码中创建采样器时，我们使用filter参数同时指定两者，但我们也可以分别使用mag_filter和min_filter来获得与上面相同的行为。</p><p>类似地，必须为每个纹理轴单独设置地址模式，而我们使用着色器代码中的唯一地址参数来完成此操作。</p><h4 id="Passing-Samplers-as-Shader-Arguments-将采样器作为着色器参数传递"><a href="#Passing-Samplers-as-Shader-Arguments-将采样器作为着色器参数传递" class="headerlink" title="Passing Samplers as Shader Arguments(将采样器作为着色器参数传递)"></a>Passing Samplers as Shader Arguments(将采样器作为着色器参数传递)</h4><p>传递采样器看起来与传递纹理非常相似，但采样器驻留在另一组参数表槽中，因此我们使用不同的方法将它们绑定到从0开始的索引：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[commandEncoder setFragmentSamplerState:samplerState atIndex:<span class="number">0</span>];</span><br></pre></td></tr></table></figure><p>我们现在可以通过在着色器代码中使用[[sampler(0)]]来引用此采样器。</p><h3 id="The-Sample-Project-示例项目"><a href="#The-Sample-Project-示例项目" class="headerlink" title="The Sample Project(示例项目)"></a>The Sample Project(示例项目)</h3><p>示例项目位于06-Texturing目录中。它从前面的章节中大量借鉴，因此本章不再重申共享的概念。<br>主要的变化是使用纹理/采样器对来确定每个像素处的网格的漫反射颜色，而不是在整个表面上插入单个颜色。这使我们可以绘制我们的纹理牛模型，在场景中产生更大的真实感和细节感。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;纹理是渲染的核心主题。虽然它们有许多用途，但它们的主要目的之一是为表面提供比单独使用顶点颜色更高的细节水平。使用纹理贴图允许我们基本上按像素指定颜色，大大提高了渲染图像的视觉保真度。&lt;/p&gt;
    
    </summary>
    
    
      <category term="iOS/Mac" scheme="https://zhaolilong.com/tags/iOS-Mac/"/>
    
      <category term="图形学" scheme="https://zhaolilong.com/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
      <category term="Metal" scheme="https://zhaolilong.com/tags/Metal/"/>
    
  </entry>
  
  <entry>
    <title>实例学习Metal-第五章 光照</title>
    <link href="https://zhaolilong.com/2020/02/02/%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0Metal-%E7%AC%AC%E4%BA%94%E7%AB%A0/"/>
    <id>https://zhaolilong.com/2020/02/02/实例学习Metal-第五章/</id>
    <published>2020-02-01T16:00:00.000Z</published>
    <updated>2020-03-13T01:54:56.383Z</updated>
    
    <content type="html"><![CDATA[<p>在本章中, 我们将开始增加虚拟场景中的现实主义, 方法是从文件中加载3D 模型, 并用方向灯照亮它们。</p><p>直到现在, 我们一直进行硬编码我们的几何数据直接进入程序。这对于微小的几何形状来说是很好的, 但是它很快就变得不可持续了。通过将模型数据以标准格式存储在文件系统中, 我们可以开始使用更大的数据集。</p><a id="more"></a><h2 id="Lighting-光照"><a href="#Lighting-光照" class="headerlink" title="Lighting(光照)"></a>Lighting(光照)</h2><p>在本章中, 我们将开始增加虚拟场景中的现实主义, 方法是从文件中加载3D 模型, 并用方向灯照亮它们。</p><p>直到现在, 我们一直进行硬编码我们的几何数据直接进入程序。这对于微小的几何形状来说是很好的, 但是它很快就变得不可持续了。通过将模型数据以标准格式存储在文件系统中, 我们可以开始使用更大的数据集。</p><h3 id="Loading-OBJ-Models-加载OBJ模型"><a href="#Loading-OBJ-Models-加载OBJ模型" class="headerlink" title="Loading OBJ Models(加载OBJ模型)"></a>Loading OBJ Models(加载OBJ模型)</h3><p>存储基本3D 模型数据最常用的格式之一是 OBJ 格式 (Wavefront技术 1991)。OBJ文件以可读的格式存储顶点位置、法线、纹理坐标和面孔的列表。示例代码包括一个未成熟的obj分析器, 它可以用合适的格式将OBJ模型加载到内存中以使用Metal进行渲染。我们不会在这里详细描述加载器。 </p><p>我们在本章中使用的模型是一个茶壶。茶壶形状是计算机图形学早期最知名的可识别图形之一。它最初是以1975年犹他大学的Martin Newell的Melitta茶壶为蓝本的。由于其有趣的拓扑和不对称性, 它经常在图形教程中露面。</p><p><img src="/2020/02/02/实例学习Metal-第五章/1584063082.png" alt=""></p><center>图 5.1：计算机渲染的Utah茶壶模型</center><p>您应该随时重新编译示例项目, 并用您自己的OBJ文件替换包含的模型。标准化为适合原点周围的1×1×1立方体的模型将是最容易使用的模型。</p><h4 id="The-Structure-of-OBJ-Models-OBJ模型的结构"><a href="#The-Structure-of-OBJ-Models-OBJ模型的结构" class="headerlink" title="The Structure of OBJ Models(OBJ模型的结构)"></a>The Structure of OBJ Models(OBJ模型的结构)</h4><p>OBJ格式的模型在逻辑上被分成<code>groups</code>，这些组基本上是多边形的命名列表。加载模型就像在应用程序包中查找OBJ文件，初始化MBEOBJModel对象以及按索引查询组一样简单。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NSURL *modelURL = [[NSBundle mainBundle] URLForResource:@&quot;teapot&quot; withExtension:@&quot;obj&quot;];</span><br><span class="line">MBEOBJModel *teapot = [[MBEOBJModel alloc] initWithContentsOfURL:modelURL]; MBEOBJGroup *group = [teapot groupAtIndex:1];</span><br></pre></td></tr></table></figure><p>索引1对应于文件中的第一个组;不属于任何组的多边形将添加到索引0的隐式、未命名组中。<br>MBEOBJGroup 是一个具有两个指针成员的结构: <code>vertices(顶点)</code>和<code>indices(索引)</code>。这些顶点和指数列表对我们自己没有任何好处;我们需要把它们放到缓冲里区。由于顶点和索引的列表经常一起使用, 所以我们需要一个对象来保存这对缓冲区。这就是我们将要说的<code>mesh(网格)</code>。</p><h4 id="The-Mesh-Class-网格类"><a href="#The-Mesh-Class-网格类" class="headerlink" title="The Mesh Class(网格类)"></a>The Mesh Class(网格类)</h4><p>网格类的接口非常简单，只包含两个缓冲区属性。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">@interface MBEMesh : NSObject</span><br><span class="line">@property (readonly) id&lt;MTLBuffer&gt; vertexBuffer; @property (readonly) id&lt;MTLBuffer&gt; indexBuffer; @end</span><br></pre></td></tr></table></figure><p>我们将网格类子类化以生成特定于应用程序的网格类型。现在，我们需要一个表示OBJ组的网格，因此我们使用以下初始化程序创建<code>MBEOBJMesh</code>类：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- (instancetype)initWithGroup:(MBEOBJGroup *)group device:(id&lt;MTLDevice&gt;)device;</span><br></pre></td></tr></table></figure><p>此方法采用OBJ组和Metal设备，并生成一个缓冲区对，其中包含组顶点和索引的存储空间。我们可以通过将其顶点缓冲区绑定到参数表并编码索引绘制调用来渲染这样的网格，就像我们在上一章中所做的那样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[renderPass setVertexBuffer:mesh.vertexBuffer offset:0 atIndex:0]; [renderPass drawIndexedPrimitives:MTLPrimitiveTypeTriangle</span><br><span class="line">indexCount:[mesh.indexBuffer length] / sizeof(MBEIndex) indexType:MBEIndexType indexBuffer:self.mesh.indexBuffer indexBufferOffset:0];</span><br></pre></td></tr></table></figure><h4 id="Normals-法线"><a href="#Normals-法线" class="headerlink" title="Normals(法线)"></a>Normals(法线)</h4><p>我们的光照计算将取决于对象的<code>法线向量</code>。法线向量是垂直于表面的<code>单位向量</code>（长度为1的向量）。如果您想象一个平面仅在一个点（我们称之为切平面）接触凸面，则法向量是垂直于平面的向量。它代表了<br>表面的“向外”方向。</p><p>我们的OBJ模型加载器完成了为模型中的每个定点生成法线向量所需的工作。我们还在顶点结构中添加了一个成员来持有法线，因此它在着色器源中的声明现在看起来像这样：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Vertex</span> </span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    float4 position;</span><br><span class="line">    float4 normal; </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="Lighting-光照-1"><a href="#Lighting-光照-1" class="headerlink" title="Lighting(光照)"></a>Lighting(光照)</h3><p>为了开始构建逼真的场景，我们需要一种方法来模拟光线与曲面的相互作用。幸运的是，许多计算机图形本身都在寻找巧妙的方法来近似光的行为。我们将使用由三个项组成的近似值来模拟场景中出现的不同种类的光：环境光，漫反射光和镜面光。每个像素的颜色将是这三个术语的总和。以下是表示最高级别关系的等式：</p><p>I<sub>total</sub> = I<sub>ambient</sub> + I<sub>diffuse</sub> + I<sub>specular</sub></p><p>在上面，<code>I</code>代表intensity(强度)，特别是外向辐射强度。我们将使用<code>L</code>来表示光源的属性，使用<code>M</code>来表示材质的属性。这些值都没有精确的物理基础。我们第一次尝试近似照明涉及很多捷径。因此，我们为这些数量选择的值将基于美学而非物理精确度。</p><p>我们将要处理的光照类型是<code>directional(方向性的)</code>;他们在太空中没有明确的位置。相反，我们想象它们足够远，只能通过它们发光的方向来表征。太阳是这种定向光的一个例子。</p><h5 id="Ambient-Light-环境光"><a href="#Ambient-Light-环境光" class="headerlink" title="Ambient Light(环境光)"></a>Ambient Light(环境光)</h5><p>环境光是与特定光源无关的非定向种类的光。相反，它是用于对间接光（从场景中的其他表面反弹的光）进行建模的近似值，其不被其他术语捕获。环境照明可防止未直接照明的几何体部分完全变黑。环境光的贡献通常是微妙的。</p><p>环境光计算为光的环境强度和光的强度的乘积<br>表面的环境响应：</p><p>I<sub>ambient</sub> = L<sub>ambientMambient</sub></p><p>通常情况下，人们将环境贡献建模为场景的属性而不是光。这表明环境光并非真正来自一个来源;相反，它是从任何光源出现在场景周围反射的光的总和。为了方便和公式的一致性，我们选择使环境光成为光本身的属性。</p><p><img src="/2020/02/02/实例学习Metal-第五章/1584063173.png" alt=""></p><center>图 5.2：环境光期通常会做出很小的贡献</center><h5 id="Diffuse-Light-漫反射光"><a href="#Diffuse-Light-漫反射光" class="headerlink" title="Diffuse Light(漫反射光)"></a>Diffuse Light(漫反射光)</h5><p>漫反射光遵循朗伯的余弦定律，该定律指出反射光的强度与入射光的方向与表面法线之间的角度的余弦成正比。法线是垂直于曲面的矢量。正面照射的光比以浅入射角到达的光反射的程度更大。</p><p><img src="/2020/02/02/实例学习Metal-第五章/1584063201.png" alt=""></p><center>图5.3：在漫射照明中，反射的光量与法线和入射角之间的角度成正比</center><p>漫反射通过以下简化方程建模：</p><p>I<sub>diffuse</sub> = cosθ·M<sub>diffuse</sub> · L<sub>diffuse</sub></p><p>如果我们假设法向量和入射光方向向量是单位向量，<br>我们可以使用熟悉的点积来计算这个术语：</p><p>I<sub>diffuse</sub> = N·L·M<sub>diffuse</sub>·L<sub>diffuse</sub></p><p><img src="/2020/02/02/实例学习Metal-第五章/1584063234.png" alt=""></p><center>图5.4：漫反射术语表示表面在所有方向上均匀反射光的趋势</center><h5 id="Specular-Light-镜面光"><a href="#Specular-Light-镜面光" class="headerlink" title="Specular Light(镜面光)"></a>Specular Light(镜面光)</h5><p>镜面光项用于模拟“有光泽”的表面。它描述了材料在特定方向上反射光而不是在各个方向上散射光的趋势。闪亮的材料创造出镜面高光，这是一个强大的视觉线索，用于说明粗糙或有光泽的表面。 “光泽”由称为镜面反射功率的参数量化。例如，5的镜面反射功率对应于相当无光泽的表面，而镜面反射功率50对应于稍微有光泽的表面。</p><p>有几种流行的计算镜面术语的方法，但我们将在这里使用<br>Blinn-Phong近似（Blinn 1977）。 Blinn-Phong镜面术语使用一个称为<code>中间向量</code>的向量，该向量指向光源方向和观察表面的方向之间的中间位置：</p><p>H = (1/2)(D+V)</p><p>一旦我们掌握了中间矢量，我们计算表面法线和中间矢量之间的点积，并将该量增加到材料的镜面反射率。</p><p>I<sub>specular</sub> =(N·H)<sup>specularPower</sup>L<sub>specular</sub>M<sub>specular</sub></p><p>这个取幂是控制所产生的镜面反射高度的“紧密”的原因;<br>镜面反射功率越高，高光越清晰。</p><p><img src="/2020/02/02/实例学习Metal-第五章/1584063306.png" alt=""></p><center>图5.5：镜面术语表示某些表面在特定方向上反射光的趋势</center><p>结果</p><p>现在我们已经计算了光照方程的所有三个项，我们将每个像素的结果加在一起以找到它的最终颜色。在接下来的几节中，我们将讨论如何使用Metal着色语言实际实现此效果。</p><p><img src="/2020/02/02/实例学习Metal-第五章/1584063329.png" alt=""></p><center>图5.6：添加环境，漫反射和镜面反射条件的贡献可以生成最终图像</center><h3 id="Lighting-in-Metal-Metal中的光照"><a href="#Lighting-in-Metal-Metal中的光照" class="headerlink" title="Lighting in Metal(Metal中的光照)"></a>Lighting in Metal(Metal中的光照)</h3><p>代表灯光和材料</p><p>我们将使用两个结构来包装与灯光和材质相关的属性。灯具有三种颜色属性，一个用于我们详细讨论的每个灯光项。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Light</span> </span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    float3 direction; </span><br><span class="line">    float3 ambientColor; </span><br><span class="line">    float3 diffuseColor; </span><br><span class="line">    float3 specularColor;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>材料还具有三种颜色属性;这些模型模拟了材料对入射光的响应。从表面反射的光的颜色取决于表面的颜色和入射光的颜色。正如我们所见，光的颜色和表面的颜色相乘以确定表面的颜色，然后将这个颜色乘以一些强度（在环境的情况下为1，在这种情况下为<em>N</em>·<em>L</em>）在镜面反射的情况下，弥散和N·H提升到一些幂。我们将镜面反射力模型化为浮点数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Material</span> </span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    float3 ambientColor; </span><br><span class="line">    float3 diffuseColor; </span><br><span class="line">    float3 specularColor; </span><br><span class="line">    <span class="keyword">float</span> specularPower;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h4 id="Uniforms-统一量"><a href="#Uniforms-统一量" class="headerlink" title="Uniforms(统一量)"></a>Uniforms(统一量)</h4><p>正如我们在前一章中所做的那样，我们需要将一些统一值传递给着色器来转换顶点。然而，这一次，我们需要一些额外的矩阵来进行与照明相关的计算。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Uniforms</span> </span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    float4x4 modelViewProjectionMatrix; </span><br><span class="line">    float4x4 modelViewMatrix;</span><br><span class="line">    float3x3 normalMatrix;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>除了模型 - 视图 - 投影矩阵（MVP），我们还存储模型视图矩阵，它将顶点从对象空间转换为眼睛空间。我们需要这个，因为镜面高光是视图相关的。在解析下面的着色器函数时，我们将讨论更多这方面的含义。</p><p>我们还包括一个普通矩阵，用于将模型的法线转换为眼睛空间。为什么我们需要一个单独的矩阵呢？答案是法线不像位置那样变换。这看起来似乎违反直觉，但考虑到这一点：当你在空间中移动一个物体而不旋转它时，表面上任何一点的“向外”方向都是不变的。</p><p>这给了我们关于如何构造普通矩阵的第一个线索：我们需要从模型视图矩阵中去掉任何转换。我们通过仅采用模型 - 视图矩阵的左上3×3部分来实现这一点，该部分是负责旋转和缩放的部分。</p><p>事实证明，只要模型 - 视图矩阵仅由旋转和均匀尺度组成（即，没有拉伸或剪切），该左上方矩阵就是用于变换法线的正确矩阵。在更复杂的情况下，我们需要使用此矩阵的逆转置，但其原因超出了本书的范围。</p><h4 id="The-Vertex-Function-顶点函数"><a href="#The-Vertex-Function-顶点函数" class="headerlink" title="The Vertex Function(顶点函数)"></a>The Vertex Function(顶点函数)</h4><p>为了存储我们的照明计算所需的每顶点值，我们声明了一个单独的“投影顶点”结构，该结构将由ver-tex函数计算和返回：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">struct ProjectedVertex &#123; float4 position [[position]]; float3 eye; float3 normal; &#125;;</span><br></pre></td></tr></table></figure><p>眼睛成员是从顶点在视图空间中的位置指向眼睛的矢量<br>虚拟相机。普通成员是顶点的视图空间法线。顶点函数计算这两个新的向量，以及投影（剪辑 -<br>space）每个顶点的位置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vertex ProjectedVertex vertex_project(device Vertex *vertices [[buffer(0)]], constant Uniforms &amp;uniforms [[buffer(1)]],</span><br><span class="line">uint vid [[vertex_id]])</span><br><span class="line">&#123;</span><br><span class="line">    ProjectedVertex outVert;</span><br><span class="line">    outVert.position = uniforms.modelViewProjectionMatrix * vertices[vid].position;</span><br><span class="line">    outVert.eye = -(uniforms.modelViewMatrix * vertices[vid].position).xyz; outVert.normal = uniforms.normalMatrix * vertices[vid].normal.xyz;</span><br><span class="line">    return outVert; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="The-Fragment-Function-片元函数"><a href="#The-Fragment-Function-片元函数" class="headerlink" title="The Fragment Function(片元函数)"></a>The Fragment Function(片元函数)</h4><p>对于每个片段，我们接收一个插值的“投影顶点”结构，并使用它来计算我们的三个照明术语：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">fragment float4 fragment_light(ProjectedVertex vert [[stage_in]], constant Uniforms &amp;uniforms [[buffer(0)]])</span><br><span class="line">&#123;</span><br><span class="line">    float3 ambientTerm = light.ambientColor * material.ambientColor;</span><br><span class="line">    float3 normal = normalize(vert.normal);</span><br><span class="line">    float diffuseIntensity = saturate(dot(normal, light.direction)); float3 diffuseTerm = light.diffuseColor * material.diffuseColor *</span><br><span class="line">diffuseIntensity;</span><br><span class="line">    float3 specularTerm(0); </span><br><span class="line">    if (diffuseIntensity &gt; 0) </span><br><span class="line">    &#123;</span><br><span class="line">        float3 eyeDirection = normalize(vert.eye);</span><br><span class="line">        float3 halfway = normalize(light.direction + eyeDirection); </span><br><span class="line">        float specularFactor = pow(saturate(dot(normal, halfway)), material.specularPower);</span><br><span class="line">        specularTerm = light.specularColor * material.specularColor * specularFactor;</span><br><span class="line">    &#125;</span><br><span class="line">    return float4(ambientTerm + diffuseTerm + specularTerm, 1); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如所讨论的，环境术语仅仅是环境光强度和材料的环境响应的乘积。</p><p>由于我们收到的法线和眼睛向量不是单位长度，因此我们在使用前将它们标准化。这必须在每个片段的基础上完成，因为即使我们在顶点函数中对它们进行了归一化，光栅化器完成的插值也不会保留单位长度属性。</p><p>为了计算漫反射项，我们首先采用视空间法线和光方向的点积。然后我们使用饱和函数将其夹在0和1之间。否则，指向远离光线的面将会消失，具有负的漫反射强度，这是非物理的。我们将这个余弦规则强度乘以光的漫反射贡献和材料漫反应的乘积，得到完整的扩散项。</p><p>为了计算镜面反射因子，我们通过对光方向和眼睛方向求和并对结果进行归一化来计算“中途”矢量。这具有平均它们的效果，因为在添加之前每个都是单位长度。我们采用表面法线和中间矢量之间的点积来得到镜面基底，然后将其提高到材料的镜面反射率以获得镜面反射强度。和以前一样，我们将它与光的镜面反射颜色和材料的镜面反应相乘，得到完整的特定术语。</p><p>最后，我们将所有三个项加在一起，并将结果作为片段的颜色值返回。</p><h3 id="The-Sample-App-样例应用"><a href="#The-Sample-App-样例应用" class="headerlink" title="The Sample App(样例应用)"></a>The Sample App(样例应用)</h3><p>本章的示例代码位于05-Lighting目录中。它从OBJ文件加载一个茶壶模型并显示它在3D中翻滚，就像上一章中的立方体一样。但是，这一次，每像素照明应用于模型，使其具有更加合理（并且非常闪亮）的外观。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在本章中, 我们将开始增加虚拟场景中的现实主义, 方法是从文件中加载3D 模型, 并用方向灯照亮它们。&lt;/p&gt;
&lt;p&gt;直到现在, 我们一直进行硬编码我们的几何数据直接进入程序。这对于微小的几何形状来说是很好的, 但是它很快就变得不可持续了。通过将模型数据以标准格式存储在文件系统中, 我们可以开始使用更大的数据集。&lt;/p&gt;
    
    </summary>
    
    
      <category term="iOS/Mac" scheme="https://zhaolilong.com/tags/iOS-Mac/"/>
    
      <category term="图形学" scheme="https://zhaolilong.com/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
      <category term="Metal" scheme="https://zhaolilong.com/tags/Metal/"/>
    
  </entry>
  
  <entry>
    <title>实例学习Metal-第四章 3D绘制</title>
    <link href="https://zhaolilong.com/2020/01/26/%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0Metal-%E7%AC%AC%E5%9B%9B%E7%AB%A0/"/>
    <id>https://zhaolilong.com/2020/01/26/实例学习Metal-第四章/</id>
    <published>2020-01-25T16:00:00.000Z</published>
    <updated>2020-03-13T01:53:23.035Z</updated>
    
    <content type="html"><![CDATA[<p>基于我们在前一章中学习的渲染管道，我们现在将开始三维渲染。</p><a id="more"></a><h1 id="Chapter-4-第四章"><a href="#Chapter-4-第四章" class="headerlink" title="Chapter 4(第四章)"></a>Chapter 4(第四章)</h1><h2 id="Drawing-in-3D-3D绘图"><a href="#Drawing-in-3D-3D绘图" class="headerlink" title="Drawing in 3D(3D绘图)"></a>Drawing in 3D(3D绘图)</h2><p>基于我们在前一章中学习的渲染管道，我们现在将开始三维渲染。</p><h3 id="Specifying-Geometry-in-3D-在3D中指定几何"><a href="#Specifying-Geometry-in-3D-在3D中指定几何" class="headerlink" title="Specifying Geometry in 3D(在3D中指定几何)"></a>Specifying Geometry in 3D(在3D中指定几何)</h3><h4 id="Cube-Geometry-立方体几何"><a href="#Cube-Geometry-立方体几何" class="headerlink" title="Cube Geometry(立方体几何)"></a>Cube Geometry(立方体几何)</h4><p>我们将在本章中呈现的对象是一个简单的立方体。在代码中编写立方体的顶点很容易，从而避免了现在加载3D模型的复杂性。以下是立方体网格的顶点：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> MBEVertex vertices[] = &#123;</span><br><span class="line">    &#123;.position=&#123;<span class="number">-1</span>, <span class="number">1</span>, <span class="number">1</span>,<span class="number">1</span>&#125;,.color=&#123;<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>&#125;&#125;, </span><br><span class="line">    &#123;.position=&#123;<span class="number">-1</span>,<span class="number">-1</span>, <span class="number">1</span>,<span class="number">1</span>&#125;,.color=&#123;<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>&#125;&#125;, </span><br><span class="line">    &#123;.position=&#123; <span class="number">1</span>,<span class="number">-1</span>, <span class="number">1</span>,<span class="number">1</span>&#125;,.color=&#123;<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>&#125;&#125;, </span><br><span class="line">    &#123;.position=&#123; <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,<span class="number">1</span>&#125;,.color=&#123;<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>&#125;&#125;, </span><br><span class="line">    &#123;.position=&#123;<span class="number">-1</span>, <span class="number">1</span>,<span class="number">-1</span>,<span class="number">1</span>&#125;,.color=&#123;<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>&#125;&#125;, </span><br><span class="line">    &#123;.position=&#123;<span class="number">-1</span>,<span class="number">-1</span>,<span class="number">-1</span>,<span class="number">1</span>&#125;,.color=&#123;<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>&#125;&#125;, </span><br><span class="line">    &#123;.position=&#123; <span class="number">1</span>,<span class="number">-1</span>,<span class="number">-1</span>,<span class="number">1</span>&#125;,.color=&#123;<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>&#125;&#125;, </span><br><span class="line">    &#123;.position=&#123; <span class="number">1</span>, <span class="number">1</span>,<span class="number">-1</span>,<span class="number">1</span>&#125;,.color=&#123;<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>&#125;&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><img src="/2020/01/26/实例学习Metal-第四章/1584062898.png" alt=""></p><center>图4.1：示例应用程序呈现的多维数据集</center><p>我们重用前一章中的相同MBEVertex结构，它具有每个顶点的位置和颜色。由于我们尚未引入照明，因此为每个顶点赋予不同的颜色可提供重要的深度提示。和以前一样，我们创建一个缓冲区来保存顶点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vertexBuffer = [device newBufferWithBytes:vertices length:sizeof(vertices) options:MTLResourceOptionCPUCacheModeDefault];</span><br></pre></td></tr></table></figure><h3 id="Index-Buffers-索引缓冲区"><a href="#Index-Buffers-索引缓冲区" class="headerlink" title="Index Buffers(索引缓冲区)"></a>Index Buffers(索引缓冲区)</h3><p>在上一章中，我们按照绘制它们的顺序存储三角形的顶点，每个顶点只使用一次。在立方体的情况下，每个顶点属于几个三角形。理想情况下，我们将重用这些顶点，而不是在内存中存储每个顶点的额外副本。随着模型的大小增加，顶点重用变得更加重要。</p><p>幸运的是，与大多数图形库一样，Metal使我们能够提供索引缓冲区以及顶点缓冲区。索引缓冲区包含一个指向ver-tex缓冲区的索引列表，用于指定每个三角形组成的顶点。</p><p>首先，我们定义了几个typedef，它们将简化索引的处理：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">typedef uint16_t MBEIndex;</span><br><span class="line">const MTLIndexType MBEIndexType = MTLIndexTypeUInt16;</span><br></pre></td></tr></table></figure><p>首先，我们将使用16位无符号索引。这允许每个网格包含多达65536个不同的顶点，这将在很长一段时间内满足我们的目的。如果我们将来需要容纳更多顶点，我们可以更改这些定义，并且我们的代码将适应更大的索引大小。 Metal允许16位和32位索引。</p><p>立方体的每个正方形面分为两个三角形，包括六个指数。我们在数组中指定它们，然后将它们复制到缓冲区中：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> MBEIndex indices[] = </span><br><span class="line">&#123;</span><br><span class="line">    <span class="number">3</span>,<span class="number">2</span>,<span class="number">6</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">3</span>, </span><br><span class="line">    <span class="number">4</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">4</span>, </span><br><span class="line">    <span class="number">4</span>,<span class="number">0</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">7</span>,<span class="number">4</span>, </span><br><span class="line">    <span class="number">1</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">6</span>,<span class="number">2</span>,<span class="number">1</span>, </span><br><span class="line">    <span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">0</span>, </span><br><span class="line">    <span class="number">7</span>,<span class="number">6</span>,<span class="number">5</span>,<span class="number">5</span>,<span class="number">4</span>,<span class="number">7</span></span><br><span class="line">&#125;;</span><br><span class="line">indexBuffer = [device newBufferWithBytes:indices length:<span class="keyword">sizeof</span>(indices) options:<span class="built_in">MTLResourceOptionCPUCacheModeDefault</span>];</span><br></pre></td></tr></table></figure><p>既然我们已经定义了一些要使用的几何体，让我们来谈谈如何渲染3D场景。</p><h3 id="Dividing-Work-between-the-View-and-the-Renderer-在视图和渲染器之间划分工作"><a href="#Dividing-Work-between-the-View-and-the-Renderer-在视图和渲染器之间划分工作" class="headerlink" title="Dividing Work between the View and the Renderer(在视图和渲染器之间划分工作)"></a>Dividing Work between the View and the Renderer(在视图和渲染器之间划分工作)</h3><p>在上一章中，我们给<code>MBEMetalView</code>类负责渲染三角形。现在，我们希望通过修复视图的功能，将资源管理和渲染的工作卸载到一个单独的类：渲染器，转向更可持续的模型。</p><h4 id="Responsibilities-of-the-View-Class-在视图和渲染器之间划分工作"><a href="#Responsibilities-of-the-View-Class-在视图和渲染器之间划分工作" class="headerlink" title="Responsibilities of the View Class(在视图和渲染器之间划分工作)"></a>Responsibilities of the View Class(在视图和渲染器之间划分工作)</h4><p>在上一章中，我们给<code>MBEMetalView</code>类负责渲染三角形。现在，我们希望通过修复视图的功能，将资源管理和渲染的工作卸载到一个单独的类：渲染器，转向更可持续的模型。</p><p>视图类应该只关注将像素放到屏幕上，因此我们从中删除命令队列，渲染管道和缓冲区属性。它保留了监听显示链接和管理纹理的责任渲染过程的附件。</p><p>新的<code>MBEMetalView</code>提供了名为<code>currentDrawable</code>的属性，它为当前帧的<code>CAMetalDrawable</code>对象和<code>currentRenderPassDescriptor</code>提供了一个属性，它将使用绘制的纹理配置的渲染过程描述符作为其主要颜色附件。</p><h4 id="The-Draw-Protocol-绘制协议"><a href="#The-Draw-Protocol-绘制协议" class="headerlink" title="The Draw Protocol(绘制协议)"></a>The Draw Protocol(绘制协议)</h4><p>为了绘图，我们需要一种方法让视图与我们沟通，是时候进行绘制调用了。我们通过名为<code>MBEMetalViewDelegate</code>的协议将视图的概念与渲染器的概念分离，该协议具有单个必需的方法：<code>-drawInView：</code>。</p><p>每个显示周期将调用此绘制方法一次，以允许我们刷新视图的内容。在委托的方法实现中，<code>currentDrawable</code>和<code>currentRenderPassDescriptor</code>属性可用于创建渲染命令编码器（我们将经常调用<code>渲染过程</code>）并对其发出绘制调用。</p><h4 id="Responsibilities-of-the-Renderer-Class-渲染者类的责任"><a href="#Responsibilities-of-the-Renderer-Class-渲染者类的责任" class="headerlink" title="Responsibilities of the Renderer Class(渲染者类的责任)"></a>Responsibilities of the Renderer Class(渲染者类的责任)</h4><p>我们的渲染器将保存我们用于使用Metal渲染的长寿命对象，包括管道状态和缓冲区等。它符合<code>MBEMetalViewDelegate</code>协议，因此通过创建命令缓冲区和命令编码器来发出绘制调用来响应<code>-drawInView：</code>消息。然而，在我们开始讨论之前，我们需要讨论绘制调用将要执行的工作。</p><h3 id="Transforming-from-3D-to-2D-从3D转换为2D"><a href="#Transforming-from-3D-to-2D-从3D转换为2D" class="headerlink" title="Transforming from 3D to 2D(从3D转换为2D)"></a>Transforming from 3D to 2D(从3D转换为2D)</h3><p>为了将3D几何体绘制到2D屏幕，这些点必须经历一系列变换：从对象空间到世界空间，到眼睛空间，到剪辑空间，到规范化设备坐标，最后到屏幕空间。</p><h4 id="From-Object-Space-to-World-Space-从物空间到世界空间"><a href="#From-Object-Space-to-World-Space-从物空间到世界空间" class="headerlink" title="From Object Space to World Space(从物空间到世界空间)"></a>From Object Space to World Space(从物空间到世界空间)</h4><p>构成3D模型的顶点用局部坐标空间（称为<code>对象空间</code>）表示。我们的立方体的顶点是关于原点的，它位于立方体的中心。为了在更大的场景中定位和定位对象，我们需要<br>指定一个可以缩放，平移和旋转它们到<code>世界空间</code>的变换。</p><p>您可以从线性代数中回忆一下，矩阵可以相乘（连接）以构建表示线性变换序列的单个矩阵。我们将调用矩阵，该矩阵将将对象移动到<code>模型矩阵</code>的世界空间中的变换序列聚集在一起。我们立方体的模型矩阵包括一个尺度变换，然后是两个旋转。这些单独变换中的每一个都随时间变化，以实现脉冲旋转立方体的效果。</p><p>以下是创建转换序列并将它们相乘以创建世界转换的代码：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> scaleFactor = sinf(<span class="number">5</span> * <span class="keyword">self</span>.time) * <span class="number">0.25</span> + <span class="number">1</span>;</span><br><span class="line">vector_float3 xAxis = &#123; <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span> &#125;;</span><br><span class="line">vector_float3 yAxis = &#123; <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span> &#125;;</span><br><span class="line">matrix_float4x4 xRot = matrix_float4x4_rotation(xAxis, <span class="keyword">self</span>.rotationX); matrix_float4x4 yRot = matrix_float4x4_rotation(yAxis, <span class="keyword">self</span>.rotationY); matrix_float4x4 scale = matrix_float4x4_uniform_scale(scaleFactor); matrix_float4x4 modelMatrix = matrix_multiply(matrix_multiply(xRot, yRot),</span><br><span class="line">scale);</span><br></pre></td></tr></table></figure><p>我们使用矩阵从右到左应用于列向量的约定，因此modelMatrix缩放顶点，然后围绕Y轴旋转它，然后围绕X轴旋转它。每帧都会更新rotationX，rotationY和time属性，以便对此转换进行动画处理。</p><h4 id="From-World-Space-to-View-Space-从世界空间到观看空间"><a href="#From-World-Space-to-View-Space-从世界空间到观看空间" class="headerlink" title="From World Space to View Space(从世界空间到观看空间)"></a>From World Space to View Space(从世界空间到观看空间)</h4><p>现在我们在世界空间中拥有了场景（缩放，旋转的立方体），我们需要相对于虚拟摄像机的视点定位整个场景。这种变换称为<code>视图空间</code>（或等效地，<code>眼睛空间</code>或<code>相机空间</code>）变换。最终在屏幕上可见的所有内容都包含在称为视锥，如下图所示。虚拟摄像机眼睛的位置是该观察体积的顶点，即观察平截头体近平面中间的点。</p><p><img src="/2020/01/26/实例学习Metal-第四章/1584062966.png" alt=""></p><center>图4.2：视锥体。平截头体的顶点与虚拟相机的眼睛重合。</center><p>构建相机的变换需要我们向后思考：将相机向后移动相当于将场景更深地移动到屏幕中，并且绕Y轴逆时针旋转场景相当于顺时针绕轨道旋转场景的相机。</p><p>在我们的示例场景中，我们希望将相机从多维数据集放回几个单位。我们使用世界空间“惯用右手”的惯例，Y轴朝上，这意味着Z轴指向屏幕外。因此，正确的转变<br>是一个平移，沿Z轴移动每个顶点一个<code>负</code>距离。等效地，该变换使摄像机沿Z轴移动正距离。这都是相关的。</p><p>以下是构建视图矩阵的代码：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vector_float3 cameraTranslation = &#123; <span class="number">0</span>, <span class="number">0</span>, <span class="number">-5</span> &#125;;</span><br><span class="line">matrix_float4x4 viewMatrix = matrix_float4x4_translation(cameraTranslation);</span><br></pre></td></tr></table></figure><h4 id="From-View-Space-to-Clip-Space-从视图空间到剪辑空间"><a href="#From-View-Space-to-Clip-Space-从视图空间到剪辑空间" class="headerlink" title="From View Space to Clip Space(从视图空间到剪辑空间)"></a>From View Space to Clip Space(从视图空间到剪辑空间)</h4><p>投影矩阵将视图空间坐标转换为<code>剪辑空间</code>坐标。</p><p>剪辑空间是GPU用于确定观看体积内三角形的可见性的3D空间。如果三角形的所有三个顶点都在剪辑体积之外，根本不渲染三角形（它被剔除）。另一方面，如果一个或多个顶点在体积内，则将其剪切到边界，并且使用一个或多个修改的三角形作为顶点着色器的输入。</p><p><img src="/2020/01/26/实例学习Metal-第四章/1584062996.png" alt=""></p><center>图4.3：被剪裁的三角形的图示。它的两个顶点超出了剪裁边界，因此面被剪裁和重新三角化，创建了三个新的三角形。</center><p>透视投影矩阵通过一系列缩放操作将视点空间中的点带入剪辑空间。在先前的变换中，<code>w</code>分量保持不变并且等于1，但是投影矩阵以这样的方式影响<code>w</code>分量：如果<code>x</code>，<code>y</code>或<code>z</code>分量的绝对值大于<code>w</code>分量的绝对值，顶点位于查看体积之外并被剪裁。</p><p>透视投影变换封装在<code>matrix_float4x4_perspective</code>工具函数中。在示例代码中，修复约70度的垂直视野，选择远近平面值，并选择等于我们的Metal视图的当前可绘制宽度和高度之间比例的纵横比。</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> aspect = drawableSize.width / drawableSize.height; floatfov=(<span class="number">2</span>*M_PI)/<span class="number">5</span>;</span><br><span class="line"><span class="keyword">float</span> near = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">float</span> far = <span class="number">100</span>;</span><br><span class="line">matrix_float4x4 projectionMatrix = matrix_float4x4_perspective(aspect, fov, near, far);</span><br></pre></td></tr></table></figure><p>我们现在有一系列矩阵将把我们从对象空间一直移动到剪辑空间，这是Metal期望我们的顶点着色器函数返回的顶点的空间。将所有这些矩阵相乘产生一个<code>模型-视图-投影</code>（MVP）矩阵，这是我们实际传递给顶点着色器的矩阵，以便于每个顶点都可以在GPU上与它相乘。</p><h4 id="The-Perspective-Divide-From-Clip-Space-to-NDC-透视划分：从剪辑空间到NDC"><a href="#The-Perspective-Divide-From-Clip-Space-to-NDC-透视划分：从剪辑空间到NDC" class="headerlink" title="The Perspective Divide: From Clip Space to NDC(透视划分：从剪辑空间到NDC)"></a>The Perspective Divide: From Clip Space to NDC(透视划分：从剪辑空间到NDC)</h4><p>在透视投影的情况下，计算<code>w</code>分量以使透视分割产生透视缩小，更远的物体缩小的现象。</p><p>在我们从顶点函数将投影顶点移交给Metal之后，它将每个组件除以w组件，从剪辑空间坐标移动到<code>标准化设备坐标</code>（NDC），在对查看体积边界进行相关剪切之后。 Metal的NDC空间是一个长方体[-1,1]×[-1,1]×[0,1]，这意味着x和y坐标的范围是-1到1，当我们移动时z坐标的范围是0到1<code>远离相机</code>。</p><h4 id="The-Viewport-Transform-From-NDC-to-Window-Coordinates-视口变换：从NDC到窗口坐标"><a href="#The-Viewport-Transform-From-NDC-to-Window-Coordinates-视口变换：从NDC到窗口坐标" class="headerlink" title="The Viewport Transform: From NDC to Window Coordinates(视口变换：从NDC到窗口坐标)"></a>The Viewport Transform: From NDC to Window Coordinates(视口变换：从NDC到窗口坐标)</h4><p>为了从NDC的半立方体映射到视图的像素坐标，Metal通过缩放和偏置标准化设备坐标来进行最终的内部转换，使得它们覆盖<code>视口</code>的大小。在我们的所有示例代码中，视口都是一个覆盖整个视图的矩形，但是可以调整视口大小，使其仅覆盖视图的一部分。</p><h3 id="3D-Rendering-in-Metal-Metal中的3D渲染"><a href="#3D-Rendering-in-Metal-Metal中的3D渲染" class="headerlink" title="3D Rendering in Metal(Metal中的3D渲染)"></a>3D Rendering in Metal(Metal中的3D渲染)</h3><h4 id="Uniforms-统一量"><a href="#Uniforms-统一量" class="headerlink" title="Uniforms(统一量)"></a>Uniforms(统一量)</h4><p>uniform是一个值，它作为参数传递给着色器，该着色器在绘制调用过程中不会发生变化。从着色器的角度来看，它是一个常数。<br>在接下来的章节中，我们将我们的uniform捆绑在一个自定义结构中。即使我们现在只有一个这样的值（MVP矩阵），我们现在也会养成这样的习惯：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">typedef struct &#123;</span><br><span class="line">    matrix_float4x4 modelViewProjectionMatrix; </span><br><span class="line">&#125; MBEUniforms;</span><br></pre></td></tr></table></figure><p>由于我们正在为我们的立方体制作动画，我们需要每帧重新生成制服，因此我们将用于生成变换的代码放入缓冲区中，并将其写入名为<code>-updateUniforms</code>的渲染器类的方法中。</p><h4 id="The-Vertex-Shader-顶点着色器"><a href="#The-Vertex-Shader-顶点着色器" class="headerlink" title="The Vertex Shader(顶点着色器)"></a>The Vertex Shader(顶点着色器)</h4><p>现在我们在工具箱中有了一些3D绘图的基础数学，让我们讨论如何让Metal实际完成变换顶点的工作。</p><p>我们的顶点着色器采用指向Vertex类型顶点数组的指针，这是在着色器源中声明的结构。它还需要一个指向Uniforms类型的统一结构的指针。这些类型的定义是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">struct Vertex </span><br><span class="line">&#123;</span><br><span class="line">    float4 position [[position]];</span><br><span class="line">    float4 color; </span><br><span class="line">&#125;;</span><br><span class="line">struct Uniforms </span><br><span class="line">&#123;</span><br><span class="line">    float4x4 modelViewProjectionMatrix; </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>请注意，我们在函数的参数列表中使用了两个不同的地址空间限定符：<code>device</code>和<code>constant</code>。通常，在使用每顶点或每个片段偏移（例如使用<code>vertex_id</code>归因的参数）索引到缓冲区时，应使用设备地址空间。当函数的许多调用将访问缓冲区的相同部分时，使用常量地址空间，就像访问每个顶点的统一结构时的情况一样。</p><h4 id="The-Fragment-Shader-片段着色器"><a href="#The-Fragment-Shader-片段着色器" class="headerlink" title="The Fragment Shader(片段着色器)"></a>The Fragment Shader(片段着色器)</h4><p>片段着色器与前一章中使用的着色器相同：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fragment half4 fragment_flatcolor(Vertex vertexIn [[stage_in]]) </span><br><span class="line">&#123;</span><br><span class="line">    return half4(vertexIn.color);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Preparing-the-Render-Pass-and-Command-Encoder-准备渲染通道和命令编码器"><a href="#Preparing-the-Render-Pass-and-Command-Encoder-准备渲染通道和命令编码器" class="headerlink" title="Preparing the Render Pass and Command Encoder(准备渲染通道和命令编码器)"></a>Preparing the Render Pass and Command Encoder(准备渲染通道和命令编码器)</h4><p>每个帧，我们需要在发出绘制调用之前配置渲染通道和命令编码器：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[commandEncoder setDepthStencilState:<span class="keyword">self</span>.depthStencilState]; </span><br><span class="line">[commandEncoder setFrontFacingWinding:<span class="built_in">MTLWindingCounterClockwise</span>]; </span><br><span class="line">[commandEncoder setCullMode:<span class="built_in">MTLCullModeBack</span>];</span><br></pre></td></tr></table></figure><p><code>depthStencilState</code>属性设置为先前配置的模板深度状态对象。</p><p>正面<code>缠绕</code>顺序确定金属是否将面向顶点顺时针或逆时针考虑为正面。默认情况下，Metal将顺时针面视为正面。样品数据和样品代码更喜欢逆时针方向，因为这在右手坐标系中更有意义，因此我们通过在此设置缠绕顺序来覆盖默认值。</p><p><code>剔除模式</code>确定是应该丢弃（剔除）正面或背面三角形（或两者都不）。这是一种优化，可以防止绘制不可见的三角形。</p><h4 id="Issuing-the-Draw-Call-发出绘制调用"><a href="#Issuing-the-Draw-Call-发出绘制调用" class="headerlink" title="Issuing the Draw Call(发出绘制调用)"></a>Issuing the Draw Call(发出绘制调用)</h4><p>渲染器对象在渲染过程’参数表上设置必要的缓冲区属性，然后调用适当的方法来渲染顶点。由于我们不需要发出额外的绘制调用，因此我们可以在此渲染过程中结束编码。</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[renderPass setVertexBuffer:<span class="keyword">self</span>.vertexBuffer offset:<span class="number">0</span> atIndex:<span class="number">0</span>];</span><br><span class="line"></span><br><span class="line"><span class="built_in">NSUInteger</span> uniformBufferOffset = <span class="keyword">sizeof</span>(MBEUniforms) * <span class="keyword">self</span>.bufferIndex; [renderPass setVertexBuffer:<span class="keyword">self</span>.uniformBuffer offset:uniformBufferOffset</span><br><span class="line">atIndex:<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">[renderPass drawIndexedPrimitives:<span class="built_in">MTLPrimitiveTypeTriangle</span> indexCount:[<span class="keyword">self</span>.indexBuffer length] / <span class="keyword">sizeof</span>(MBEIndex) indexType:MBEIndexType</span><br><span class="line">indexBuffer:<span class="keyword">self</span>.indexBuffer</span><br><span class="line">indexBufferOffset:<span class="number">0</span>]; </span><br><span class="line"></span><br><span class="line">[renderPass endEncoding];</span><br></pre></td></tr></table></figure><p>正如我们在前一章中看到的，第一个参数告诉Metal我们想要绘制什么类型的原始图形，无论是点，线还是三角形。其余参数告诉Metal索引缓冲区的计数，大小，地址和偏移量，用于索引到先前设置的顶点缓冲区。</p><h3 id="The-Sample-Project-示例项目"><a href="#The-Sample-Project-示例项目" class="headerlink" title="The Sample Project(示例项目)"></a>The Sample Project(示例项目)</h3><p>本章的示例代码位于04-DrawingIn3D目录中。将上面学到的所有内容整合在一起，就可以呈现出光彩夺目的旋转立方体。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;基于我们在前一章中学习的渲染管道，我们现在将开始三维渲染。&lt;/p&gt;
    
    </summary>
    
    
      <category term="iOS/Mac" scheme="https://zhaolilong.com/tags/iOS-Mac/"/>
    
      <category term="图形学" scheme="https://zhaolilong.com/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
      <category term="Metal" scheme="https://zhaolilong.com/tags/Metal/"/>
    
  </entry>
  
  <entry>
    <title>实例学习Metal-第三章 2D绘制</title>
    <link href="https://zhaolilong.com/2020/01/19/%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0Metal-%E7%AC%AC%E4%B8%89%E7%AB%A0/"/>
    <id>https://zhaolilong.com/2020/01/19/实例学习Metal-第三章/</id>
    <published>2020-01-18T16:00:00.000Z</published>
    <updated>2020-03-13T01:50:26.409Z</updated>
    
    <content type="html"><![CDATA[<p>基于我们在前一章中学习的渲染管道，我们现在将开始三维渲染。</p><a id="more"></a><h1 id="Chapter-3-第三章"><a href="#Chapter-3-第三章" class="headerlink" title="Chapter 3(第三章)"></a>Chapter 3(第三章)</h1><h2 id="Drawing-in-2D-2D绘制"><a href="#Drawing-in-2D-2D绘制" class="headerlink" title="Drawing in 2D(2D绘制)"></a>Drawing in 2D(2D绘制)</h2><p>在上一章中，我们了解了Metal框架的许多基本移动部分：设备，纹理，命令缓冲区和命令队列。虽然它引入了很多Metal的移动部件，但我们无法同时覆盖所有部件。本章将为渲染几何体时使用的Metal部分的讨论增加更多深度。特别是，我们将通过Metal渲染管道，介绍函数和库，并发出我们的第一个绘制调用。</p><p>本章的最终目标是向您展示如何使用Metal开始渲染实际几何体。我们绘制的三角形只能是2D。随后的章节将介绍绘制3D形状所需的数学，并最终为3D模型制作动画。</p><h3 id="Setup-设置"><a href="#Setup-设置" class="headerlink" title="Setup(设置)"></a>Setup(设置)</h3><p>MBEMetalView类的初始化程序已经过重构，可以调用一系列方法，这些方法将完成为使我们准备渲染所需的所有工作：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="keyword">self</span> makeDevice]; </span><br><span class="line">[<span class="keyword">self</span> makeBuffers]; </span><br><span class="line">[<span class="keyword">self</span> makePipeline];</span><br></pre></td></tr></table></figure><p><code>-makeDevice</code>与以前在<code>-init</code>方法中直接包含的代码完全相同，正如我们在第2章中看到的：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"> - (<span class="keyword">void</span>)makeDevice </span><br><span class="line"> &#123;</span><br><span class="line">    device = <span class="built_in">MTLCreateSystemDefaultDevice</span>();</span><br><span class="line">    <span class="keyword">self</span>.metalLayer.device = device;</span><br><span class="line">    <span class="keyword">self</span>.metalLayer.pixelFormat = <span class="built_in">MTLPixelFormatBGRA8Unorm</span>; </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">其他两种方法的定义将在以下部分中给出。</span><br><span class="line"></span><br><span class="line"><span class="meta">### Using Buffers to Store Data(使用缓冲区存储数据)</span></span><br><span class="line"></span><br><span class="line">Metal提供了一个协议<span class="built_in">MTLBuffer</span>，用于表示具有固定长度的无类型字节缓冲区。它的接口与<span class="built_in">NSData</span>非常相似，它具有contents属性（如<span class="built_in">NSData</span>的bytes属性）和`length`属性。但是，通过从Metal设备请求特定大小的缓冲区来创建Metal缓冲区。</span><br><span class="line"></span><br><span class="line">我们将使用一个Metal缓冲区来存储我们想要绘制的顶点的位置和颜色。这称为`交错`缓冲区，因为位置和颜色数据被编织在一起成为一个连续的流，而不是为每个顶点属性指定单独的缓冲区。</span><br><span class="line"></span><br><span class="line">我们定义一个结构来保持每个顶点的位置和颜色。这个结构的成员是`vector_float4`类型，它是Apple的SIMD（代表“单指令，多数据”）框架提供的类型。在某些情况下，SIMD类型可以比常规浮动阵列更有效地操作。金属着色器最自然地在SIMD数据上运行，因此我们也在客户端代码中使用它们。</span><br><span class="line"></span><br><span class="line">这是我们的顶点类型，表示具有位置和颜色的顶点：</span><br><span class="line"></span><br><span class="line">```objc</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> </span><br><span class="line">&#123;</span><br><span class="line">    vector_float4 position;</span><br><span class="line">    vector_float4 color; </span><br><span class="line">&#125; MBEVertex;</span><br></pre></td></tr></table></figure><p>我们的缓冲区将包含三个顶点，足以绘制一个三角形。顶点分别为红色，绿色和蓝色。由于这些值不会改变，我们静态声明它们，然后向Metal询问包含值副本的缓冲区：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">- (<span class="keyword">void</span>)makeBuffers </span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">const</span> MBEVertex vertices[] = </span><br><span class="line">    &#123;</span><br><span class="line">        &#123;.position=&#123; <span class="number">0.0</span>, <span class="number">0.5</span>,<span class="number">0</span>,<span class="number">1</span>&#125;,.color=&#123;<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>&#125;&#125;, </span><br><span class="line">        &#123;.position=&#123;<span class="number">-0.5</span>,<span class="number">-0.5</span>,<span class="number">0</span>,<span class="number">1</span>&#125;,.color=&#123;<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>&#125;&#125;, </span><br><span class="line">        &#123;.position=&#123; <span class="number">0.5</span>,<span class="number">-0.5</span>,<span class="number">0</span>,<span class="number">1</span>&#125;,.color=&#123;<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>&#125;&#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="keyword">self</span>.vertexBuffer = [device newBufferWithBytes:vertices length:<span class="keyword">sizeof</span>(vertices) options:<span class="built_in">MTLResourceOptionCPUCacheModeDefault</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>您可能已经注意到每个顶点位置由四个组件组成，即使我们只关心x和y位置（因为我们绘制的是2D三角形）。这是因为Metal在4D齐次坐标中最自然地工作，其中每个点都有x，y，z和w坐标，w固定为1.我们使用齐次坐标，因为它们使得平移和投影等变换更自然。我们将在下一章中介绍这些转换。</p><p>为了简化我们需要在着色器中进行的数学运算，这些点在剪辑空间坐标中指定，其中x轴从左到右从-1到1运行，y轴从-1到1运行从下到上。</p><p>每种颜色都由熟悉的红色，绿色，蓝色和alpha组成。</p><p>现在，让我们看一下绘制时将处理这些数据的顶点和片段函数。</p><h3 id="Functions-and-Libraries-函数与库"><a href="#Functions-and-Libraries-函数与库" class="headerlink" title="Functions and Libraries(函数与库)"></a>Functions and Libraries(函数与库)</h3><p>如第1章所述，现代图形API提供了“可编程管道”，这意味着它们允许GPU执行的许多操作由应用于每个顶点或像素的小程序指定。这些通常被称为“着色”。这是一个糟糕的名称，因为着色器不仅仅是计算像素的阴影（颜色）。核心Metal框架不使用该名称“着色器”，但在本文中我们将与“函数”互换使用。</p><p>要将Metal着色器代码合并到我们的项目中，我们需要向项目添加Metal源文件以包含将处理顶点和片段的着色器。</p><p><img src="/2020/01/19/实例学习Metal-第三章/1584062747.png" alt=""></p><center>图3.1：在Xcode中添加Metal Shader源文件</center><p>以下是Shaders.metal的序文：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">using namespace metal;</span><br><span class="line">struct Vertex </span><br><span class="line">&#123;</span><br><span class="line">    float4 position [[position]];</span><br><span class="line">    float4 color; </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>我们定义了一个名为Vertex的结构，它看起来与我们在Objective-C客户端代码中创建的顶点结构非常相似。一个区别是每个成员都是float4类型而不是vector_float4。这些在概念上是相同的类型（四个32位浮点数的SIMD向量），但由于金属着色语言源自C ++，因此它的编写方式不同。金属着色器代码中的向量和矩阵类型属于simd命名空间，由着色器编译器推断，允许我们简单地将类型写为float4。</p><p>另一个区别是位置struct成员上存在[[position]]属性。此属性用于表示Metal应将哪个值视为顶点着色器返回的顶点的剪辑空间位置。从顶点着色器返回自定义结构时，结构的一个成员必须具有此属性。或者，您可以从顶点函数返回一个float4，它隐含地假定为顶点的位置。</p><p>Metal着色器函数的定义必须以<code>函数限定符</code>为前缀，该函数限定符是<code>vertex</code>，<code>fragment</code>或<code>kernel</code>之一。<code>vertex</code>函数限定符表示函数将用作顶点着色器，该几何体在几何体中的每个正在被绘制顶点上运行一次。在这种情况下，我们的顶点着色器名为<code>vertex_main</code>，它看起来像这样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vertex Vertex vertex_main(device Vertex *vertices [[buffer(0)]], uint vid [[vertex_id]])</span><br><span class="line">&#123;</span><br><span class="line">    return vertices[vid];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于我们没有在顶点着色器中变换顶点的位置或颜色，我们可以简单地返回（通过复制）参数指定的索引处的顶点，其中[[vertex_id]]属性从0到2运行为为每个顶点调用顶点函数。如果我们正在做更复杂的工作，比如投影顶点或顶点照明，我们会在这里做。我们将在后续章节中看到更高级的顶点着色器。</p><p>由于我们绘制到屏幕的每个三角形可能覆盖许多像素，因此必须有一个管道阶段，该阶段采用顶点函数返回的值并对其进行插值，以便为当前三角形中的每个可能像素（片段）生成一个值。这个阶段称为光栅化器。光栅化器有效地“切割”三角形到它们的组成片段中，并为可能受当前三角形影响的每个像素的每个属性（在我们的例子中为位置和颜色）产生插值。然后将这些插入的值传递给片段函数，片段函数执行任何必要的每片段工作（例如纹理和每像素照明）。</p><p>片段函数的来源非常简短：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fragment float4 fragment_main(Vertex inVertex [[stage_in]]) </span><br><span class="line">&#123;</span><br><span class="line">    return inVertex.color; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>片段函数<code>fragment_main</code>采用Vertex限定的属性标识<code>[[stage_in]]</code>，它将其标识为每片段数据，而不是绘制调用中常量的数据。此顶点与顶点函数返回的顶点实例不完全对应。而是，如上所述，它是由光栅化器生成的插值版本。</p><p>片段函数负责返回要写入渲染缓冲区的颜色，因此<code>fragment_main</code>只提取（插入的）片段颜色并返回它。</p><h4 id="Libraries-库"><a href="#Libraries-库" class="headerlink" title="Libraries(库)"></a>Libraries(库)</h4><p>通常，图形库需要单独编译每个着色器的源。然后必须将着色器链接在一起以形成程序。 Metal在着色器周围引入了更好的抽象：库。库只不过是用Metal着色语言编写的逻辑功能组。在本章的示例项目中，我们将顶点和片段函数集中到一个文件（Shaders.metal）中。此文件将与项目的其余部分一起编译，编译的函数包含在应用程序包中。 Metal允许我们在运行时通过名称轻松查找函数，如下一个清单所示。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">id&lt;MTLLibrary&gt; library = [self.device newDefaultLibrary];</span><br><span class="line"></span><br><span class="line">id&lt;MTLFunction&gt; vertexFunc = [library newFunctionWithName:@&quot;vertex_main&quot;]; </span><br><span class="line">id&lt;MTLFunction&gt; fragmentFunc = [library newFunctionWithName:@&quot;fragment_main&quot;];</span><br></pre></td></tr></table></figure><p>我们也可以选择在运行时将应用程序的着色器动态编译为库，并从中请求函数对象。由于着色器代码在应用程序编译时是已知的，这是一个不必要的步骤，我们只使用默认库。</p><p>一旦引用了顶点和片段函数，就可以配置管道以使用它们，并且Metal会隐式执行必要的链接。这将在以下部分中说明。上面的代码包含在示例代码中的<code>-makePipeline</code>方法中。</p><h3 id="The-Render-Pipeline-渲染管道"><a href="#The-Render-Pipeline-渲染管道" class="headerlink" title="The Render Pipeline(渲染管道)"></a>The Render Pipeline(渲染管道)</h3><p>前几代图形库让我们将图形硬件视为状态机：你设置一些状态（比如从哪里拉数据，以及绘制调用是否应该写入深度缓冲区），并且该状态会影响绘制调用你问题之后。存在像OpenGL这样的图形库中的大多数API调用，以允许您设置状态的各个方面。对于第1章中讨论的“固定功能管道”尤其如此。</p><p>金属提供了一些不同的模型。不是调用作用于某个全局“上下文”对象的API，而是将大部分Metal的状态构建到预编译对象中，这些对象包含从一端获取顶点数据并在另一端生成光栅化图像的虚拟管道。</p><p>为什么这很重要？通过要求在预编译渲染状态中冻结昂贵的状态更改，Metal可以预先执行验证，否则必须在每次绘制调用时执行。像OpenGL这样的复杂状态机会花费大量的CPU时间，只需确保状态配置是自洽的。 Metal要求我们在管道创建过程中修复最昂贵的状态更改，而不是允许它们随时随意更改，从而避免了这种开销。让我们更深入地看一下。</p><h4 id="Render-Pipeline-Descriptors-渲染管道描述符"><a href="#Render-Pipeline-Descriptors-渲染管道描述符" class="headerlink" title="Render Pipeline Descriptors(渲染管道描述符)"></a>Render Pipeline Descriptors(渲染管道描述符)</h4><p>为了构建描述Metal应该如何渲染几何体的管道状态，我们需要创建一个描述符对象，它将一些东西连接起来：我们想要在绘制时使用的顶点和片段函数，以及我们的帧缓冲区的格式附件。<br>渲染管道描述符是MTLRenderPipelineDescriptor类型的对象，它包含管道的配置选项。以下是我们如何创建管道描述符对象：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">MTLRenderPipelineDescriptor</span> *pipelineDescriptor = [<span class="built_in">MTLRenderPipelineDescriptor</span> new];</span><br><span class="line">pipelineDescriptor.vertexFunction = vertexFunc; </span><br><span class="line">pipelineDescriptor.fragmentFunction = fragmentFunc; </span><br><span class="line">pipelineDescriptor.colorAttachments[<span class="number">0</span>].pixelFormat = <span class="keyword">self</span>.metalLayer.pixelFormat;</span><br></pre></td></tr></table></figure><p>顶点和片段函数属性设置为我们先前从默认库请求的函数对象。</p><p>绘图时，我们可以定位许多不同类型的附件。附件描述了绘制结果的纹理。在这种情况下，我们只有一个附件：索引0处的颜色附件。这表示实际将在屏幕上显示的纹理。我们将附件的像素格式设置为<code>CAMetalLayer</code>的像素格式，后者支持我们的视图，以便Metal知道要绘制的纹理中像素的颜色深度和组件顺序。</p><p>既然我们有了一个管道描述符，我们需要让Metal来完成创建工作渲染管道状态。</p><h4 id="Render-Pipeline-State-渲染管道状态"><a href="#Render-Pipeline-State-渲染管道状态" class="headerlink" title="Render Pipeline State(渲染管道状态)"></a>Render Pipeline State(渲染管道状态)</h4><p><code>渲染管道状态</code>是符合协议<code>MTLRenderPipelineState</code>的对象。我们通过向设备提供新创建的管道描述符来创建管道状态，将结果存储在另一个名为pipeline的属性中。</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">self</span>.pipeline = [<span class="keyword">self</span>.device newRenderPipelineStateWithDescriptor:pipelineDescriptor</span><br><span class="line">error:<span class="literal">NULL</span>];</span><br></pre></td></tr></table></figure><p>管道状态封装了从我们在描述符上设置的着色器派生的编译和链接着色器程序。因此，它是一个有点昂贵的对象。理想情况下，您只需为每对着色器函数创建一个渲染管道状态，但有时候附件的目标像素格式会有所不同，因此需要额外的渲染管道状态对象。关键是创建渲染管道状态对象是昂贵的，因此您应该避免在每帧的基础上创建它们，并尽可能地缓存它们。</p><p>上面的代码是示例代码中-buildPipeline方法的核心部分。由于渲染管道状态对象将在我们的应用程序的生命周期中存活，因此我们将其存储在属性中。我们还创建了一个命令队列并将其存储在一个属性中，如前一章所述。</p><h3 id="Encoding-Render-Commands-编码渲染命令"><a href="#Encoding-Render-Commands-编码渲染命令" class="headerlink" title="Encoding Render Commands(编码渲染命令)"></a>Encoding Render Commands(编码渲染命令)</h3><p>在上一章中，我们没有与render命令编码器进行太多交互，因为我们没有执行任何绘图。这一次，我们需要将实际绘制调用编码到渲染命令缓冲区中。首先，让我们重新审视从图层和渲染过程描述符的配置中检索drawable。这是此示例项目的<code>-redraw</code>方法的开头：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">id&lt;CAMetalDrawable&gt; drawable = [self.metalLayer nextDrawable]; </span><br><span class="line">id&lt;MTLTexture&gt; framebufferTexture = drawable.texture;</span><br><span class="line">`</span><br></pre></td></tr></table></figure><p>如果由于某种原因我们没有从drawable中获得可绘制或可渲染的纹理，则实际的绘制调用由<code>if(drawable)</code>条件保护。尝试使用纹理为nil的传递描述符创建命令缓冲区将导致异常。</p><p>renderPass对象的构造与之前完全相同，只是我们选择了浅灰色来清除屏幕，而不是我们上次使用的令人讨厌的红色。</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">MTLRenderPassDescriptor</span> *passDescriptor = [<span class="built_in">MTLRenderPassDescriptor</span> renderPassDescriptor];</span><br><span class="line">passDescriptor.colorAttachments[<span class="number">0</span>].texture = framebufferTexture; </span><br><span class="line">passDescriptor.colorAttachments[<span class="number">0</span>].clearColor = <span class="built_in">MTLClearColorMake</span>(<span class="number">0.85</span>, <span class="number">0.85</span>, <span class="number">0.85</span>, <span class="number">1</span>);</span><br><span class="line">passDescriptor.colorAttachments[<span class="number">0</span>].storeAction = <span class="built_in">MTLStoreActionStore</span>; </span><br><span class="line">passDescriptor.colorAttachments[<span class="number">0</span>].loadAction = <span class="built_in">MTLLoadActionClear</span>;</span><br></pre></td></tr></table></figure><p>现在，我们通过使用渲染传递描述符创建渲染命令编码器并对我们的绘制调用进行编码来启动渲染过程：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">id</span>&lt;<span class="built_in">MTLRenderCommandEncoder</span>&gt; commandEncoder = [commandBuffer renderCommandEncoderWithDescriptor:passDescriptor];</span><br><span class="line">[commandEncoder setRenderPipelineState:<span class="keyword">self</span>.pipeline]; </span><br><span class="line">[commandEncoder setVertexBuffer:<span class="keyword">self</span>.vertexBuffer offset:<span class="number">0</span> atIndex:<span class="number">0</span>]; </span><br><span class="line">[commandEncoder drawPrimitives:<span class="built_in">MTLPrimitiveTypeTriangle</span> vertexStart:<span class="number">0</span> vertexCount:<span class="number">3</span>]; </span><br><span class="line">[commandEncoder endEncoding];</span><br></pre></td></tr></table></figure><p>-setVertexBuffer：偏移量：atIndex：方法用于从我们之前创建的MTLBuffer对象映射到着色器代码中的顶点函数的参数回想顶点参数是用[[缓冲液（0）]]属性归因的，注意我们现在在准备绘制调用时提供索引0。<br>我们调用<code>-drawPrimitives:vertexStart:vertexCount:instanceCount:</code>。方法来编写绘制三角形的请求我们将0传递给<code>vertexStart</code>参数，以便我们从缓冲区的最开始绘制我们为<code>vertexCount</code>传递3，因为三角形有三个点。<br>我们像以前一样通过触发绘制的显示并提交命令缓冲区来完成：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[commandBuffer presentDrawable:drawable]; </span><br><span class="line">[commandBuffer commit];</span><br></pre></td></tr></table></figure><p>这些行完善了<code>-redraw</code>方法的新实现。</p><h3 id="Staying-In-Sync-With-CADisplayLink-与CADisplayLink保持同步"><a href="#Staying-In-Sync-With-CADisplayLink-与CADisplayLink保持同步" class="headerlink" title="Staying In-Sync With CADisplayLink(与CADisplayLink保持同步)"></a>Staying In-Sync With CADisplayLink(与CADisplayLink保持同步)</h3><p>现在我们的-redraw实现已经完成，我们需要弄清楚如何重复调用它。我们可以使用常规的旧NSTimer，但Core Animation提供了更好的方法：CADisplayLink。这是一种特殊的定时器，与设备的显示环路同步，从而实现更一致的定时。每次显示链接<br>火，我们将调用我们的-redraw方法来更新屏幕。</p><p>我们重写-didMoveToSuperview来配置显示链接：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">- (void)didMoveToSuperview</span><br><span class="line">&#123;</span><br><span class="line">    [super didMoveToSuperview]; </span><br><span class="line">    if (self.superview)</span><br><span class="line">    &#123;</span><br><span class="line">        self.displayLink = [CADisplayLink displayLinkWithTarget:self selector:@selector(displayLinkDidFire:)];</span><br><span class="line">        [self.displayLink addToRunLoop:[NSRunLoop mainRunLoop] forMode:NSRunLoopCommonModes];</span><br><span class="line">    &#125; </span><br><span class="line">    else </span><br><span class="line">    &#123;</span><br><span class="line">        [self.displayLink invalidate];</span><br><span class="line">        self.displayLink = nil; </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这将创建一个显示链接，并使用主运行循环对其进行计划。如果我们从超级视图中删除，我们将使显示链接无效并将其取消。</p><p>每秒六十次，显示链接触发并调用其目标方法<code>-displayLinkDidFire:</code>，后者又调用<code>-redraw</code>:</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- (<span class="keyword">void</span>)displayLinkDidFire:(<span class="built_in">CADisplayLink</span> *)displayLink </span><br><span class="line">&#123;</span><br><span class="line">    [<span class="keyword">self</span> redraw]; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="The-Sample-Project-示例项目"><a href="#The-Sample-Project-示例项目" class="headerlink" title="The Sample Project(示例项目)"></a>The Sample Project(示例项目)</h3><p>本章的示例项目位于03-DrawingIn2D目录中。如果您构建并运行它，您应该会在屏幕上看到一个非常彩色的三角形。</p><p><img src="/2020/01/19/实例学习Metal-第三章/1584062830.png" alt=""></p><center>图3.2：由Metal渲染的多色三角形</center><p>请注意，如果旋转显示屏，则三角形会扭曲。这是因为我们在剪辑空间中指定了三角形的坐标，无论纵横比如何，它始终沿着每个轴从-1到1运行。在下一章中，我们将讨论如何在渲染三维图形时补偿纵横比。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;基于我们在前一章中学习的渲染管道，我们现在将开始三维渲染。&lt;/p&gt;
    
    </summary>
    
    
      <category term="iOS/Mac" scheme="https://zhaolilong.com/tags/iOS-Mac/"/>
    
      <category term="图形学" scheme="https://zhaolilong.com/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
      <category term="Metal" scheme="https://zhaolilong.com/tags/Metal/"/>
    
  </entry>
  
  <entry>
    <title>实例学习Metal-第二章 设置舞台并清除屏幕</title>
    <link href="https://zhaolilong.com/2020/01/12/%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0Metal-%E7%AC%AC%E4%BA%8C%E7%AB%A0/"/>
    <id>https://zhaolilong.com/2020/01/12/实例学习Metal-第二章/</id>
    <published>2020-01-11T16:00:00.000Z</published>
    <updated>2020-03-13T01:53:13.027Z</updated>
    
    <content type="html"><![CDATA[<p>本章介绍了在Metal中将屏幕清除为纯色所需的最低限度。即使这种简单的操作也需要金属框架所暴露的许多概念。以下章节将以此材料为基础，演示如何进行3D渲染等。</p><a id="more"></a><h1 id="Chapter2-第二章"><a href="#Chapter2-第二章" class="headerlink" title="Chapter2 (第二章)"></a>Chapter2 (第二章)</h1><h2 id="Setting-the-Stage-and-Clearing-the-Screen-设置舞台和清除屏幕"><a href="#Setting-the-Stage-and-Clearing-the-Screen-设置舞台和清除屏幕" class="headerlink" title="Setting the Stage and Clearing the Screen(设置舞台和清除屏幕)"></a>Setting the Stage and Clearing the Screen(设置舞台和清除屏幕)</h2><p>本章介绍了在Metal中将屏幕清除为纯色所需的最低限度。即使这种简单的操作也需要金属框架所暴露的许多概念。以下章节将以此材料为基础，演示如何进行3D渲染等。</p><h3 id="Creating-a-New-Project-创建一个新项目"><a href="#Creating-a-New-Project-创建一个新项目" class="headerlink" title="Creating a New Project(创建一个新项目)"></a>Creating a New Project(创建一个新项目)</h3><p>让我们在Xcode中创建一个新项目。我们更喜欢从单视图模板开始，因为它创建了一个视图控制器并将它连接到我们的窗口。</p><p><img src="/2020/01/12/实例学习Metal-第二章/1584062478.png" alt=""></p><center>图2.1：在Xcode中创建一个新的单视图项目</center><h3 id="Interfacing-with-UIKit-与UIKit接口"><a href="#Interfacing-with-UIKit-与UIKit接口" class="headerlink" title="Interfacing with UIKit(与UIKit接口)"></a>Interfacing with UIKit(与UIKit接口)</h3><p>iOS上的每个UIView都使用Core Animation层作为其后备存储。换句话说，视图的图层包含在屏幕上绘制的实际内容。我们说这样的视图由CALayer实例支持。</p><p>您可以通过覆盖UIView子类上的<code>+layerClass</code>方法，告诉UIView更改它实例化为其后备层的图层类型。</p><p>您可以使用Xcode中的“File•New•File …”菜单在您自己的项目中进行操作，并生成一个新的Cocoa Touch类，它是UIView的子类。我们称之为<code>MBEMetalView</code>。</p><p><img src="/2020/01/12/实例学习Metal-第二章/1584062555.png" alt=""></p><center>图2.2：在Xcode中添加一个新的UIView子类</center><p>CAMetalLayer不是由Metal框架提供，而是由Core Animation提供。 CAMetalLayer是将UIKit和Metal绑定在一起的粘合剂，它提供了一些我们很快就会看到的非常好的功能。</p><p>让我们在UIView子类中实现+ layerClass，这样它就知道我们需要一个Metal层而不是一个CALayer。以下是完整的MBEMetalView实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@implementation MBEMetalView</span><br><span class="line"></span><br><span class="line">+ (id)layerClass </span><br><span class="line">&#123;</span><br><span class="line">    return [CAMetalLayer class]; </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@end</span><br></pre></td></tr></table></figure><p>将主故事板文件中的视图的自定义类更改为<code>MBEMetalView</code>。这将导致在加载故事板时实例化子类。这反过来为我们提供了一个适当的Metal层支持视图。</p><p><img src="/2020/01/12/实例学习Metal-第二章/1584062589.png" alt=""></p><center>图2.3：为视图控制器的根视图设置自定义类</center><p>为方便起见，您可以添加一个属性到您的视图类，它是一个CAMetalLayer类型的。</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">@property</span> (<span class="keyword">readonly</span>) <span class="built_in">CAMetalLayer</span> *metalLayer;</span><br></pre></td></tr></table></figure><p>这可以防止您不得不重复从图层属性（即<code>CALayer</code>）的类型转换为实际的子类（<code>CAMetalLayer</code>），因为<code>CAMetalLayer</code>提供了一些在<code>CALayer</code>上找不到的方法。您可以按如下方式实现此属性：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- (<span class="built_in">CAMetalLayer</span> *)metalLayer </span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span> (<span class="built_in">CAMetalLayer</span> *)<span class="keyword">self</span>.layer;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果您在设备上构建并运行此项目，您将只看到纯白色屏幕。要实际进行任何绘图，我们需要了解Metal设备以及它们帮助我们创建的所有其他对象。首先，关于在Metal中使用协议的一个词。</p><h3 id="Protocols-协议"><a href="#Protocols-协议" class="headerlink" title="Protocols(协议)"></a>Protocols(协议)</h3><p>Metal API中的一个共同主题是使用协议而不是具体类来公开Metal功能。许多Metal API返回符合特定协议的对象，具体类型是次要的。这样做的好处是您无需关心实现该功能的确切类。</p><p>声明符合协议MTLDevice的对象的语法如下所示：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">id</span> &lt;<span class="built_in">MTLDevice</span>&gt; device;</span><br></pre></td></tr></table></figure><p>现在，我们来看看如何检索和使用设备。</p><h3 id="Devices-设备"><a href="#Devices-设备" class="headerlink" title="Devices(设备)"></a>Devices(设备)</h3><p>设备是GPU的抽象。它提供了创建命令队列，渲染状态和库等对象的方法。我们将很快查看其中的每一个。</p><p>Metal提供了一个C函数<code>MTLCreateSystemDefaultDevice</code>，它可以创建并返回一个满足我们需求的设备。此函数不带参数，因为没有可指定的设备属性。</p><p>我们的Metal层需要知道哪个设备将被渲染到其中。我们还需要在图层上配置像素格式，以便每个人都对其颜色组件的大小和顺序达成一致。 <code>MTLPixelFormatBGRA8Unorm</code>是一个不错的选择。使用此像素格式，每个像素将由蓝色，绿色，红色和alpha分量组成，每个分量将是一个8位无符号整数（介于0和255之间）。</p><p>在视图子类上创建设备属性很有帮助，因为我们需要设备在代码的其余部分为我们创建各种资源：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">@interface</span> <span class="title">MBEMetalView</span> ()</span></span><br><span class="line"><span class="keyword">@property</span> (<span class="keyword">readonly</span>) <span class="keyword">id</span>&lt;<span class="built_in">MTLDevice</span>&gt; device; </span><br><span class="line"><span class="keyword">@end</span></span><br></pre></td></tr></table></figure><p>在我们使用Metal的函数之前，我们需要使用以下行导入Metal模块：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">@import</span> Metal;</span><br></pre></td></tr></table></figure><p>以下是<code>-init</code>的完整实现，显示了所有必要的配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">- (instancetype)initWithCoder:(NSCoder *)aDecoder </span><br><span class="line">&#123;</span><br><span class="line">    if ((self = [super initWithCoder:aDecoder])) </span><br><span class="line">    &#123;</span><br><span class="line">        _metalLayer = (CAMetalLayer *)[self layer];</span><br><span class="line">        _device = MTLCreateSystemDefaultDevice(); _metalLayer.device = _device; </span><br><span class="line">        _metalLayer.pixelFormat = MTLPixelFormatBGRA8Unorm;</span><br><span class="line">    &#125;</span><br><span class="line">    return self; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>请注意，我们覆盖<code>initWithCoder:</code>因为我们知道我们正在从故事板加载我们的视图。为了完整起见，我们还应该包含一个<code>init</code>的重写，以便我们可以以编程方式实例化该类。</p><h3 id="The-redraw-method-重绘方法"><a href="#The-redraw-method-重绘方法" class="headerlink" title="The redraw method(重绘方法)"></a>The redraw method(重绘方法)</h3><p>在接下来的章节中，我们将绘图的责任委托给一个单独的类。目前，我们的视图类中的<code>-redraw</code>方法是我们发出绘图命令的地方。此外，我们不会重复重绘屏幕，只需将其清除一次为纯色。因此，只需调用<code>-redraw</code>就足够了。我们可以通过覆盖<code>-didMoveToWindow</code>方法来调用它，因为这个方法将在应用程序启动时调用一次。</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- (<span class="keyword">void</span>)didMoveToWindow </span><br><span class="line">&#123;</span><br><span class="line">    [<span class="keyword">self</span> redraw]; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>重绘方法本身将完成清除屏幕所需的所有工作。本章其余部分的所有代码都包含在此方法中。</p><h3 id="Textures-and-Drawables-纹理和绘图"><a href="#Textures-and-Drawables-纹理和绘图" class="headerlink" title="Textures and Drawables(纹理和绘图)"></a>Textures and Drawables(纹理和绘图)</h3><p>Metal中的纹理是图像的容器。您可能习惯将纹理视为单个图像，但Metal中的纹理更抽象。 Metal还允许单个纹理对象表示图像<code>阵列</code>，每个图像称为<code>切片</code>。纹理中的每个图像都具有特定的大小和像素格式。纹理可以是1D，2D或3D。</p><p>我们现在不需要任何这些奇特的纹理。相反，我们将使用单个2D纹理作为我们的渲染缓冲区（即，实际像素被写入的位置）。此文本将与我们的应用程序运行设备的屏幕具有相同的分辨率。我们通过使用Core Animation提供的功能之一获得对此纹理的引用：<code>CAMetalDrawable</code>协议。</p><p>可绘制物(drawable)是由Metal层提供的物体，可以为我们提供可渲染的纹理。每次绘制时，我们都会向Metal图层请求一个可绘制对象，我们可以从中提取一个充当我们帧缓冲区的纹理。代码非常简单：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">id</span>&lt;<span class="built_in">CAMetalDrawable</span>&gt; drawable = [<span class="keyword">self</span>.metalLayer nextDrawable]; </span><br><span class="line"><span class="keyword">id</span>&lt;<span class="built_in">MTLTexture</span>&gt; texture = drawable.texture;</span><br></pre></td></tr></table></figure><p>当我们完成渲染到纹理时，我们还将使用drawable向核心动画发信号，因此它可以在屏幕上显示。要实际清除帧缓冲区的纹理，我们需要设置一个渲染通道描述符来描述每帧采取的操作。</p><h3 id="Render-Passes-渲染通道"><a href="#Render-Passes-渲染通道" class="headerlink" title="Render Passes(渲染通道)"></a>Render Passes(渲染通道)</h3><p><code>渲染过程描述符</code>告诉Metal在渲染图像时要执行的操作。在渲染过程开始时，<code>loadAction</code>确定是否清除或保留纹理的先前内容。 <code>storeAction</code>确定了什么<br>渲染对纹理的影响：结果可以存储或丢弃。由于我们希望我们的像素在屏幕上结束，因此我们选择我们的商店操作为<code>MTLStoreActionStore</code>。</p><p>传递描述符也是我们选择在绘制任何几何图形之前屏幕将被清除的颜色的位置。在下面的情况中，我们选择不透明的红色（red= 1，green= 0，blue= 0，alpha = 1）。</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">MTLRenderPassDescriptor</span> *passDescriptor = [<span class="built_in">MTLRenderPassDescriptor</span> renderPassDescriptor];</span><br><span class="line">passDescriptor.colorAttachments[<span class="number">0</span>].texture = texture; </span><br><span class="line">passDescriptor.colorAttachments[<span class="number">0</span>].loadAction = <span class="built_in">MTLLoadActionClear</span>; </span><br><span class="line">passDescriptor.colorAttachments[<span class="number">0</span>].storeAction = <span class="built_in">MTLStoreActionStore</span>; </span><br><span class="line">passDescriptor.colorAttachments[<span class="number">0</span>].clearColor = <span class="built_in">MTLClearColorMake</span>(<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>);</span><br></pre></td></tr></table></figure><p>下面将使用渲染过程描述符来创建用于执行渲染命令的命令编码器。我们有时会将命令编码器本身称为<code>渲染过程</code>。</p><h3 id="Queues-Buffers-and-Encoders-队列，缓冲区和编码器"><a href="#Queues-Buffers-and-Encoders-队列，缓冲区和编码器" class="headerlink" title="Queues, Buffers, and Encoders(队列，缓冲区和编码器)"></a>Queues, Buffers, and Encoders(队列，缓冲区和编码器)</h3><p><code>命令队列</code>是一个对象，用于保存要执行的渲染命令缓冲区列表。我们只需询问设备即可获得一个。通常，命令队列是一个长期存在的对象，因此在更高级的场景中，我们将保留为多个帧创建的队列。</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">id</span>&lt;<span class="built_in">MTLCommandQueue</span>&gt; commandQueue = [<span class="keyword">self</span>.device newCommandQueue];</span><br></pre></td></tr></table></figure><p><code>命令缓冲区</code>表示要作为一个单元执行的渲染命令的集合。每个命令缓冲区都与一个队列相关联：</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">id</span>&lt;<span class="built_in">MTLCommandBuffer</span>&gt; commandBuffer = [commandQueue commandBuffer];</span><br></pre></td></tr></table></figure><p>命令编码器是一个对象，用于告诉Metal我们实际想要做什么的绘图。它负责将这些高级命令（设置这些着色器参数，绘制这些三角形等）转换为低级指令，然后将这些指令写入相应的命令缓冲区。一旦我们发出了所有的绘制调用（我们将在下一章讨论），我们将endEncoding消息发送到命令编码器，以便它有机会完成其编码。</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">id</span> &lt;<span class="built_in">MTLRenderCommandEncoder</span>&gt; commandEncoder = [commandBuffer renderCommandEncoderWithDescriptor:passDescriptor];</span><br><span class="line">[commandEncoder endEncoding];</span><br></pre></td></tr></table></figure><p>作为最后一个操作，命令缓冲区将发出信号，一旦所有前面的命令完成，其drawable将准备好显示在屏幕上。然后，我们调用commit来指示此命令缓冲区已完成并准备好放入命令队列以便在GPU上执行。反过来，这将导致我们的帧缓冲区填充我们选择的清晰颜色，红色。</p><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[commandBuffer presentDrawable:drawable]; </span><br><span class="line">[commandBuffer commit];</span><br></pre></td></tr></table></figure><h3 id="The-Sample-App-示例项目"><a href="#The-Sample-App-示例项目" class="headerlink" title="The Sample App(示例项目)"></a>The Sample App(示例项目)</h3><p>本章的示例代码位于02-ClearScreen目录中。</p><p><img src="/2020/01/12/实例学习Metal-第二章/1584062640.png" alt=""></p><center>图2.4：将屏幕清除为纯红色的结果</center><h3 id="Conclusion-总结"><a href="#Conclusion-总结" class="headerlink" title="Conclusion(总结)"></a>Conclusion(总结)</h3><p>本章为更多令人兴奋的主题奠定了基础，例如3D渲染。希望你现在对使用Metal时会看到的一些对象有所了解。在下一章中，我们将介绍2D中的绘图几何。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本章介绍了在Metal中将屏幕清除为纯色所需的最低限度。即使这种简单的操作也需要金属框架所暴露的许多概念。以下章节将以此材料为基础，演示如何进行3D渲染等。&lt;/p&gt;
    
    </summary>
    
    
      <category term="iOS/Mac" scheme="https://zhaolilong.com/tags/iOS-Mac/"/>
    
      <category term="图形学" scheme="https://zhaolilong.com/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
      <category term="Metal" scheme="https://zhaolilong.com/tags/Metal/"/>
    
  </entry>
  
  <entry>
    <title>实例学习Metal-第一章 欢迎</title>
    <link href="https://zhaolilong.com/2020/01/05/%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0Metal-%E7%AC%AC%E4%B8%80%E7%AB%A0/"/>
    <id>https://zhaolilong.com/2020/01/05/实例学习Metal-第一章/</id>
    <published>2020-01-04T16:00:00.000Z</published>
    <updated>2020-03-13T01:48:36.707Z</updated>
    
    <content type="html"><![CDATA[<p>欢迎来到<code>实例学习Metal</code>！在本书中，我们将探索Metal框架，使用它深入了解实时渲染和数据并行计算的世界。本章为本书的其余部分奠定了基础。</p><a id="more"></a><h1 id="Chapter-1-第一章"><a href="#Chapter-1-第一章" class="headerlink" title="Chapter 1 (第一章)"></a>Chapter 1 (第一章)</h1><h2 id="Welcome-欢迎"><a href="#Welcome-欢迎" class="headerlink" title="Welcome(欢迎)"></a>Welcome(欢迎)</h2><p>欢迎来到<code>Metal编程实例</code>！在本书中，我们将探索Metal框架，使用它深入了解实时渲染和数据并行计算的世界。本章为本书的其余部分奠定了基础。</p><p>本书的目的是详细解释如何在Metal中实现常见的GPU编程任务。虽然这里讨论的许多原则已经使用了几十年，但使用新框架实现它们并不总是那么容易。当一个新框架为了提高效率而消除了高级库的许多便利时，这一点尤其正确。</p><p>作为游戏或其他图形密集型应用程序的创建者，您在图形方面有很多选择。您可以使用虚幻引擎或Unity，无需接触代码即可获得跨平台支持。您可以编写SpriteKit或SceneKit代码，并利用抽象塔的优势，让您根据场景图和材料表达自己。您可以编写OpenGL或OpenGL ES代码，要求您更多地了解GPU实际上如何工作。从iOS 8开始，您可以省去大部分抽象并使用Metal。</p><p>重要的是要意识到尽管Metal是底层的，但它仍然是一个抽象层。这是一件好事，因为如果没有这样的层，我们将负责了解GPU编程的所有细节，这既是大量的知识，也可能随着新硬件的发布而发生变化。实际上，Metal本身位于驱动程序体系结构的抽象之上，驱动程序体系结构是iOS上可用的所有图形框架的通用基础。疲惫的表情，<code>龟速一路下来</code>。</p><p>另一方面，Metal使程序员比以往更大程度地负责资源管理和并发。除了各种Metal类和协议以及新的Metal着色语言之外，您还必须保持对操作内存的明确控制，以免崩溃或获得未定义的结果。本书提供的示例代码不仅向Metal本身提供了温馨介绍，而且还提供了使用它所必需的底层编程结构。</p><p>本书分为大致三个部分。在第2章到第4章中，我们介绍了Metal并教你如何在屏幕上获得3D数字动画。在第5章到第12章中，我们探讨了许多常用技术的实现，例如模型加载，光照，纹理，立方体贴图，alpha混合和文本渲染。最后两章是数据并行编程的介绍，它利用GPU进行更广泛的计算。最后，您将拥有使用Metal的技能和信心，真正释放您的创造潜力并释放GPU的全部力量。</p><p>让我们开始吧！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;欢迎来到&lt;code&gt;实例学习Metal&lt;/code&gt;！在本书中，我们将探索Metal框架，使用它深入了解实时渲染和数据并行计算的世界。本章为本书的其余部分奠定了基础。&lt;/p&gt;
    
    </summary>
    
    
      <category term="iOS/Mac" scheme="https://zhaolilong.com/tags/iOS-Mac/"/>
    
      <category term="图形学" scheme="https://zhaolilong.com/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
      <category term="Metal" scheme="https://zhaolilong.com/tags/Metal/"/>
    
  </entry>
  
  <entry>
    <title>第三章</title>
    <link href="https://zhaolilong.com/2019/03/02/%E7%AC%AC%E4%B8%89%E7%AB%A0/"/>
    <id>https://zhaolilong.com/2019/03/02/第三章/</id>
    <published>2019-03-02T15:08:19.000Z</published>
    <updated>2020-03-13T01:01:32.778Z</updated>
    
    <content type="html"><![CDATA[<p>既然您已经安装了Unity和Unity ARKit插件，现在是时候学习更多有关此工具的知识并开始我们的第一次AR体验。请注意，我称这是一种体验，而不是游戏，尽管它可能以某种方式用作游戏;从我的观点来看，游戏需要一些关键元素，我将在第4章详细介绍。</p><a id="more"></a><h1 id="第三章"><a href="#第三章" class="headerlink" title="第三章"></a>第三章</h1><h2 id="Unity-ARKit"><a href="#Unity-ARKit" class="headerlink" title="Unity ARKit"></a>Unity ARKit</h2><p>既然您已经安装了Unity和Unity ARKit插件，现在是时候学习更多有关此工具的知识并开始我们的第一次AR体验。请注意，我称这是一种体验，而不是游戏，尽管它可能以某种方式用作游戏;从我的观点来看，游戏需要一些关键元素，我将在第4章详细介绍。</p><p>如果您还没有打开我们在上一章创建的AR项目，那么现在是进行此操作的好时机。如果您查看Project文件夹（图3-1）并查看每个文件夹，您将看到Unity ARKit插件附带了许多我们将在本书中探索和使用的资源。</p><h3 id="创建一个场景"><a href="#创建一个场景" class="headerlink" title="创建一个场景"></a>创建一个场景</h3><p>我们要做的第一项任务是创建GameObject并将其放入我们的场景中并在AR中查看它。从“菜单”中，选择“GameObject”➤“三维对象”➤“多维数据集”（图3-1）。我们可以选择任何3D对象，但我希望您在AR中看到Cube并在3D空间中移动它。虽然我更喜欢Spheres，但3DCube 有六个顶点（多边形的角点），这些顶点会更容易看到。但是，我们很快就会添加不同形状的GameObject。</p><p><img src="/2019/03/02/第三章/1551539521.jpg" alt=""></p><center>图 3-1. 创建一个3D GameObject</center><p>完成此任务后，您将在“场景”面板中看到我们令人惊奇的Cube （图3-2）。</p><p><img src="/2019/03/02/第三章/1551539615.jpg" alt=""></p><center>图 3-2. 场景中的Cube GameObject</center><p>现在让我们看看Inspector（图3-3）。如果您的变换位置与我的不同，请暂时不要担心（无论如何我们将移动GameObject）。注意比例是1,1,1。 Unity使用度量标准进行测量，因此Unity空间中的1个单位相当于1米的实际值。现在对于大多数传统游戏（不是AR），这并不是初学者需要担心的（很多）。但是，因为我们将游戏资产投射到现实世界中，所以正确地进行测量和缩放变得非常重要。因此，如果我们将Cube 的比例保持在1米宽，1米高，1米深，这将是一个非常大的Cube 。用于描述3D图形中的坐标的惯例是X，Y，Z。我会在本书中使用这个标准。我将扩大我们惊人的Cube ，所以它将适合我的小公寓。一些读者可能会感到惊讶的是，大多数教学书籍的作者并不住在价值数百万美元的豪宅中（至少这位作者没有）。</p><p><img src="/2019/03/02/第三章/1551539781.jpg" alt=""></p><center>图 3-3. Inspector中的Cube GameObject</center><p>在Inspector中，设置scale为0.25, 0.25, 0.25（图 3-4）。</p><p><img src="/2019/03/02/第三章/1551539890.jpg" alt=""></p><center>图 3-4. 减小Cube 的Scale</center><p>现在，如果您在场景中查看多维数据集，它将（或应该）看起来更小（图3-5）。如果您想要仔细查看GameObject，可以将场景视图中的摄像机移动到更靠近多维数据集的位置。移动场景视图相机有两种主要方式。最简单的方法是在Hierarchy面板中选择GameObject并按f键（我记得这是f作为焦点）。另一种方法是使用鼠标中键（如果你有一个3键鼠标）来移动或移出相机或双击鼠标（如果你有一个魔术鼠标）。我（非常）老了，喜欢用我的5键鼠标。</p><p><img src="/2019/03/02/第三章/1551540009.jpg" alt=""></p><center>图 3-5. 缩小比例的Cube GameObject的场景视图</center><h3 id="摄像机"><a href="#摄像机" class="headerlink" title="摄像机"></a>摄像机</h3><p>现在是讨论相机的好时机。我们刚刚在Scene视图中移动了相机。使用此相机，开发人员可以查看场景中的内容。但是，如果查看“层次”面板，您将看到一个GameObjectMain Camera。这是玩家将要浏览的相机。您将在图3-5中注意到，我的场景视图中有一个摄像头图标。这是玩家的相机在场景中的位置。</p><p>我希望您在“层次”面板中选择“Main Camera”。您将在Scene视图右下方的小窗口中看到一个小窗口（图3-6）。此窗口显示播放器相机的视图（相机预览）。</p><p><img src="/2019/03/02/第三章/1551540191.jpg" alt=""></p><center>图 3-6. 摄像机预览</center><p>虽然Camera Preview窗口为我们提供了一个好主意 场景对玩家来说是什么样的，为了获得更好的视野，我们可以选择 游戏视图选项卡（图3-7）。</p><p><img src="/2019/03/02/第三章/1551540259.jpg" alt=""></p><center>图 3-7. 游戏视图</center><p>正如我们在前一章中看到的，我们可以使用许多设置（宽高比，比例等）。我们可以在这里看到我们惊人的Cube有点远。我们将首先移动GameObject，然后我们将移动Main Camera。</p><h3 id="变换"><a href="#变换" class="headerlink" title="变换"></a>变换</h3><p>有几种方法可以在Unity中移动（转换）GameObject。我们将使用的第一种方法（也是我使用的主要方法）是在Inspector中设置变换设置。首先，选择我们想要转换的GameObject。然后，在检查器中将变换位置设置为0,0,0（图3-8）。</p><p><img src="/2019/03/02/第三章/1551540355.jpg" alt=""></p><center>图 3-8. 具有更新的转换位置的GameObject</center><p>现在让我们看一下Main Camera，看一下播放器的外观（图3-9）。</p><p><img src="/2019/03/02/第三章/1551540437.jpg" alt=""></p><center>图 3-9. 重置变换位置的GameObject的相机预览</center><p>你会注意到GameObject距离Main Camera仍然有点太远了。在屏幕的左上角（在Hierarchy面板的正上方），有六个图标（图3-10）。</p><p><img src="/2019/03/02/第三章/1551540587.jpg" alt=""></p><center>图 3-10. 六个变换图标</center><p>第一个图标是手形工具（Q快捷方式），用于在场景视图中转换（或平移）相机。选择此工具后，在“层次结构（Hierarchy）”移动鼠标中选择任何GameObject，并注意GameObject的变换设置不会更改，但GameObject的视图会发生变化。在按住alt（选项）键的同时，使用“手形”工具可以围绕其枢轴点绕相机进行环绕。通过按住控制按钮，您可以将摄像机移动（或移动）距离GameObject更近或更远。</p><p>下一个图标是移动工具（W快捷方式）。您可以猜测，移动工具用于移动GameObject在场景中的位置。选择Main Camera后，选择移动工具（通过选择移动图标或按W键），您将注意到在场景视图中，Main Camera图标现在具有移动Gizmo（带箭头的红色，绿色蓝色线条）要点 - 图3-11）。首先，选择绿线（Y轴）并向下移动主摄像机。请注意，选择此行时，其他箭头线将显示为灰色，并且您选择的行将更改为黄色。现在尝试将相机移动到Y轴上的0。您会注意到这可能需要一些时间。如果无法正确显示位置，则可能需要在检查器的Y中输入零（这就是我更喜欢在检查器中键入值的原因）。</p><p><img src="/2019/03/02/第三章/1551540769.jpg" alt=""></p><center>图 3-11. 移动Gizmo</center><p>下一个工具是旋转工具（E快捷方式）。正如您可能猜到的，此工具用于旋转GameObject。尝试选择多维数据集，然后按R键。您将看到旋转Gizmo（图3-12）。使用旋转Gizmo，您可以通过单击并拖动围绕它出现的线框旋转Gizmo的轴来更改GameObject的旋转。使用“旋转Gizmo”时，红色，绿色和蓝色圆圈围绕红色，绿色和蓝色轴执行旋转（红色是x轴，绿色是y轴，蓝色是z轴）。外圆用于围绕场景视图z轴旋转GameObject。</p><p><img src="/2019/03/02/第三章/1551540850.jpg" alt=""></p><center>图 3-12. 旋转Gizmo</center><p>下一个工具是Scale toll（R快捷方式）。通过选择Scale Gizmo的中心然后拖动鼠标，缩放工具用于在所有轴上缩放或重新缩放GameObjects（图3-13）。您也可以使用此工具通过选择任意一个轴来在单个轴上进行缩放。</p><p><img src="/2019/03/02/第三章/1551540923.jpg" alt=""></p><center>图 3-13. 缩放Gizmo</center><p>使用多维数据集缩放多维数据集选择的Cube GameObject设置位置，或者在我们使用转换工具时它已被移动; 现在是将位置设置或重置为0,0,0的好时机（图3-14）。</p><p><img src="/2019/03/02/第三章/1551541076.jpg" alt=""></p><center>图 3-14. Cube GameObject位置设置</center><p>现在我们需要将Main Camera定位在原点（0,0,0）。如果你看看我的立方体的位置，这意味着我们的相机将在我们的立方体中间。所以，让我们先把立方体移开。将立方体变换位置设置为0,0,1，然后将主摄像机移动到0,0,0（图3-15）。现在，立方体看起来就像距离我们的相机1米远。</p><p><img src="/2019/03/02/第三章/1551541180.jpg" alt=""></p><center>图 3-15. 新的主摄像机设置</center><h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><p>现在是时候看看我们这个惊人的立方体将如何在现实世界中展现出来。在为iOS开发时，我们需要在测试或部署游戏之前使用Xcode。要在iTunes上发布AR游戏，我们需要将游戏提交给Apple进行审批，然后当它获得批准后，我们​​可以从iTunes商店下载它，看看它在我们的设备上的样子。使用Xcode，我们可以在我们的设备上预览我们的游戏将会是什么样子，但这仍然需要我们构建和运行游戏并使用Xcode来预览游戏。正如您可能想象的那样，这是一次非常耗时（并且有点令人沮丧）的体验。 Unity拯救了我们，为我们提供了Unity Remote。 Unity Remote是一个应用程序（或应用程序），可用于iTunes应用商店中的iOS设备。此工具可帮助我们在iOS设备上测试游戏，而无需将游戏提交到iTunes商店。但是，在撰写本文时，Unity Remote（版本5）不支持AR。 Unity的优秀人员已经考虑过这一挑战，并在Unity ARKit中加入了一个名为UnityARKitRemote的小程序。 Unity ARKitRemote为我们提供了在iOS设备上测试AR项目所需的工具。</p><h3 id="ARKit-Remote"><a href="#ARKit-Remote" class="headerlink" title="ARKit Remote"></a>ARKit Remote</h3><p>在项目文件夹中，输入搜索文本查找ARKit Remote预制件（图 3-16）。现在拖拽文件到Hierarchy选项卡（图 3-17）.</p><p><img src="/2019/03/02/第三章/1551595928.jpg" alt=""></p><center>图 3-16. 搜索ARKit Remote<p><img src="/2019/03/02/第三章/1551595975.jpg" alt=""></p><center>图 3-17. 在Hierarchy中的ARKitRemote预制件<h3 id="设置主摄像机"><a href="#设置主摄像机" class="headerlink" title="设置主摄像机"></a>设置主摄像机</h3><p>现在在主摄像机设定中，设置clear flag为Depth only（图 3-18）。</p><p><img src="/2019/03/02/第三章/1551596138.jpg" alt=""></p><center>图 3-18. 设置相机的Clear Flags为Depth only<h3 id="添加一个组件"><a href="#添加一个组件" class="headerlink" title="添加一个组件"></a>添加一个组件</h3><p>现在我们打算添加一个组件到我们的相机。在这个例子中，我们打算添加一个Unity AR Video脚本。添加这个脚本，选中主摄像机（Main Camera），在Inspector中选择添加组件（Add Component）。</p><p>在Inspector中，您将看到一列你能够添加的组件（图 3-18）。这可能花费一会功夫去找，所以我建议使用在添加组件菜单中的搜索栏来添加我们寻找的脚本。在图3-19中，在搜索栏中，我搜索video。</p><p><img src="/2019/03/02/第三章/1551596538.jpg" alt=""></p><center>图 3-19. 搜索Unity AR Video脚本组件</center><p>一旦您发现了到Unity AR Video脚本，选中它（单击鼠标），现在您应当看到这个组件被添加到Main Camera上了。</p><p><img src="/2019/03/02/第三章/1551596695.jpg" alt=""></p><center>图 3-20. Unity AR Video脚本组件添加到主摄像机上</center><p>在Unity AR Video脚本中，有一个属性叫做Clear Material。我们打算添加一个材质。在Unity AR Video脚本的Clear Materials属性，在属性框的右侧，有一个小齿轮（图 3-19）；如果您选中这个齿轮，您将会看到一个在这个项目文件夹下所有可用材质的列表（图 3-21）。另外，你可以手动搜索，或者使用搜索栏。搜索YUV材质。我将详细介绍这种材料的作用以及我们在后面的章节中使用它的原因。</p><p><img src="/2019/03/02/第三章/1551596988.jpg" alt=""></p><center>图 3-21. 为Clear Material选择YUV材质</center><h3 id="跟踪手机运动"><a href="#跟踪手机运动" class="headerlink" title="跟踪手机运动"></a>跟踪手机运动</h3><p>为了使AR项目看起来真实，我们需要跟踪手机在现实世界中的移动，并在手机屏幕上投影虚拟对象的准确表示。 Unity的优秀人才（再次）让我们的生活更轻松，在Unity中，ARKit有一个名为Unity AR Camera Manager的脚本。按照我们添加Unity AR Video脚本的步骤，我们将添加Unity AR Camera Manager。首先选择Main Camera，然后在Inspector中选择Add Component（图 3-22）;现在搜索AR Camera Manager（图3-23），并将其添加到Main Camera。</p><p><img src="/2019/03/02/第三章/1551654194.jpg" alt=""></p><center>图 3-22. 添加组件</center><p><img src="/2019/03/02/第三章/1551654227.jpg" alt=""></p><center>搜索Unity AR Camera Manager</center><p>最好将Main Camera添加到Unity AR Camera Manager的跟踪Tracked Camera属性中;这将确保AR Camera Manager使用正确的相机。但是，如果您不选择此选项，Unity AR Camera Manager将为您选择。要将Main Camera添加到Unity AR Camera Manager的Camera属性，请从Hierarchy中选择Main Camera，然后将其拖动到Unity AR Camera Manager的Camera属性（图 3-24）。</p><p><img src="/2019/03/02/第三章/1551654485.jpg" alt=""></p><center>图 3-24. 设置Main Camera作为Tracked Camera<h3 id="构建并运行"><a href="#构建并运行" class="headerlink" title="构建并运行"></a>构建并运行</h3><p>现在我们已准备好构建和运行我们的应用程序。确保已将iOS设备连接到Mac，然后从Unity File菜单中选择Build＆Run（图3-25）。如果您尚未下载最新版本的Xcode，则需要立即执行此操作（这需要一段时间）。</p><p><img src="/2019/03/02/第三章/1551654576.jpg" alt=""></p><center>图 3-25. 选择Build & Run</center><p><img src="/2019/03/02/第三章/1551654731.jpg" alt=""></p><center>图 3-26. 构建设置<p>在Build设置菜单中，首先选择要在其上构建的平台，在我们的示例中将是iOS。此外，选中“开发构建”复选框。最后，仅选择要构建的场景非常重要。如果未列出当前场景，请单击“添加打开场景”按钮（图3-26）并取消选中任何其他场景。在Build Setting屏幕中，选择Player Settings图标。这将打开玩家设置的Inspector，我们将在其中输入公司名称和产品名称（图3-27）。</p><p><img src="/2019/03/02/第三章/1551654943.jpg" alt=""></p><center>图 3-27. Player Settings的检视器视图</center><p>向下滚动菜单以找到Bundle Identifier（图3-26）。请务必注意，一旦您在Xcode中向个人团队注册了捆绑包标识符，将来就无法将相同的捆绑包标识符注册到其他Apple Developer Program团队。这意味着当您使用免费的Apple ID和个人团队测试游戏时，您应该选择仅用于测试的包标识符 - 您将无法使用相同的包标识符来释放游戏。执行此操作的最佳解决方案是在测试包标识符的末尾添加“Test” - 例如，com.yourCompanyName.yourAppNameTest。另请注意，捆绑标识符以所谓的反向DNS样式编写。接受的字符是字母数字字符，句点和连字符。在我的例子中（图3-28），我使用过com。 RottenEggProductions.HelloWorldARTest作为包标识符（您将需要自己的名字）。如果您有签名团队ID，您可能也想要包含该ID。但出于测试目的，这不是必需的。</p><p><img src="/2019/03/02/第三章/1551655117.jpg" alt=""></p><center>图 3-28. 在PlayerSetting中设置Bundle Identifier</center><p>现在选择Build and Run图标。 Unity将提示您保存项目。学习入门编程课程的传统是命名我们的第一个应用程序Hello World（不要问我原因）。所以，在这个传统中，我将命名我的第一个AR App，Hello WorldAR。请注意，在图3-29中，我将其保存在与Unity Project相同的文件夹中。有些人会说这不是好习惯，但现在已经足够好了</p><p><img src="/2019/03/02/第三章/1551655198.jpg" alt=""></p><center>图 3-29. 保存Hello WorldAR Menu</center><p>保存文件后，Unity将开始编译应用程序（图3-28）并最终打开Xcode（图3-29）。当Xcode打开时（图3-31），确保选择了正确的设备（iPhone或iPad），选择播放按钮以在设备上启动游戏（图3-30）。如果Unity报告任何错误，请务必检查错误是什么并在重试之前解决这些问题。</p><p><img src="/2019/03/02/第三章/1551655287.jpg" alt=""></p><center>图 3-30. Unity编译我们的应用程序</center><p><img src="/2019/03/02/第三章/1551655344.jpg" alt=""></p><center>图 3-31. Xcode</center><p>系统将提示您允许Unity ARKit访问您的相机，如果一切正常，您应该在现实世界中看到您的惊人立方体。在我的例子中，你可以在我的Mount Aoraki照片前看到我惊人的立方体（图3-32）。</p><p><img src="/2019/03/02/第三章/1551655438.jpg" alt=""></p><center>图 3-32. 我的Hello WorldAR应用程序</center><h3 id="保存场景"><a href="#保存场景" class="headerlink" title="保存场景"></a>保存场景</h3><p>现在是拯救我们现场的好时机。从文件菜单中，选择“文件”➤“将场景另存为”并命名此场景（图3-33）。我已选择Hello WorldAR作为此场景的名称（图3-34）。</p><p><img src="/2019/03/02/第三章/1551655680.jpg" alt=""></p><center>图 3-33. 场景另存为（Save Scene as）菜单<p><img src="/2019/03/02/第三章/1551655775.jpg" alt=""></p><center>图 3-34. 保存场景并选择它的位置</center><h3 id="了解场景"><a href="#了解场景" class="headerlink" title="了解场景"></a>了解场景</h3><p>现在可能是讨论Unity场景和项目之间差异的好时机。 Unity项目包含可能用于游戏或应用程序的所有场景和必要代码。场景是项目的元素（或组件）。将该项目视为整部电影，将场景视为该电影的一部分。在游戏中，这些场景可以是菜单，关卡，积分等。</p><h3 id="引入视觉惯性测距法（Visual-Inertial-Odometry）"><a href="#引入视觉惯性测距法（Visual-Inertial-Odometry）" class="headerlink" title="引入视觉惯性测距法（Visual Inertial Odometry）"></a>引入视觉惯性测距法（Visual Inertial Odometry）</h3><p>现在我们将看一些用于创建AR游戏的重要工具。在我们的Hello WorldAR项目中，我们创建了一个位于iPhone相机前面的立方体，并在我们移动相机位置时停留在那里。相机如何知道它的位置？您可能已经知道，iPhone有一些非常酷的方式来了解它的位置。我最常用的是加速度计。加速度计允许iPhone知道它在3轴（X，Y，Z）中的位置。这对于在纵向和横向模式之间切换非常有用。我使用的另一个工具是指南针（或磁力计），正如您可能已经知道的那样，这对于导航非常有用。最后一个工具是陀螺仪。陀螺仪跟踪iPhone的旋转或扭曲。虽然这些是很好的导航工具，但它们没有跟踪AR中手机移动所需的精确度。为了跟踪AR所需的iPhone的移动，Apple最近在手机的相机中加入了一些技术。通过组合视觉信息（来自摄像机）和惯性信息（来自加速度计和陀螺仪），可以精确测量iPhone的位置。</p><h3 id="特征点（Feature-Points）"><a href="#特征点（Feature-Points）" class="headerlink" title="特征点（Feature Points）"></a>特征点（Feature Points）</h3><p>那么相机如何跟踪手机的位置？好问题！ iPhone中的相机（目前是iPhone 8或更高版本）非常智能，可以识别现实世界中的关键点（或特征点），并且当移动相机时，跟踪这些点的位置。这个过程需要一些非常令人印象深刻的数学，但最近的iPhone有足够的处理能力来做到这一点。</p><h3 id="点云（Point-Clouds）"><a href="#点云（Point-Clouds）" class="headerlink" title="点云（Point Clouds）"></a>点云（Point Clouds）</h3><p>Unity ARKit包括一个预制件，用于帮助手机识别物理世界中的特征点。我们将要使用的第一个是PointCloud Prefab。在Unity中打开Hello WorldAR应用程序后，我们将创建一个空的GameObject。从文件菜单中，选择GameObject➤CreateEmpty（图3-35）。</p><p><img src="/2019/03/02/第三章/1551656212.jpg" alt=""></p><center>图 3-35. 创建一个Empty GameObject</center><p>在Inspector中选中Empty GameObject后，将其重命名为Point Cloud。现在添加一个组件。在搜索栏中，搜索Unity Point Cloud示例并将其添加到Point Cloud GameObject（图3-36）。</p><p><img src="/2019/03/02/第三章/1551656302.jpg" alt=""></p><center>图 3-36. 搜索Point Cloud Example</center><p>添加Unity Point Cloud示例脚本后，现在将最大点数设置为120（图3-37）。您可以根据需要设置多个点云。</p><p><img src="/2019/03/02/第三章/1551656378.jpg" alt=""></p><center>图 3-37. 设置要显示的最大点数</center><p>现在我们需要添加一个Point Cloud Particle预制件到Point Cloud。选择Point Cloud Prefab选项框右侧的小齿轮，然后搜索预制件（图 3-38）。选择并拖拽PointCloudPrefab到Point Cloud Particle Example脚本里的Point Cloud Particle预制件选项框（图 3-39）。</p><p><img src="/2019/03/02/第三章/1551656959.jpg" alt=""></p><center>图 3-38. 搜索PointCloud预制件</center><p><img src="/2019/03/02/第三章/1551657029.jpg" alt=""></p><center>图 3-39. PointCloudPrefab设置为Point Cloud Prefab</center><h3 id="测试-1"><a href="#测试-1" class="headerlink" title="测试"></a>测试</h3><p>现在我们将测试我们的Point Cloud。当我们测试我们的Hello WorldAR应用程序时，我们经历了构建应用程序的长期（可能是乏味的）任务，在Xcode中启动它。然后最终能够在我们的iOS设备上看到我们的应用程序。 Unity的优秀人才对此进行了思考，并为我们创造了一种减少测试开发时间的方法。在Unity ARKit中，有一个Scene可以让我们在Unity的Game选项卡中预览构建。如果你想在每次想要预览开发时都经历使用Xcode的过程，那很好。但是，我会向您展示一种您可能更有价值的方式。</p><h3 id="Unity-ARKitRemote"><a href="#Unity-ARKitRemote" class="headerlink" title="Unity ARKitRemote"></a>Unity ARKitRemote</h3><p>由于Unity Remote Connection目前不支持AR，因此我们需要在iOS设备上构建和部署App。 Unity的优秀人才包括在Unity ARKit中，这是一个名为ARKit Remote的场景。您可以使用搜索栏在Project文件夹中找到它。在图3-40中，我使用了搜索字符串remote。</p><p><img src="/2019/03/02/第三章/1551738319.jpg" alt=""></p><center>图 3-40. 搜索UnityARKitRemote场景</center><p>双击场景打开它。如果您没有保存当前场景，Unity打开另一场景前系统会提示您先保存它。您将会看到这是一个非常简单的场景，它包含了一个主摄像机（Main Camera）和一个直射光（Directional Light）（图 3-41）。</p><p><img src="/2019/03/02/第三章/1551739189.jpg" alt=""></p><center>图 3-41. UnityARKitRemote</center><p>如果在层次结构(Hierarchy)中选择主摄像机(Main Camera)，您将看到主摄像机(Main Camera)添加了多个脚本（图 3-42）。这些脚本将使手机摄像头能够跟踪其位置，并使我们能够在Unity编辑器中查看摄像机视图。</p></center></center></center></center></center></center>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;既然您已经安装了Unity和Unity ARKit插件，现在是时候学习更多有关此工具的知识并开始我们的第一次AR体验。请注意，我称这是一种体验，而不是游戏，尽管它可能以某种方式用作游戏;从我的观点来看，游戏需要一些关键元素，我将在第4章详细介绍。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Unity" scheme="https://zhaolilong.com/tags/Unity/"/>
    
      <category term="ARKit" scheme="https://zhaolilong.com/tags/ARKit/"/>
    
  </entry>
  
  <entry>
    <title>第二章</title>
    <link href="https://zhaolilong.com/2019/02/27/%E7%AC%AC%E4%BA%8C%E7%AB%A0/"/>
    <id>https://zhaolilong.com/2019/02/27/第二章/</id>
    <published>2019-02-27T00:05:07.000Z</published>
    <updated>2020-03-13T01:06:01.924Z</updated>
    
    <content type="html"><![CDATA[<p>如果顺利的话，您可能已经对增强现实（或AR）有了一个很好的了解。由于对术语虚拟现实（或VR），增强现实和混合现实之间的差异存在一些混淆，我认为可能值得在本书中澄清AR的含义。</p><p>虚拟现实（VR）是一个计算机生成的环境，通过感官和感知模拟体验。不同于传统的计算机系统，VR系统将用户置于体验之中。代替在他们屏幕前观看，用户沉浸其中并且能够与3D世界互动。</p><a id="more"></a><h1 id="第二章"><a href="#第二章" class="headerlink" title="第二章"></a>第二章</h1><h2 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h2><p>如果顺利的话，您可能已经对增强现实（或AR）有了一个很好的了解。由于对术语虚拟现实（或VR），增强现实和混合现实之间的差异存在一些混淆，我认为可能值得在本书中澄清AR的含义。</p><p>虚拟现实（VR）是一个计算机生成的环境，通过感官和感知模拟体验。不同于传统的计算机系统，VR系统将用户置于体验之中。代替在他们屏幕前观看，用户沉浸其中并且能够与3D世界互动。</p><p>现在，让我们看看增强现实（AR）。普遍的共识是AR被定义为真实世界环境的一个直接实时视图，它的元素被计算机生成的信息“增强”。VR和AR之间根本的区别在于AR包括真实环境的<strong>实时视图</strong>。VR系统通常不包括真实环境的实时视图。 VR耳机是全封闭的，显示完全计算机产生。</p><p>混合现实（MR，虽然这个缩写词很少使用），是一个术语这主要是微软用来区分他们的HoloLens。我觉得混合现实是另一种形式的AR。但是，还有一些对此进行辩论。当我问微软的好朋友时，他们觉得混合现实介于AR和VR之间，完全集成了数字对象进入您的世界，使它看起来好像它们真的在那里。</p><p>您可能会惊讶于VR和AR这两个词一直存在很多年。虽然关于首次使用术语VR的问题存在相当大的争议（主要是由于对术语的商定定义），有一些普遍认为该术语最初是在20世纪50年代左右使用的，作者提到完全沉浸式系统或环境。自始至终美国军方和美国宇航局，飞机制造商使用AR系统用于培训，研究和开发。然而，直到2016年我们看到了第一个商用消费类AR系统Oculus Rift。Occulus Rift由Oculus VR制造（最终被Facebook以20亿美元的价格买断）。</p><p>多年来也提到了AR。困难同意当时对AR的首次提及也是由于对什么是AR的商定定义。 1989年，乔治道格拉斯写了一篇文章计算机驱动的天文望远镜引导和控制系统具有叠加的星场和天体坐标图形显示这似乎是第一个AR系统。</p><p>最近，有几个有趣的发展AR。虽然有一些专有系统，但第一个最值得注意的开发是为Android和iOS推出PokémonGo手机。使用地理定位功能和集成摄像头在手机上，用户能够在现实世界中看到屏幕上出现的虚拟对象。</p><p>在本书中，我将专注于开发一款iOS的AR游戏。我出于多种原因选择了iOS。首先，有很多设备使用iOS。更重要的是，Apple正在投入AR硬件和软件的开发。在iOS11中，苹果包含了ARKit。ARKit使得它变得简单对于我们创建AR游戏以及在用户的环境中放入虚拟物体的模拟。通过结合来自设备的运动传感器的信息及其相机的数据，ARKit可以提供帮助iPhone或iPad分析周围环境。苹果也加强了iPhone 8和iPhone X中相机的功能。在iPhone 8和iPhone X相机已经被设计用于低光拍摄和60-fps的视频。iPhone X上的双光学防抖功能和改进的iPhone 8上的光学防抖功能也提供了提高视觉清晰度。这些硬件和软件功能有助于实现游戏在用户环境中更自然地出现。苹果也大力投入改善未来iPhone和iPad的AR功能。</p><p>Unity最近在Unity商店中推出了Unity ARKit。 这使我们更容易为iOS制作AR游戏。因此，在本书中，我将使用Unity ARKit。所以现在是一个安装最新版Unity ARKit的好时机。Unity ARKit的最低要求如下：</p><ul><li><p>支持ARKit且具有最新功能的iOS设备 iOS 11.3或更高版本。</p></li><li><p>安装macOS 10.13（High Sierra）或更高版本的Mac。</p></li><li><p>Unity版2017.1或更高版本。</p></li><li><p>来自于Apple Developer网站的最新版本的XCode 9.3（或更高版本）（需要macOS 10.13）。</p></li></ul><p>现在您已经安装了Unity，现在是时候熟悉Unity ARKit的各种元素了，我们将用它来制作和测试我们的游戏。在我们探索Unity ARKit的不同组件时， 我将讨论开发AR游戏的一些技术原理。由于这是一本介绍性的书，我不会深入研究技术细节，并试图保持这个相对较高的水平。我的编辑让我推荐有关额外AR的书籍，所以我可能会保留关于AR的第二本书的更高级或技术内容。</p><p>现在让我们启动Unity并创建一个新项目。</p><p>当您启动Unity时，您将看到Projects屏幕（图 2-1）。</p><p><img src="/2019/02/27/第二章/1551277997.jpg" alt=""></p><center>图 2-1. Unity Projects屏幕</center><p>选择屏幕右上角的“新建”图标。这将打开 Unity New Project屏幕（图2-2）。在对话框中，键入 在项目名称中，设置Unity文件的位置，输入您组织的名称，并将模板设置为3D。</p><p><img src="/2019/02/27/第二章/1551278189.jpg" alt=""></p><center>图 2-2. Unity New Project屏幕</center><p>在Unity New Project屏幕的对话框中，输入项目名称，选择要保存此文件的位置，然后选择“创建” 项目图标（图2-2）。我选择了AR projects作为文件名并选择了硬盘驱动器上的Users文件夹。</p><p>现在Unity将打开一个空的Unity项目（图 2-3）。</p><p><img src="/2019/02/27/第二章/1551278449.jpg" alt=""></p><center>图 2-3 一个空的Unity项目屏幕</center><h3 id="安装Unity-ARKit"><a href="#安装Unity-ARKit" class="headerlink" title="安装Unity ARKit"></a>安装Unity ARKit</h3><p>现在是安装Unity ARKit的好时机。安装来自Unity Store的Unity ARKit，您将需要访问Unity资产商店。 Unity资产商店可以通过多种方式访问​​。在Unity屏幕的主窗口有一个Assets Store的选项卡，这将显示资产商店窗口。该窗口也可以通过使用Command键和数字9键（⌘+9）。从资产商店下载资产，您需要注册，用Unity去创建一个Unity ID。当您已经创建一个Unity ID，在Unity资产商店的窗口中，有一个搜索栏。在搜索栏中输入ARKit，这将显示符合该搜索条件的文件列表（图 2-4）。在Unity中默认窗口设置将显示Unity商店窗口最小化；使用全屏模式查看资产商店，屏幕的右上角有一个下啦菜单。选中这个并点击鼠标左键。这将显示屏幕选项，Reload（重新加载），Maximize（最大化），Close（关闭）选项卡以及Add（添加）选项卡。选中最大化按钮（点击鼠标左键）。在屏幕的顶部，有很多过滤选项。过滤选项的下面，有符合您搜索条件的资产。双击ARKit，这将加载这个资产的屏幕。选中import（导入）按钮。这个资产将被导入到Unity。（图 2-5）。</p><p><img src="/2019/02/27/第二章/1551309799.jpg" alt=""></p><center>图 2-4. Unity资产商店</center><p><img src="/2019/02/27/第二章/1551309853.jpg" alt=""></p><center>图 2-5. 场景文件夹中带有ARKit的Unity项目文件夹</center><h3 id="编辑器布局"><a href="#编辑器布局" class="headerlink" title="编辑器布局"></a>编辑器布局</h3><p>现在是仔细研究Unity布局的好时机。主窗口被分割成面板。默认显示视图（出厂设置）通过单击视图的选项卡选择区域。视图可以被添加，移动，移除以及缩放，编辑器支持切换布局，所以布局本质上是一种特定的视图排列。例如，主窗口的默认布局（图 2-6）有一个区域包含场景视图（图 2-7）和游戏视图（图 2-8）。</p><p><img src="/2019/02/27/第二章/1551312350.jpg" alt=""></p><center>图 2-6. Unity编辑器默认布局</center><p><img src="/2019/02/27/第二章/1551312381.jpg" alt=""></p><center>图 2-7. 多选项卡区域选中场景视图</center><p><img src="/2019/02/27/第二章/1551312467.jpg" alt=""></p><center>图 2-8. 多选项卡区域选中游戏视图</center><h3 id="预设布局"><a href="#预设布局" class="headerlink" title="预设布局"></a>预设布局</h3><p>默认布局只是几种预设布局中的一种。替代布局可以从主窗口右上角的菜单中选择（图2-9）。 Unity还使我们能够创建自己的布局。在图2-9中，你会看到我的菜单有一个手机游戏配置。这是我的自定义布局，我在创建手机游戏时创建的布局。检验菜单上的各种布局。图2-6至2-7显示了由此产生的布局。</p><p><img src="/2019/02/27/第二章/1551312763.jpg" alt=""></p><center>图 2-9. 布局菜单</center><p>我稍后会更详细地描述各种独特的类型，但是现在，请注意，2-by-3（2×3）布局（图2-10）是布局的示例，场景视图和游戏视图位于不同的区域而不是共用同一个。 4-split（4分割）布局（图2-11）有四个场景视图实例，表明布局不限于每个布局 视图类型。 Tall（高版面）布局（图2-12）提供了一个水平场景视图。 Wide（宽版面）布局（图2-13）提供了一个横向场景视图。</p><p><img src="/2019/02/27/第二章/1551313521.jpg" alt=""></p><center>图 2-10. 2×3布局</center><p><img src="/2019/02/27/第二章/1551313573.jpg" alt=""></p><center>图 2-11. 4分割布局</center><p><img src="/2019/02/27/第二章/1551313606.jpg" alt=""></p><center>图 2-12. 高版面布局</center><p><img src="/2019/02/27/第二章/1551313638.jpg" alt=""></p><center>图 2-13. 宽版面布局</center><h3 id="自定义布局"><a href="#自定义布局" class="headerlink" title="自定义布局"></a>自定义布局</h3><p>预设布局提供了各种工作空间，但幸运的是，您并不仅限于使用它们。 Unity提供了根据需要完全重新排列编辑器窗口的灵活性。</p><h3 id="缩放区域"><a href="#缩放区域" class="headerlink" title="缩放区域"></a>缩放区域</h3><p>对于初学者，您可能会在尝试各种预设布局时注意到有些区域太窄，例如，在宽版面布局（图2-13）中的左侧面板。幸运的是，您可以单击某个区域的边框并拖动它来调整区域大小。</p><h3 id="移动视图"><a href="#移动视图" class="headerlink" title="移动视图"></a>移动视图</h3><p>更酷，你可以移动视图。将视图的选项卡拖动到另一个选项卡区域将移动视图到那。并将选项卡拖动到一个 “对接”区域将创造一个新的区域。比如，以默认局部启动，拖拽Inspector（检视）选项卡到Hierarchy（层级）选项卡的右侧。现在检视器视图与Hierarchy视图共用相同的区域。结果应当看起来如图2-14。</p><p><img src="/2019/02/27/第二章/1551314467.jpg" alt=""></p><center>图 2-14. 自定义视图移动的工作区</center><h3 id="分离视图"><a href="#分离视图" class="headerlink" title="分离视图"></a>分离视图</h3><p>您甚至可以拖拽一个视图到编辑器窗口外面以便它驻留在自己的“浮动”窗口中，可以像任何其他区域一样对待。将“场景”选项卡拖到编辑器外部，使其位于浮动窗口中， 然后将“游戏”选项卡拖动到其选项卡区域。结果应当看起来像图2-15。同样地，将选项卡拖动到浮动的停靠区域，将向窗口添加到另一个区域。</p><blockquote><p>提示 喜欢将游戏视图分离成浮动窗口，因为我在编辑工作之前，我通常不需要看到它直到我单击了“运行”，这样我就可以最大化游戏视图以填充整个屏幕。我也喜欢使用多台显示器。这种方式，我可以最大化我的屏幕空间。</p></blockquote><p><img src="/2019/02/27/第二章/1551314973.jpg" alt=""></p><center>图 2-15. 新视图的列表</center><p>浮动窗口经常被其他窗口掩盖，所以菜单栏上的Windows菜单包含用于制作每个视图的菜单项可见性。请注意，每个都有一个键盘快捷键，还有一个布局子菜单与编辑器内的布局菜单相同。</p><h3 id="添加和移除视图"><a href="#添加和移除视图" class="headerlink" title="添加和移除视图"></a>添加和移除视图</h3><p>您还可以使用菜单中的菜单添加和删除每个区域中的视图 该区域的右上角（图2-15）。“关闭标签”项将删除目前显示的视图。“添加标签”项提供了新视图的列表你可以选择。</p><p>您可能希望为不同的目标平台设置不同的布局，或者开发与游戏测试的不同布局，甚至对于不同的游戏采用不同的布局。例如，我有一个专门为我的自定义布局 以合适的肖像方式预先保存游戏视图的手机游戏 比。每次手动重新配置编辑器都是一件麻烦事 你启动Unity。幸运的是，您可以通过选择来命名和保存布局 布局菜单中的“保存布局”选项，将提示您输入 新布局名称（图2-16）。</p><p><img src="/2019/02/27/第二章/1551532134.jpg" alt=""></p><center> 图 2-16. 提示新布局</center><p>保存后，新布局将列在布局菜单中 如果选择“删除布局”，如果您选择删除布局将从列表中删除布局 （图2-17）。</p><p><img src="/2019/02/27/第二章/1551532322.jpg" alt=""></p><center>图 2-17. 布局删除菜单</center><p>如果您弄乱或删除了原始布局，可以在区域菜单选择中恢复出厂设置选项（图2-18）。这也将删除自定义布局。</p><p><img src="/2019/02/27/第二章/1551532458.jpg" alt=""></p><center>图 2-18. 恢复初始布局设置</center><p>如果更改布局但尚未保存更改，则可以随时丢弃它们，只需在布局菜单中重新选择该布局即可。</p><h3 id="检视器视图"><a href="#检视器视图" class="headerlink" title="检视器视图"></a>检视器视图</h3><p>首先要详细描述的最佳视图是Inspector View，用于显示有关在其他视图中选择的对象的信息。它真的不仅仅是检查员，因为它通常可以用来修改选定的项目。</p><p>检视器视图也被用来显示和调整各种设定，可以在编辑菜单中显示。（图 2-19）。</p><p><img src="/2019/02/27/第二章/1551532784.jpg" alt=""></p><center>图 2-19. 在编辑菜单中显示</center><p>检视器视图显示了编辑器的设定。如果项目目前有metafile，那么版本控制模式被设置到Meta文件中（如果您正在使用Asset Server，这个选项被设置为Asset Server）。为了隐藏metafile，设置版本控制模式为隐藏。（图 2-20）。</p><p><img src="/2019/02/27/第二章/1551532951.jpg" alt=""></p><center>图 2-20. 检视器视图中的编辑器设定</center><p>将版本控制模式设置为已禁用，Unity将删除metafile。资产跟踪现在在项目的Library文件夹里面的二进制文件中处理。</p><blockquote><p><strong>注意</strong> 使用metafile进行版本控制的Unity用户支持还可以选择将资产序列化模式设置为强制文本。在该模式下，Unity场景文件以纯文本格式保存YAML（YAML Ain’t Markup Language）格式。</p></blockquote><p>通常，检视器视图会显示最近选择的对象的属性（当您调出编辑器设置时，您选择它）。但有时您不希望检视器视图发生变化，当你选择其他对象时。在这种情况下，您可以通过选择视图右上方菜单中的“锁定”选项来固定检视器视图到一个对象（图2-21）。</p><p><img src="/2019/02/27/第二章/1551533612.jpg" alt=""></p><center>图 2-21. 锁定检视器视图</center><h3 id="项目视图"><a href="#项目视图" class="headerlink" title="项目视图"></a>项目视图</h3><p>虽然检视器视图可以被认为编辑器中最低级别的视图，因为它显示了仅仅单一对象的属性，项目视图可以被认为是最高级别的视图（图 2-22）。项目视图显示了所有游戏可用的资产，范围从单独的模型，纹理，以及脚本到场景文件的合并资产。所有项目资产都是驻留在项目的Assets文件夹中的文件 （因此您可能希望将项目视图视为资产视图）。</p><p><img src="/2019/02/27/第二章/1551533939.jpg" alt=""></p><center>图 2-22. 项目视图的顶层</center><h3 id="在一列和两列之间切换"><a href="#在一列和两列之间切换" class="headerlink" title="在一列和两列之间切换"></a>在一列和两列之间切换</h3><p>在几个较旧版本的Unity中，项目视图只有一列显示。该选项仍可在项目视图的菜单中找到（单击视图右上角小的三条线图标），现在您可以在一列到两列之间切换。</p><h3 id="缩放图标"><a href="#缩放图标" class="headerlink" title="缩放图标"></a>缩放图标</h3><p>右侧面板中底部的滑块缩放的视图—更大的比例对于纹理来说是很好的，对于没有有趣图标的脚本来说更小的比例较好。这是按资产类型划分资产的一个很好的理由（即将所有纹理放在Textures文件夹中，脚本放在Script文件夹中，等等）。有可能，单级滑块设置不适合资产类型的混合。</p><h3 id="检查资产"><a href="#检查资产" class="headerlink" title="检查资产"></a>检查资产</h3><p>选择右侧的资产将在“检查器视图”中显示该资产的属性。例如，如果选择动画样本，则“检查器视图”将显示有关动画的信息，其中一些可以更改，例如持续时间，甚至可以让您在编辑器中运行动画（图2-23）。我们将在后面的章节中介绍如何更改资产属性，但现在可以在项目视图中选择各种类型的资源，并查看Inspector视图中显示的内容。</p><p><img src="/2019/02/27/第二章/1551534499.jpg" alt=""></p><center>图 2-23. 在项目视图中检视一个选中资产</center><h3 id="资产搜索"><a href="#资产搜索" class="headerlink" title="资产搜索"></a>资产搜索</h3><p>在一个较大复杂的项目中，很难手动搜索一个特定的资产。幸运地，就想在Finder中一样，有一个搜索框可以被用来过滤显示在项目视图右侧面板的结果。如图2-24所示，项目视图显示搜索名称中带有“add”的资产的结果。</p><p><img src="/2019/02/27/第二章/1551534810.jpg" alt=""></p><center>图 2-24. 搜索名称中带有“add”的资产</center><p>右侧面板显示资产（即我们所有资产）下的所有内容的搜索结果。通过选择左侧面板中的一个子文件夹，可以进一步缩小搜索范围。例如，如果您知道自己在寻找场景，并且已根据资产类型将资源安排到子文件夹中，则可以选择要搜索的文件夹。在图2-25中，我在examples文件夹中搜索了文件名带有“add”的任何资产。</p><p><img src="/2019/02/27/第二章/1551535022.jpg" alt=""></p><center>图 2-25. 在指定文件夹中搜索资产</center><p>请注意搜索下方;有一个选项卡，其中包含所选文件夹的名称。您仍然可以单击左侧的“资源”选项卡，查看本地和Unity资源商店中所有资产的搜索结果，我们将在本书中对其进行大量使用。</p><p>您还可以使用搜索框右侧的菜单按资产类型过滤搜索。您可以选择场景作为感兴趣的资产类型，而不仅仅是在Examples文件夹中搜索（图2-26）。请注意这是如何添加到搜索框中生效的。 t：前缀表示应按以下资产类型过滤搜索。您可以在不使用菜单的情况下输入。</p><p><img src="/2019/02/27/第二章/1551535263.jpg" alt=""></p><center>图 2-26. 通过资产类型过滤搜索</center><p>资产类型菜单右侧的按钮用于按标签过滤（您可以在检查器视图中为每个资产分配标签），这对于搜索资产商店也非常方便。最右边的按钮（星号）会将当前搜索保存在左侧面板的“收藏夹”部分中。</p><h3 id="经营资产"><a href="#经营资产" class="headerlink" title="经营资产"></a>经营资产</h3><p>项目视图中的资产可以像Finder中的相应文件一样进行操作。</p><p>双击资产将尝试打开合适的程序以查看或编辑资产。这相当于右键单击资产并选择“打开”。双击场景文件将在此Unity Editor窗口中打开场景，就像您在“文件”菜单中选择了“打开场景”一样。</p><p>您还可以重命名，复制和删除文件，并将文件拖入和拖出文件夹，就像您一样可以在Finder中。当您右键单击资产时，Unity Edit菜单和弹出菜单中的某些操作可用。在接下来的几章中，您将对此进行一些练习。</p><p>同样，在下一章中，您将处理向项目添加资产的工作。这涉及导入文件或导入Unity包，使用菜单栏上的Assets菜单或使用Finder将文件拖到项目的Assets文件夹中。</p><h3 id="Hierarchy视图"><a href="#Hierarchy视图" class="headerlink" title="Hierarchy视图"></a>Hierarchy视图</h3><p>每个游戏引擎都有一个顶级对象，称为GameObject或实体，用于表示具有位置，潜在行为和名称以识别它的任何内容。 UnityGameObject是GameObject类的实例。</p><blockquote><p><strong>注意</strong> 一般来说，当我们引用一种Unity对象时，我们将使用它的类名来精确，并明确如何在脚本中引用该对象。</p></blockquote><p>层次结构视图是当前场景的另一种表示形式。虽然场景视图是您可以像使用内容创建工具一样工作的场景的3D表示，而游戏视图显示了玩游戏时的场景，但是层次结构视图列出了场景中的所有GameObject在易于导航的树形结构中。</p><h3 id="检查GameObject"><a href="#检查GameObject" class="headerlink" title="检查GameObject"></a>检查GameObject</h3><p>单击层次结构视图中的GameObject时，它将成为当前的编辑器选择，其组件将显示在编辑器中。每个GameObject都有一个变换组件，它指定相对于层次结构中父级的位置，旋转和缩放（如果您熟悉3D图形的数学，则变换本质上是对象的变换矩阵）。一些组件为GameObject提供功能（例如，光照是附有光照组件的GameObject）。其他组件引用网格，纹理和脚本等资源。图2-27显示了主摄像机GameObject的组件（在层次结构视图中，GameObject的整个运行器树以蓝色显示，因为它链接到预制件，一种特殊类型的资产，用于克隆一个或一组GameObject）。</p><p><img src="/2019/02/27/第二章/1551535821.jpg" alt=""></p><center>Hierarchy视图和检视视图</center><h3 id="父与子GameObject"><a href="#父与子GameObject" class="headerlink" title="父与子GameObject"></a>父与子GameObject</h3><p>您会发现许多GameObject都按层次排列，因此是该视图的名称。育儿对于概念上组合在一起的GameObject有意义。例如，当您想要移动汽车时，您希望车轮随车一起自动移动。因此，车轮应指定为汽车的儿童，偏离汽车的中心。当车轮转动时，它们相对于汽车的运动转动。育儿还允许我们一次激活或停用整组GameObject。</p><h3 id="场景视图"><a href="#场景视图" class="headerlink" title="场景视图"></a>场景视图</h3><p>虽然Hierarchy视图允许我们在当前场景中创建，检查和修改GameObjects，但它并没有为我们提供一种可视化场景的方法。这就是场景视图的用武之地。场景视图类似于3D建模应用程序的界面。它允许您从任何3D有利位置检查和修改场景，并让您了解最终产品的外观。</p><h3 id="场景导航"><a href="#场景导航" class="headerlink" title="场景导航"></a>场景导航</h3><p>如果您不熟悉在3D空间中工作，那么在2D工作中这是一个简单的扩展。而不是仅仅在具有x和y轴以及（x，y）坐标的空间中工作，在3D空间中，您具有额外的z轴和（x，y，z）坐标。 x轴和z轴定义地平面，y-指向上方（您可以将y视为高度）。</p><blockquote><p><strong>注意</strong> 一些3D应用程序和游戏引擎使用z轴表示高度，使用x轴和y轴作为地平面，因此在导入资源时，您可能需要调整（旋转）它们。</p></blockquote><p>3D空间中的视点通常称为相机。单击右上角多色场景Gizmo的x，y和z箭头可以快速翻转相机，使其面向相应的轴。例如，单击y箭头可以看到场景的俯视图（图2-28），场景Gizmo下的文本显示“Top”。</p><p><img src="/2019/02/27/第二章/1551536198.jpg" alt=""></p><center>图 2-28. 场景视图的顶级视图</center><p>这里的摄像机与游戏中使用的场景中的CameraGameObject不同，因此当您在场景视图中环顾四周时，您不必担心会弄乱游戏。</p><p>为了演示如何使用导航工具，我从项目文件夹中选择了PlayerGameObject并将其拖到层次结构视图中。</p><p>单击“场景Gizmo”中心的框可在透视图之间切换摄像机投影，从而使对象在远处后退时变小;和正交，无论是近距离还是远距离，它们都以原始尺寸呈现。透视更加真实，而且你通常在游戏中使用它，但正交设计在设计时通常更方便（因此它在计算机辅助设计应用中无处不在）。场景Gizmo下文本前面的小图形表示当前投影。</p><p>您可以使用鼠标滚轮或在“编辑器”窗口的右上方工具栏中选择“手形”工具进行放大和缩小，并在按住Control键的同时单击并拖动鼠标。选择“手形”工具后，您还可以通过单击拖动视图来移动相机，并且可以在按住Option（或Alt）键的同时拖动鼠标来旋转（环绕）相机，这样您就不会受到限制只是轴摄像机的角度，如图2-29所示。</p><p><img src="/2019/02/27/第二章/1551536399.jpg" alt=""></p><center>图 2-29. 场景视图中的倾斜透视</center><p>请注意，当您从任意角度查看时，场景Gizmo下的文本会显示Persp或Iso，具体取决于您是使用透视投影还是正投影（Iso是等长投影的缩写，这是游戏中常见的倾斜正交视图喜欢星际争霸）。</p><p>工具栏上的其他按钮激活用于移动，旋转和缩放GameObject的模式。目前没有理由改变它们，因此当您开始创建新项目时，将更详细地解释这些模式。</p><blockquote><p><strong>提示</strong> 如果您不小心对场景进行了更改，可以从“编辑”菜单中选择“撤消”。如果你做了很多你不想保留的更改，当你切换到另一个场景或退出Unity时，你可以拒绝保存这个场景。在此期间，请注意您仍然可以在这些模式下使用备用键盘和鼠标组合移动相机。表2-1列出了所有可能的选项。</p></blockquote><p>表 2-1. 可用的场景视图相机控件</p><table><thead><tr><th>功能</th><th>手工工具</th><th>一键鼠标或触摸板</th><th>两键鼠标</th><th>三键鼠标</th></tr></thead><tbody><tr><td>移动</td><td>按住-拖拽</td><td>按住Alt-Command并按住-拖拽</td><td>按住Alt-Control按住-拖拽</td><td>按住Alt和中键按住-拖拽</td></tr><tr><td>旋转</td><td>按住Alt键并按住-拖拽</td><td>按住Alt键按住-拖拽</td><td>按住Alt键并按住-拖拽</td><td>按住Alt并按住-拖拽</td></tr><tr><td>缩放</td><td>按住Control键按住-拖拽</td><td>按住Control键按住-拖拽或者两指滑动</td><td>按住Alt键并右键按住-拖拽</td><td>按住Alt键并右键按住-拖拽或者滑动滚轮</td></tr></tbody></table><p>还有一些其他方便的基于键盘的场景导航功能。按箭头键将沿x-z平面（地平面）向前，向后，向左和向右移动摄像机。按住鼠标右键可以像在第一人称游戏中一样导航场景。 AWSD键分别向左，向前，向右和向后移动，并移动鼠标控制相机（视点）所在的位置。</p><p>当你想在场景视图中查看特定的GameObject时，有时最快的方法是在Hierarchy视图中选择GameObject，然后使用Edit菜单中的Frame Selected菜单项（注意方便的快捷键F） 。在图2-28中，我单击Scene Gizmo的x轴以获得水平视图，然后在Hierarchy View中选择Player GameObject，并按下F键（Edit菜单中选择Frame的快捷键）进行缩放在场景视图中的运行器中心和居中。</p><p>您也可以直接在“场景视图”中选择一个GameObject，但必须先退出“手形”工具。就像在层次结构视图中选择GameObject将导致在Scene View和Inspector View中显示该选择一样，在Scene View中选择GameObject同样会在Inspector视图中显示该选择，并在层次结构中将其显示为选定的GameObject视图。在图2-30中，在我调用运行器上的Frame Selected后，我单击了Move工具（编辑器窗口右上角的Hand工具按钮右侧的按钮），然后在Player中单击了Player附近的GameObject。场景视图。层次结构视图自动更新以显示已选择GameObject，并且游戏对象也显示在检查器视图中。</p><p><img src="/2019/02/27/第二章/1551537481.jpg" alt=""></p><center>图 2-30. 在场景视图中选中一个GameObject</center><h3 id="场景视图选项"><a href="#场景视图选项" class="headerlink" title="场景视图选项"></a>场景视图选项</h3><p>位于场景视图顶部的按钮提供显示选项，以帮助您进行游戏开发。每个按钮配置一个视图模式。</p><p>最左边的按钮设置绘图模式。通常，此模式设置为“纹理”，但如果要查看所有多边形，可以将其设置为“线框”（图2-31）。</p><p><img src="/2019/02/27/第二章/1551537584.jpg" alt=""></p><center>图 2-31. “场景”视图中的线框显示</center><p>下一个按钮设置“渲染路径”，它控制场景是正常着色还是用于诊断。 </p><p>“渲染路径”模式按钮右侧的三个按钮是简单的切换按钮。当你将鼠标悬停在它们上面时，它们会弹出一些鼠标悬停文档（也称为工具提示）。</p><p>第一个控制场景光照模式。这在使用场景视图中的默认光照方案或您放置在游戏中的实际光照之间切换。</p><p>中间按钮切换游戏覆盖模式，无论天空，镜头光晕和雾效果是否可见。</p><p>最后，还有Audition模式，可以打开和关闭声音。</p><h3 id="场景视图Gizmos"><a href="#场景视图Gizmos" class="headerlink" title="场景视图Gizmos"></a>场景视图Gizmos</h3><p>右侧的Gizmos按钮激活与组件关联的诊断图形的显示。图2-32中的场景视图显示了一些小玩意儿。通过单击Gizmos按钮并检查可用小玩意列表，您可以看到代表摄像机和灯光的那些图标。</p><p><img src="/2019/02/27/第二章/1551537792.jpg" alt=""></p><center>图 2-32. 场景视图中的Gizmos</center><p>您可以选择和取消选择Gizmos窗口中的各个复选框，以便专注于您感兴趣的对象。左上角的复选框在小玩意的3D显示或2D图标之间切换。相邻的滑块控制小玩意的比例（因此隐藏所有小玩意的快速方法是将比例滑块一直拖动到左侧）。</p><h3 id="游戏视图"><a href="#游戏视图" class="headerlink" title="游戏视图"></a>游戏视图</h3><p>现在让我们来看看游戏视图。与层次结构视图和场景视图一样，游戏视图描绘当前场景，但不用于编辑目的。相反，游戏视图用于运行和调试游戏。</p><p>单击Unity Editor窗口顶部的“运行”按钮时，将自动显示“游戏视图”。如果单击“运行”时没有现有的“游戏视图”，则会创建一个新的游戏视图。如果在编辑器未处于运行模式时游戏视图可见，则它显示游戏处于其初始状态（即，从初始摄像机位置的有利位置）。</p><p>游戏视图显示了游戏在实际部署时的外观和功能，但可能与最终构建目标的外观和行为有所不同。一个可能的区别是游戏视图的大小和宽高比。可以使用视图左上角的菜单更改此设置。图2-33显示了当您从调整视图尺寸的自由宽高比切换到5：4宽高比时会发生什么情况，从而缩小游戏显示范围，使其适合区域和保持所选的宽高比。</p><p><img src="/2019/02/27/第二章/1551537981.jpg" alt=""></p><center>图 2-33. 游戏视图</center><h3 id="运行时最大化"><a href="#运行时最大化" class="headerlink" title="运行时最大化"></a>运行时最大化</h3><p>单击“运行时最大化”按钮将导致游戏视图扩展，以便在运行模式下填充整个编辑器窗口（图2-34）。如果视图与“编辑器”窗口分离，则该按钮无效。</p><p><img src="/2019/02/27/第二章/1551538132.jpg" alt=""></p><center>图 2-34. 游戏视图运行时最大化</center><h3 id="统计"><a href="#统计" class="headerlink" title="统计"></a>统计</h3><p>“统计”按钮显示有关场景的统计信息（图2-35）随着游戏的运行而更新。</p><p><img src="/2019/02/27/第二章/1551538234.jpg" alt=""></p><center>图 2-35. 带有统计的游戏视图</center><h3 id="游戏视图Gizmos"><a href="#游戏视图Gizmos" class="headerlink" title="游戏视图Gizmos"></a>游戏视图Gizmos</h3><p>Gizmos按钮可激活与组件关联的诊断图形的显示。图2-36中的游戏视图显示了两个图标，它们是音频源的小玩意。 Gizmos按钮右侧的列表允许您选择要显示的小玩意。</p><p><img src="/2019/02/27/第二章/1551538327.jpg" alt=""></p><center>图 2-36. 带有Gizmos的游戏视图</center><p>游戏视图和场景视图都是当前场景的描绘。 Unity项目由一个或多个场景组成，Unity Editor一次打开一个场景。将项目视为游戏，将场景视为关卡（实际上，在场景中运行的一些Unity脚本函数在其名称中使用“级别”）。通过附加组件使Unity GameObject变得有趣，每个组件都提供一些特定的信息或行为。这就是Inspector View的用武之地。如果在Hierarchy View或Scene View中选择一个游戏对象，Inspector View将显示其附加的组件。</p><h3 id="控制台视图"><a href="#控制台视图" class="headerlink" title="控制台视图"></a>控制台视图</h3><p>所有预设布局中的剩余视图（控制台视图）很容易被忽略，但它非常有用（图2-37）。</p><p><img src="/2019/02/27/第二章/1551538502.jpg" alt=""></p><center>图 2-37. 控制台视图</center><p>控制台视图中显示信息，警告和错误消息。错误为红色，警告为黄色，信息性消息为白色。从列表中选择一条消息会在下方区域显示更多详细信息。此外，Unity Editor底部的单行区域显示最新的Console消息，因此即使Console视图不可见，您也始终可以看到已记录消息。</p><blockquote><p><strong>提示</strong> 警告消息很容易被忽略，但您可以自行忽略它们。它们是有原因的，通常表明必须解决的问题。如果你让警告累积起来，很难注意到一个非常重要的警告何时出现。</p></blockquote><p>控制台很快就会混乱。您可以使用控制台视图顶部最左侧的三个按钮来管理这种混乱。清除切换按钮可删除所有消息。 “折叠切换”按钮组合了类似的消息。每次编辑器进入播放模式时，清除播放切换将删除所有消息。</p><p>错误暂停按钮将导致编辑器暂停错误消息，特别是当脚本调用Log.LogError时。</p><p>在编辑器中操作时，日志消息最终会出现在编辑器日志中，而从Unity构建的可执行文件生成的消息将被定向到播放器日志。从视图菜单中选择Open Player Log或Open Editor Log（单击Console视图右上角的小图标）将在文本文件或控制台应用程序中显示这些日志（图2-38）。</p><p><img src="/2019/02/27/第二章/1551538673.jpg" alt=""></p><center>图 2-38. Mac控制台应用中的Unity日志</center><h3 id="进一步探索"><a href="#进一步探索" class="headerlink" title="进一步探索"></a>进一步探索</h3><p>我们已经结束了这次Unity之旅。在第3章中，您将开始学习一些ARKit功能。这是真正开始使用Unity的第一章。您还没有开始构建自己的场景（将在第3章开始），但您已经能够熟悉Unity编辑器。有很多官方Unity资源可以扩展我将要讨论的主题。</p><h3 id="Unity手册"><a href="#Unity手册" class="headerlink" title="Unity手册"></a>Unity手册</h3><p>正如您所看到的，Unity用户界面很多，我们几乎都没有。现在是认真阅读Unity手册的好时机，可以从Unity编辑器（欢迎屏幕或帮助菜单）或Unity网站（<a href="http://unity3d.com/）下的学习选项卡下阅读“文档”部分。当您想要查看某些内容或只是阅读Unity而没有在附近运行Unity" target="_blank" rel="noopener">http://unity3d.com/）下的学习选项卡下阅读“文档”部分。当您想要查看某些内容或只是阅读Unity而没有在附近运行Unity</a> Editor时，Web版本非常方便。</p><p>本章介绍的大部分内容与Unity手册的Unity基础部分中的主题相匹配，特别是“学习界面”，“自定义工作区”，“发布构建”和“Unity热键”部分。我们确实跳过了进入Unity手册的高级部分，触及Unity对版本控制的支持。 Unity手册的“使用Unity进行外部版本控制”页面对此进行了更深入的介绍。</p><h3 id="指南"><a href="#指南" class="headerlink" title="指南"></a>指南</h3><p>除了“文档”部分，Unity网站上的“学习”选项卡还包含一个“教程”部分，其中包含大量的初级编辑器视频。顾名思义，这些视频介绍了Unity编辑器，实际上这组视频涵盖了本章讨论的大部分内容，包括最重要视图的描述（游戏视图，场景视图，层次结构视图，检查器视图，和Project View）甚至是发布构建的过程。</p><h3 id="版本控制"><a href="#版本控制" class="headerlink" title="版本控制"></a>版本控制</h3><p>虽然我只是简单地讨论了版本控制，但在解释如何删除元文件的上下文中，该主题值得多讨论，因为版本控制系统（或VCS）对于软件开发非常重要（您将首先实现它）你失去你的项目的时间或不记得你做了什么改变打破了你的游戏！）。如果你已经有了一个最喜欢的VCS，你可能想在Unity中使用它，如果你还没有使用它，那么你可能想要考虑它，如果只是保留你的项目的旧版本，以防你需要滚动返回，能够检查版本之间的差异。</p><p>在版本控制系统中，Perforce是游戏工作室中常用的商业工具，而Subversion（svn）作为开源选项有着悠久的历史。目前，像Git和Mercurial这样的分布式版本控制系统正在发展趋势。我在Bitbucket上使用Mercurial（http：// bitbucket.com /）作为我的内部项目并在GitHub上发布公共项目，包括本书的项目。</p><p>说Unity VCS支持与产品无关是另一种说法，Unity没有任何特定的版本控制系统集成到Unity Editor中。 Unity Pro用户的元文件和YAML场景文件只是提供了与常用于源代码的面向文本的版本控制系统的更好兼容性。您仍然必须在Unity之外自己运行VCS操作。顺便提一下，您可以在<a href="http://yaml.org/上找到有关YAML的更多信息。我发现使用GitHub网站上提供的Mac" target="_blank" rel="noopener">http://yaml.org/上找到有关YAML的更多信息。我发现使用GitHub网站上提供的Mac</a> GitHub应用程序和类似的BitTucket SourceTree也很方便，也可以在该网站上找到。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如果顺利的话，您可能已经对增强现实（或AR）有了一个很好的了解。由于对术语虚拟现实（或VR），增强现实和混合现实之间的差异存在一些混淆，我认为可能值得在本书中澄清AR的含义。&lt;/p&gt;
&lt;p&gt;虚拟现实（VR）是一个计算机生成的环境，通过感官和感知模拟体验。不同于传统的计算机系统，VR系统将用户置于体验之中。代替在他们屏幕前观看，用户沉浸其中并且能够与3D世界互动。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Unity" scheme="https://zhaolilong.com/tags/Unity/"/>
    
      <category term="ARKit" scheme="https://zhaolilong.com/tags/ARKit/"/>
    
  </entry>
  
  <entry>
    <title>第一章</title>
    <link href="https://zhaolilong.com/2019/02/25/%E7%AC%AC%E4%B8%80%E7%AB%A0/"/>
    <id>https://zhaolilong.com/2019/02/25/第一章/</id>
    <published>2019-02-25T00:31:18.000Z</published>
    <updated>2020-03-13T01:12:45.988Z</updated>
    
    <content type="html"><![CDATA[<p>在本书中，我们将学习如何去创建一个增强现实（AR）游戏使用游戏开发软件Unity（Unity3D 2018或者更新版本， Unity）。本章中，我们将通过下载和安装Unity的过程，了解Unity提供的一些工具。我们也将安装一个来自Unity Asset Store存在的AR项目，探索这个游戏的一些特性。第二章，我们将安装ARKit和提供一个Unity用户界面的概览。第三章，我们将开始使用Unity ARKit并使用一些关键的功能。我还将提供视觉惯性测距的基本概述以及这对创建AR项目的意义。我们将使用基本场景并测试Unity ARKit。在第四章，我们将使用一些Unity ARKit中更高级的功能，例如AR场景的命中测试和光照。最后，第五章，我们将把所有这些结合起来，使用Unity ARKit来制作一款AR游戏。</p><a id="more"></a><h1 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在本书中，我们将学习如何去创建一个增强现实（AR）游戏使用游戏开发软件Unity（Unity3D 2018或者更新版本， Unity）。本章中，我们将通过下载和安装Unity的过程，了解Unity提供的一些工具。我们也将安装一个来自Unity Asset Store存在的AR项目，探索这个游戏的一些特性。第二章，我们将安装ARKit和提供一个Unity用户界面的概览。第三章，我们将开始使用Unity ARKit并使用一些关键的功能。我还将提供视觉惯性测距的基本概述以及这对创建AR项目的意义。我们将使用基本场景并测试Unity ARKit。在第四章，我们将使用一些Unity ARKit中更高级的功能，例如AR场景的命中测试和光照。最后，第五章，我们将把所有这些结合起来，使用Unity ARKit来制作一款AR游戏。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;本书是为没有使用Unity或制作游戏的经验的初学者编写的。这些章节按顺序编写，以帮助每一步的学习。但是，如果您正在阅读本书并且已经了解Unity或制作游戏，那么请随意跳过您认为已经知道的章节。</p><h3 id="Unity3D"><a href="#Unity3D" class="headerlink" title="Unity3D"></a>Unity3D</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Unity游戏引擎是一个创建2D和3D游戏的跨平台游戏开发工具。跨平台不同的人有不同的理解。Unity可以被使用在macOS，Windows，或者Linux上，这可以被认为是一个跨平台开发工具。但是，Unity可以用来开发游戏机，个人计算机，网络浏览器，移动设备，VR系统的游戏等等，这也可能是Unity被认为是跨平台开发工具的原因。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Unity可用于创建3D游戏，也就是说，游戏看起来像是在3D空间中运行（它有X，Y和Z）。Unity也可用于创建2D游戏。最近，Unity已经用于创建VR和AR游戏或者模拟。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在本书中，我们将使用Unity最新版本，当前是2018.1版本。然而，像大多数软件（和很多硬件）一样，Unity不断推出新特性和新功能，到本书印刷时，可能会有更新版本的Unity。当Unity对其软件进行微小更改时，通常会添加一个数字（如2018.1.1）。当更新有点重要时，版本号将会改变（如2018.2）。当Unity通常进行重大更改时，版本号将完全更改（Unity 1,2,3,4,5）。 2017年7月，Unity将版本编号系统更改为发布年份（2017年和2018年）。</p><h3 id="Unity要求"><a href="#Unity要求" class="headerlink" title="Unity要求"></a>Unity要求</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在你开始学习制作游戏之前，你将需要下载Unity并安装它在你的Mac上。虽然可以在Windows个人计算机上安装带有Unity的iOS设备的游戏，但您需要使用一个名为Xcode的软件来移植Unity代码，以便它可以在Mac或iOS设备上运行。目前，Xcode仅适用于Mac。所以，如果你有一台Windows PC，那么在某个阶段你需要使用Mac来移植游戏。在本书中，我将使用Mac;如果您使用的是Windows PC，则许多说明或说明可能不适用于您。</p><h3 id="准备你的Mac"><a href="#准备你的Mac" class="headerlink" title="准备你的Mac"></a>准备你的Mac</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于使用Unity的iOS开发，您需要一台运行Mac OS X 10.9或更高版本的Lion或Mountain Lion以及Xcode 7.0或更高版本的Mac。 Unity 2018仍然可以在一些较旧的系统上运行，但是您需要最新版本的Xcode，如上所述，这是iOS开发所必需的。最新版本的Xcode通常支持更新版本的iOS。在撰写本文时，Xcode的当前版本是版本9，这是我将在本书中使用的内容。</p><h3 id="注册"><a href="#注册" class="headerlink" title="注册"></a>注册</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我强烈建议您查看Apple开发人员网站（<a href="https://developer.apple.com/" target="_blank" rel="noopener">https://developer.apple.com/</a>）并注册为iOS开发人员。虽然这不是本书的绝对要求，但如果您想在App Store上发布游戏，那么您将需要成为注册的Apple Developer。注册为Apple Developer的过程可能需要一段时间，尤其是如果您正在注册公司。第一步是注册为Apple Developer（目前是免费的），然后一旦注册，下一步就是注册为iOS开发人员（目前每年99美元）。</p><h3 id="下载Xcode"><a href="#下载Xcode" class="headerlink" title="下载Xcode"></a>下载Xcode</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在本书的后面部分，你不需要Xcode，但值得下载和安装Xcode。您可以在Apple Developer网站（<a href="https://developer.apple.com/" target="_blank" rel="noopener">https://developer.apple.com/</a>）上找到最新版本的Xcode。</p><h3 id="下载Unity"><a href="#下载Unity" class="headerlink" title="下载Unity"></a>下载Unity</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在是安装Unity的好时机。访问Unity网站<a href="https://unity3d.com" target="_blank" rel="noopener">https://unity3d.com</a>，然后选择Get Unity或输入[https:// store.unity.com/](https:// store.unity.com/)。在此页面上，您将找到Unity的最新版本（在撰写本文时，2018.1）。您还可以在Unity网站上找到Unity的早期版本。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虽然只有一个Unity应用程序，但您可以订阅不同的许可选项，具体取决于您的需求和公司规模（如果有的话）。三种许可选项目前是Personal，Plus和Pro。要开始下载过程，请单击符合您需求的订阅选项按钮（在撰写本文时，这将是Try Personal，Get Plus或Go Pro）。该文件大约为1GB，因此下载可能需要一段时间。在你等待的时候，你在Unity网站上，花一些时间查看已发布的一些游戏和演示，社区网站和用户论坛。这些在使用Unity的游戏开发过程中非常有用。</p><h3 id="安装Unity"><a href="#安装Unity" class="headerlink" title="安装Unity"></a>安装Unity</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;您从Unity下载的文件是一个下载安装程序，在撰写本文时名为UnityDownloadAssistant。</p><h3 id="运行下载助手"><a href="#运行下载助手" class="headerlink" title="运行下载助手"></a>运行下载助手</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下载UnityDownloadAssistant文件后，双击该文件以运行Unity Download Assistant。双击Unity Download Assistant图标以开始安装Unity（图1-1）。</p><p><img src="/2019/02/25/第一章/1551054573.jpg" alt=""></p><p>图 1-1. Unity下载助手</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;安装程序将处理整个安装周期，当这个完成的时候，一个Unity的文件夹将会被放置在Applications文件夹里（除非你选择了一个不同的安装位置）。如果您安装了以前版本的Unity，新版本的安装可能替换以前的版本。我建议在安装新版本之前重命名以前版本的文件夹（例如，Unity2017）。这样您仍然可以使用Unity的两个版本。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Unity安装文件夹包含Unity应用程序和几个支持文件夹和应用程序（图 1-2）。</p><p><img src="/2019/02/25/第一章/1551188404.jpg" alt=""></p><p>图 1-2 Unity安装文件夹</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Unity文件夹中最重要的文件之一是Unity应用程序，它将提供一些工具用来创建和测试您的游戏。应用程序有时有时称为Unity编辑器，不同于其他程序，Unity运行时引擎（也称为Unity播放器）。Unity运行时引擎已集成到最终版本，这将使游戏能够在目标硬件上运行。当我提到Unity时，通常指的是Unity编辑器。 我有时会将Unity技术称为Unity。但如果顺利的话，上下文是明确的。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Documentation文件夹包含用户手册，组件参考，脚本参考文档。这些在Unity网站上也是可用的（选择学习链接）。所有这些文档都是HTML文档，从Unity Help菜单系统中可以用浏览器打开，或者可以双击直接打开它们。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Standard Assets文件夹包含许多以.unityPackage作为文件扩展名的文件。这些是Unity的包文件，它包含Unity资产的集合，可以被导入Unity。它也可能创建你自己的标准资产并导出这些资产为一个包文件。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;还有Unity Bug Reporter应用程序。这个应用程序是通常直接在Unity编辑器中运行Report a Bug功能。然而，这个应用程序从Unity安装文件夹直接运行。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果您在Unity安装时下载了样例项目，确保在Unity中打开这些。如果您在安装时不下载这些。它仍然可以在任何时候呗下载。</p><h3 id="欢迎"><a href="#欢迎" class="headerlink" title="欢迎"></a>欢迎</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在Unity安装完成后（做好准备需要一段时间），Unity编辑器欢迎界面将出现Unity Hello！窗口（图 1-3）。Unity Hello！窗口是您登录Unity账户的地方（如果您有的话）。如果您没有Unity账户，选择Create One链接。如果您当前没有连接网络，您可以通过选择Work offline按钮进行离线工作。</p><p><img src="/2019/02/25/第一章/1551190638.jpg" alt=""></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当您启动Unity（图 1-3）时Unity Hello！窗口将会出现。我强烈建议创建一个Unity账户，如果您还没有创建的话。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首次登录以后，您将会看到License管理界面。如果您已经付费了Unity的授权版本，在对话框中输入你的授权序列号。请输入您的许可证 对话框中的序列号。如果你想使用免费版的Unity， 选择Unity Personal单选按钮（图 1-4）。</p><p><img src="/2019/02/25/第一章/1551222294.jpg" alt=""></p><p>图 1-4 Unity授权管理界面</p><h3 id="设置Unity"><a href="#设置Unity" class="headerlink" title="设置Unity"></a>设置Unity</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在我们开始使用Unity制作游戏之前，现在是查看Unity的一些选项和管理功能的好时机。</p><h3 id="改变外观（Pro版）"><a href="#改变外观（Pro版）" class="headerlink" title="改变外观（Pro版）"></a>改变外观（Pro版）</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果你已经购买了一个Unity的Pro授权，你将能够在浅色或深色之间选择。如果你正在使用Unity的免费版本，你讲只能看到浅色外观。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;作为大多数游戏开发的初学者使用Unity的免费版本，我将使用浅色外观截屏。对于这本书的纸质版本浅色外观也能产生更好的截屏效果。如果你有高级版本并且想去改变外观，选择Unity菜单中的Prefrences（偏好设置）项（图 1-5）</p><p><img src="/2019/02/25/第一章/1551223091.jpg" alt=""></p><p>图 1-5 Unity偏好设置菜单</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;随着偏好设置菜单的打开，你可以改变皮肤用深色到浅色或浅色到深色（图 1-6）如果你正在使用Unity个人版本，您被迫接受浅色皮肤。</p><p><img src="/2019/02/25/第一章/1551223299.jpg" alt=""></p><p>图 1-6 Unity编辑器中的通用偏好设置菜单</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当您已经打开偏好设置菜单时，我建议确保启动时加载以前的项目选项是未选中的。这将确保Unity在启动时加载项目选择对话框。这将确保您避免更新错误的版本或者在准备好之前更新您正在使用的Unity版本。</p><h3 id="报告问题"><a href="#报告问题" class="headerlink" title="报告问题"></a>报告问题</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果你继续使用Unity几年，你将遇到一些bug（真实的和想象中的）。我从1.6版本使用Unity并遇到了很多Unity的bug。软件的bug对于Unity不是唯一的。一个游戏开发引擎是软件中复杂的一片并且Unity肯定赞赏并重视错误报告。如果bug不被报告，那么Unity很难修复它们。Unity Bug Reporter应用程序提供了这个特性。正如前面提到的，报告一个Bug Report可在Unity安装文件夹中找到，也可从Unity编辑器的“帮助”菜单中选择（图1-7）。</p><p><img src="/2019/02/25/第一章/1551224060.jpg" alt=""></p><p>图 1-7 帮助菜单中的报告Bug选项</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在帮助菜单上选择Report a Bug选项或者在Unity安装文件夹中双击Report a Bug应用程序来打开Unity Report a Bug应用程序（图 1-8）。该应用程序提供菜单选项和对话框，供用户指定问题是关于什么的，问题发生的频率，bug的标题，bug的细节，以及附加任何有助于修复的相关文件的选项。Unity Bug Reporter需要用户指定一个email地址以便于Unity团队可以回复bug报告者。</p><p><img src="/2019/02/25/第一章/1551224778.jpg" alt=""></p><p>图 1-8 Unity Bug Reporter窗口</p><h3 id="iOS开发要求"><a href="#iOS开发要求" class="headerlink" title="iOS开发要求"></a>iOS开发要求</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在前面的章节中，我建议下载Xcode和注册苹果开发者计划是一个好的主意。如果你还没有做好。现在是停下来做这些的好时机。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于iOS开发的硬件和软件要求以及关于苹果开发者计划的细节列在苹果开发者支持页面(<a href="https://developer.apple.com" target="_blank" rel="noopener">https://developer.apple.com</a>)上。你也可以找到Xcode的要求和下载页面，网址为<a href="https://developer.apple.com/Xcode/" target="_blank" rel="noopener">https://developer.apple.com/Xcode/</a>。</p><h3 id="Unity网站"><a href="#Unity网站" class="headerlink" title="Unity网站"></a>Unity网站</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;随着Unity Technologies增加Unity的特性和功能，内容的广度和深度也增加了。网站上有大量的信息，但是我建议看看FAQ部分（<a href="https://unity3d.com/unity/faq" target="_blank" rel="noopener">https://unity3d.com/unity/faq</a>）。也有一些非常棒的指南，文档，以及视频，这些将帮助你使用Unity（<a href="https://unity3d.com/unity/faq" target="_blank" rel="noopener">https://unity3d.com/unity/faq</a>）来学习创建游戏。</p><h3 id="Unity社区"><a href="#Unity社区" class="headerlink" title="Unity社区"></a>Unity社区</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在帮助菜单中，有官方的Unity社区网站链接。这包含了官方Unity论坛（<a href="https://forum.unity.com" target="_blank" rel="noopener">https://forum.unity.com</a>），由Unity工作人员主持。对于任何游戏开发者而言这是非常棒的资源。这个菜单上还有Unity Answers的链接，它使用了一个Stack Exchange格式并包含一些控制（或审核） 问题和解答。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Unity反馈网站（<a href="https://feedback.unity3d.com" target="_blank" rel="noopener">https://feedback.unity3d.com</a>）让开发者能够在未来可能的特性上发出请求或者投票。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在本书中，我们将学习如何去创建一个增强现实（AR）游戏使用游戏开发软件Unity（Unity3D 2018或者更新版本， Unity）。本章中，我们将通过下载和安装Unity的过程，了解Unity提供的一些工具。我们也将安装一个来自Unity Asset Store存在的AR项目，探索这个游戏的一些特性。第二章，我们将安装ARKit和提供一个Unity用户界面的概览。第三章，我们将开始使用Unity ARKit并使用一些关键的功能。我还将提供视觉惯性测距的基本概述以及这对创建AR项目的意义。我们将使用基本场景并测试Unity ARKit。在第四章，我们将使用一些Unity ARKit中更高级的功能，例如AR场景的命中测试和光照。最后，第五章，我们将把所有这些结合起来，使用Unity ARKit来制作一款AR游戏。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>增强现实交互</title>
    <link href="https://zhaolilong.com/2018/06/20/%E5%A2%9E%E5%BC%BA%E7%8E%B0%E5%AE%9E%E4%BA%A4%E4%BA%92/"/>
    <id>https://zhaolilong.com/2018/06/20/增强现实交互/</id>
    <published>2018-06-20T08:47:03.000Z</published>
    <updated>2020-03-10T01:56:09.669Z</updated>
    
    <content type="html"><![CDATA[<p>在真实世界场景中显示虚拟物体可能是很有趣的，但是你想做得更多而不仅仅是在一个场景上覆盖静态图片。另外在场景中显示虚拟物体，ARKit也可以使得虚拟物体在屏幕上移动，给用户与虚拟物体交互的能力，通过触摸手势，例如点击或者滑动。</p><a id="more"></a><p>例如，一个用户可能想点击一个虚拟物体来使得它移动或者以某种方式响应，例如改变它的外观或者在屏幕上移动。通过制作增强现实交互，你的应用可能更感兴趣和赞同。</p><blockquote><p><strong>注意</strong> 你仅仅可以测试和运行ARKit应用在iPhone 6s或者更高，或者一个iPad Pro上。</p></blockquote><p>让我们创建一个新的增强现实应项目，命名为ARGesture。这个项目将包含一个AppDelegate.swift文件，一个ViewController.swift文件和一个Main.storyboard文件，还有art.scnassets文件夹，它包含了一个ship.scn对象和一个texture.png文件。</p><p>我们的目标是创建一个几何模型并在屏幕上显示它。然后用户可以在那个模型上滑动并使得它旋转。为了做到这点，我们将需要学习一些技能。</p><p>首先，大多数人熟悉操作几何模型使用角度，但是苹果的SceneKit框架使用弧度。我们可以编写我们自己的公式去转换角度到弧度，但是苹果提供了一个数学框架叫作GLKit，它包含了一个可以执行这个计算的函数。作为一个通用的规则，尽可能依赖苹果框架总是最好的，而不是编写你自己的函数，因为苹果框架被测试过，而你讲不得不花费时间调试和测试你自己的函数。</p><p>在ViewController.swift文件的顶部，添加以下行导入GLKit框架</p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> GLKit</span><br></pre></td></tr></table></figure><p>你的ViewController.swift文件应该导入GLKit，UIKit，SceneKit和ARKit框架总共四个import语句。</p><p>接下来，我们需要创建一个节点，该节点代表我们想添加到屏幕上的几何模型。这意味着创建一个SCNNode对象。因为我们将需要访问这个对象在不止一个方法中，创建这个作为一个IBOutlet属性，所以ViewController.swift文件顶部应当看起来像这样:</p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> UIKit</span><br><span class="line"><span class="keyword">import</span> SceneKit</span><br><span class="line"><span class="keyword">import</span> ARKit</span><br><span class="line"><span class="keyword">import</span> GLKit</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ViewController</span>: <span class="title">UIViewController</span>, <span class="title">ARSCNViewDelegate</span> </span>&#123;</span><br><span class="line">    <span class="meta">@IBOutlet</span> <span class="keyword">var</span> sceneView: <span class="type">ARSCNView</span>!</span><br><span class="line">    <span class="keyword">let</span> node = <span class="type">SCNNode</span>()</span><br></pre></td></tr></table></figure><p>在viewDidLoad函数中，我们可以添加调试选项，将在屏幕上显示世界原点。你可能不想显示世界原点在最终的应用中，但是它可以当你开发应用时是有用的，显示给你虚拟物体出现在屏幕的位置。添加以下行在viewDidLoad函数中：</p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sceneView.debugOptions = [<span class="type">ARSCNDebugOptions</span>.showWorldOrigin, <span class="type">ARSCNDebugOptions</span>.showFeaturePoints]</span><br></pre></td></tr></table></figure><h2 id="存储和访问图形资产"><a href="#存储和访问图形资产" class="headerlink" title="存储和访问图形资产"></a>存储和访问图形资产</h2><p>现在我们需要创建一个几何模型。在这种情况下，我们想创建一个金字塔，所以我们将需要定义它的宽，高和长。另外，我们也想去应用一个纹理到我们的金字塔上。</p><p>增强现实应用项目引入了两个图像文件：ship.scn和texture.png。我们将不显示ship.scn文件，所以你可以删除代码，显示这个ship.scn在屏幕上。然而，我们想去使用texture.png文件。</p><p>在前一章节中，你看到了如何使用一个纹理图像图片通过简单地定义它的名字像这样：</p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> material = <span class="type">SCNMaterial</span>()</span><br><span class="line">material.diffuse.contents = <span class="type">UIImage</span>(named: <span class="string">"stone.jpg"</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在真实世界场景中显示虚拟物体可能是很有趣的，但是你想做得更多而不仅仅是在一个场景上覆盖静态图片。另外在场景中显示虚拟物体，ARKit也可以使得虚拟物体在屏幕上移动，给用户与虚拟物体交互的能力，通过触摸手势，例如点击或者滑动。&lt;/p&gt;
    
    </summary>
    
    
      <category term="AR" scheme="https://zhaolilong.com/tags/AR/"/>
    
      <category term="增强现实" scheme="https://zhaolilong.com/tags/%E5%A2%9E%E5%BC%BA%E7%8E%B0%E5%AE%9E/"/>
    
  </entry>
  
</feed>
